{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fef2aad6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from math import sqrt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3dec5da2",
   "metadata": {},
   "outputs": [],
   "source": [
    "week1=pd.read_csv(\"nfl-big-data-bowl-2024/tracking_week_1.csv\")\n",
    "week2=pd.read_csv(\"nfl-big-data-bowl-2024/tracking_week_2.csv\")\n",
    "week3=pd.read_csv(\"nfl-big-data-bowl-2024/tracking_week_3.csv\")\n",
    "week4=pd.read_csv(\"nfl-big-data-bowl-2024/tracking_week_4.csv\")\n",
    "week5=pd.read_csv(\"nfl-big-data-bowl-2024/tracking_week_5.csv\")\n",
    "week6=pd.read_csv(\"nfl-big-data-bowl-2024/tracking_week_6.csv\")\n",
    "week7=pd.read_csv(\"nfl-big-data-bowl-2024/tracking_week_7.csv\")\n",
    "week8=pd.read_csv(\"nfl-big-data-bowl-2024/tracking_week_8.csv\")\n",
    "week9=pd.read_csv(\"nfl-big-data-bowl-2024/tracking_week_9.csv\")\n",
    "plays=pd.read_csv(\"nfl-big-data-bowl-2024/plays.csv\")\n",
    "games=pd.read_csv(\"nfl-big-data-bowl-2024/games.csv\")\n",
    "players=pd.read_csv(\"nfl-big-data-bowl-2024/players.csv\")\n",
    "tackles=pd.read_csv(\"nfl-big-data-bowl-2024/tackles.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2e289df6",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_plays=pd.concat([week1, week2, week3, week4, week5, week6, week7, week8, week9],axis=0)\n",
    "plays[\"uniqueid\"]=plays[\"gameId\"]*plays[\"playId\"]\n",
    "all_plays[\"uniqueid\"]=all_plays[\"gameId\"]*all_plays[\"playId\"]\n",
    "plays_final=pd.merge(plays,games, on=\"gameId\",how=\"right\")\n",
    "plays_final=plays_final[plays_final[\"playNullifiedByPenalty\"]==\"N\"]\n",
    "plays_final.drop([\"gameId\",\"playId\",\"ballCarrierDisplayName\",\"playDescription\",\"prePenaltyPlayResult\",\"playNullifiedByPenalty\",\n",
    "                 \"foulName1\",\"foulName2\",\"penaltyYards\",\"foulNFLId1\",\"foulNFLId2\",\"season\",\"gameDate\",\"gameTimeEastern\"],axis=1,inplace=True)\n",
    "def assign_offense_defense(row):\n",
    "    if row['possessionTeam'] == row['homeTeamAbbr']:\n",
    "        row['offenseScore'] = row['preSnapHomeScore']\n",
    "        row['defenseScore'] = row['preSnapVisitorScore']\n",
    "        row['offenseWinProbability'] = row['preSnapHomeTeamWinProbability']\n",
    "        row['offenseWPAdded']=row[\"homeTeamWinProbabilityAdded\"]\n",
    "        row['defenseWinProbability'] = row['preSnapVisitorTeamWinProbability']\n",
    "        row['defenseWPAdded']=row[\"visitorTeamWinProbilityAdded\"]\n",
    "    else:\n",
    "        row['offenseScore'] = row['preSnapVisitorScore']\n",
    "        row['defenseScore'] = row['preSnapHomeScore']\n",
    "        row['offenseWinProbability'] = row['preSnapVisitorTeamWinProbability']\n",
    "        row['offenseWPAdded']=row[\"visitorTeamWinProbilityAdded\"]\n",
    "        row['defenseWinProbability'] = row['preSnapHomeTeamWinProbability']\n",
    "        row['defenseWPAdded']=row[\"homeTeamWinProbabilityAdded\"]\n",
    "    return row\n",
    "\n",
    "plays_final = plays_final.apply(assign_offense_defense, axis=1)\n",
    "plays_final=plays_final.drop([\"preSnapHomeScore\",\"preSnapVisitorScore\",\"preSnapHomeTeamWinProbability\",\"preSnapVisitorTeamWinProbability\",\n",
    "                             \"homeFinalScore\",\"visitorFinalScore\",\"homeTeamWinProbabilityAdded\",\"visitorTeamWinProbilityAdded\"], axis=1)\n",
    "all_plays=pd.merge(all_plays, games, on=\"gameId\",how=\"right\")\n",
    "all_plays.drop([\"gameDate\",\"gameTimeEastern\",\"homeTeamAbbr\",\"visitorTeamAbbr\",\"homeFinalScore\",\"visitorFinalScore\"],axis=1, inplace=True)\n",
    "all_id=plays_final.uniqueid\n",
    "final_data=pd.merge(all_plays, plays_final, on=\"uniqueid\",how=\"right\")\n",
    "final_data.drop([\"gameId\",\"playId\",\"time\",\"jerseyNumber\",\"season\",\"yardlineSide\",\n",
    "                     \"yardlineNumber\",\"passResult\",\"passLength\",\"week_y\",\"homeTeamAbbr\",\"visitorTeamAbbr\"], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d09bbc44",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_check = ['x', 'y', 's', 'a', 'dis']\n",
    "rows_with_all_nas = final_data[columns_to_check].isna().all(axis=1)\n",
    "final_data = final_data[~rows_with_all_nas]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "631a4327",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/0b/4q6tccn90zd2mrdvjhd77ydm0000gn/T/ipykernel_1121/2563332080.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  nfinal_data[\"AbsolutePostPlay\"]=nfinal_data[\"absoluteYardlineNumber\"]+nfinal_data[\"playResult\"]\n"
     ]
    }
   ],
   "source": [
    "safefumble_ids = final_data[(final_data['event'] == 'fumble') | (final_data['event'] == 'safety')]['uniqueid'].unique()\n",
    "nfinal_data = final_data[~final_data['uniqueid'].isin(safefumble_ids)]\n",
    "for index, row in nfinal_data.iterrows():\n",
    "    if row['playDirection']==\"left\":\n",
    "        nfinal_data.at[index,\"x\"]=120-row[\"x\"]\n",
    "        nfinal_data.at[index,\"o\"]=360-row[\"o\"]\n",
    "        nfinal_data.at[index,\"dir\"]=360-row[\"dir\"]\n",
    "        nfinal_data.at[index,\"absoluteYardlineNumber\"]=120-row[\"absoluteYardlineNumber\"]\n",
    "nfinal_data[\"AbsolutePostPlay\"]=nfinal_data[\"absoluteYardlineNumber\"]+nfinal_data[\"playResult\"]\n",
    "nfinal_data=nfinal_data[nfinal_data[\"uniqueid\"]!=4753982039408]\n",
    "nfinal_data=nfinal_data[nfinal_data[\"uniqueid\"]!=3912749001045]\n",
    "nfinal_data=nfinal_data[nfinal_data[\"uniqueid\"]!=4147333259153]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0e1878d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_groups = nfinal_data.groupby('uniqueid').filter(lambda x: ~((x['event'] == 'handoff') | (x['event'] == 'pass_outcome_caught') | (x[\"event\"]==\"run\")).any())\n",
    "unique_ids_without_events = filtered_groups['uniqueid'].unique()\n",
    "nfinal_data=nfinal_data[~nfinal_data['uniqueid'].isin(unique_ids_without_events)]\n",
    "relevant_events = nfinal_data[nfinal_data['event'].isin(['handoff', 'run', 'pass_outcome_caught'])]\n",
    "event_counts = relevant_events.groupby('uniqueid')['event'].nunique()\n",
    "plays_with_multiple_events = event_counts[event_counts > 1].index.tolist()\n",
    "nfinal_data=nfinal_data[~nfinal_data['uniqueid'].isin(plays_with_multiple_events)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "794998e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing row number: 10000\n",
      "Processing row number: 20000\n",
      "Processing row number: 30000\n",
      "Processing row number: 40000\n",
      "Processing row number: 50000\n",
      "Processing row number: 60000\n",
      "Processing row number: 70000\n",
      "Processing row number: 80000\n",
      "Processing row number: 90000\n",
      "Processing row number: 100000\n",
      "Processing row number: 110000\n",
      "Processing row number: 120000\n",
      "Processing row number: 130000\n",
      "Processing row number: 140000\n",
      "Processing row number: 150000\n",
      "Processing row number: 160000\n",
      "Processing row number: 170000\n",
      "Processing row number: 180000\n",
      "Processing row number: 190000\n",
      "Processing row number: 200000\n",
      "Processing row number: 210000\n",
      "Processing row number: 220000\n",
      "Processing row number: 230000\n",
      "Processing row number: 240000\n",
      "Processing row number: 250000\n",
      "Processing row number: 260000\n",
      "Processing row number: 270000\n",
      "Processing row number: 280000\n",
      "Processing row number: 290000\n",
      "Processing row number: 300000\n",
      "Processing row number: 310000\n",
      "Processing row number: 320000\n",
      "Processing row number: 330000\n",
      "Processing row number: 340000\n",
      "Processing row number: 350000\n",
      "Processing row number: 360000\n",
      "Processing row number: 370000\n",
      "Processing row number: 380000\n",
      "Processing row number: 390000\n",
      "Processing row number: 400000\n",
      "Processing row number: 410000\n",
      "Processing row number: 420000\n",
      "Processing row number: 430000\n",
      "Processing row number: 440000\n",
      "Processing row number: 450000\n",
      "Processing row number: 460000\n",
      "Processing row number: 470000\n",
      "Processing row number: 480000\n",
      "Processing row number: 490000\n",
      "Processing row number: 500000\n",
      "Processing row number: 510000\n",
      "Processing row number: 520000\n",
      "Processing row number: 530000\n",
      "Processing row number: 540000\n",
      "Processing row number: 550000\n",
      "Processing row number: 560000\n",
      "Processing row number: 570000\n",
      "Processing row number: 580000\n",
      "Processing row number: 590000\n",
      "Processing row number: 600000\n",
      "Processing row number: 610000\n",
      "Processing row number: 620000\n",
      "Processing row number: 630000\n",
      "Processing row number: 640000\n",
      "Processing row number: 650000\n",
      "Processing row number: 660000\n",
      "Processing row number: 670000\n",
      "Processing row number: 680000\n",
      "Processing row number: 690000\n",
      "Processing row number: 700000\n",
      "Processing row number: 710000\n",
      "Processing row number: 720000\n",
      "Processing row number: 730000\n",
      "Processing row number: 740000\n",
      "Processing row number: 750000\n",
      "Processing row number: 760000\n",
      "Processing row number: 770000\n",
      "Processing row number: 780000\n",
      "Processing row number: 790000\n",
      "Processing row number: 800000\n",
      "Processing row number: 810000\n",
      "Processing row number: 820000\n",
      "Processing row number: 830000\n",
      "Processing row number: 840000\n",
      "Processing row number: 850000\n",
      "Processing row number: 860000\n",
      "Processing row number: 870000\n",
      "Processing row number: 880000\n",
      "Processing row number: 890000\n",
      "Processing row number: 900000\n",
      "Processing row number: 910000\n",
      "Processing row number: 920000\n",
      "Processing row number: 930000\n",
      "Processing row number: 940000\n",
      "Processing row number: 950000\n",
      "Processing row number: 960000\n",
      "Processing row number: 970000\n",
      "Processing row number: 980000\n",
      "Processing row number: 990000\n",
      "Processing row number: 1000000\n",
      "Processing row number: 1010000\n",
      "Processing row number: 1020000\n",
      "Processing row number: 1030000\n",
      "Processing row number: 1040000\n",
      "Processing row number: 1050000\n",
      "Processing row number: 1060000\n",
      "Processing row number: 1070000\n",
      "Processing row number: 1080000\n",
      "Processing row number: 1090000\n",
      "Processing row number: 1100000\n",
      "Processing row number: 1110000\n",
      "Processing row number: 1120000\n",
      "Processing row number: 1130000\n",
      "Processing row number: 1140000\n",
      "Processing row number: 1150000\n",
      "Processing row number: 1160000\n",
      "Processing row number: 1170000\n",
      "Processing row number: 1180000\n",
      "Processing row number: 1190000\n",
      "Processing row number: 1200000\n",
      "Processing row number: 1210000\n",
      "Processing row number: 1220000\n",
      "Processing row number: 1230000\n",
      "Processing row number: 1240000\n",
      "Processing row number: 1250000\n",
      "Processing row number: 1260000\n",
      "Processing row number: 1270000\n",
      "Processing row number: 1280000\n",
      "Processing row number: 1290000\n",
      "Processing row number: 1300000\n",
      "Processing row number: 1310000\n",
      "Processing row number: 1320000\n",
      "Processing row number: 1330000\n",
      "Processing row number: 1340000\n",
      "Processing row number: 1350000\n",
      "Processing row number: 1360000\n",
      "Processing row number: 1370000\n",
      "Processing row number: 1380000\n",
      "Processing row number: 1390000\n",
      "Processing row number: 1400000\n",
      "Processing row number: 1410000\n",
      "Processing row number: 1420000\n",
      "Processing row number: 1430000\n",
      "Processing row number: 1440000\n",
      "Processing row number: 1450000\n",
      "Processing row number: 1460000\n",
      "Processing row number: 1470000\n",
      "Processing row number: 1480000\n",
      "Processing row number: 1490000\n",
      "Processing row number: 1500000\n",
      "Processing row number: 1510000\n",
      "Processing row number: 1520000\n",
      "Processing row number: 1530000\n",
      "Processing row number: 1540000\n",
      "Processing row number: 1550000\n",
      "Processing row number: 1560000\n",
      "Processing row number: 1570000\n",
      "Processing row number: 1580000\n",
      "Processing row number: 1590000\n",
      "Processing row number: 1600000\n",
      "Processing row number: 1610000\n",
      "Processing row number: 1620000\n",
      "Processing row number: 1630000\n",
      "Processing row number: 1640000\n",
      "Processing row number: 1650000\n",
      "Processing row number: 1660000\n",
      "Processing row number: 1670000\n",
      "Processing row number: 1680000\n",
      "Processing row number: 1690000\n",
      "Processing row number: 1700000\n",
      "Processing row number: 1710000\n",
      "Processing row number: 1720000\n",
      "Processing row number: 1730000\n",
      "Processing row number: 1740000\n",
      "Processing row number: 1750000\n",
      "Processing row number: 1760000\n",
      "Processing row number: 1770000\n",
      "Processing row number: 1780000\n",
      "Processing row number: 1790000\n",
      "Processing row number: 1800000\n",
      "Processing row number: 1810000\n",
      "Processing row number: 1820000\n",
      "Processing row number: 1830000\n",
      "Processing row number: 1840000\n",
      "Processing row number: 1850000\n",
      "Processing row number: 1860000\n",
      "Processing row number: 1870000\n",
      "Processing row number: 1880000\n",
      "Processing row number: 1890000\n",
      "Processing row number: 1900000\n",
      "Processing row number: 1910000\n",
      "Processing row number: 1920000\n",
      "Processing row number: 1930000\n",
      "Processing row number: 1940000\n",
      "Processing row number: 1950000\n",
      "Processing row number: 1960000\n",
      "Processing row number: 1970000\n",
      "Processing row number: 1980000\n",
      "Processing row number: 1990000\n",
      "Processing row number: 2000000\n",
      "Processing row number: 2010000\n",
      "Processing row number: 2020000\n",
      "Processing row number: 2030000\n",
      "Processing row number: 2040000\n",
      "Processing row number: 2050000\n",
      "Processing row number: 2060000\n",
      "Processing row number: 2070000\n",
      "Processing row number: 2080000\n",
      "Processing row number: 2090000\n",
      "Processing row number: 2100000\n",
      "Processing row number: 2110000\n",
      "Processing row number: 2120000\n",
      "Processing row number: 2130000\n",
      "Processing row number: 2140000\n",
      "Processing row number: 2150000\n",
      "Processing row number: 2160000\n",
      "Processing row number: 2170000\n",
      "Processing row number: 2180000\n",
      "Processing row number: 2190000\n",
      "Processing row number: 2200000\n",
      "Processing row number: 2210000\n",
      "Processing row number: 2220000\n",
      "Processing row number: 2230000\n",
      "Processing row number: 2240000\n",
      "Processing row number: 2250000\n",
      "Processing row number: 2260000\n",
      "Processing row number: 2270000\n",
      "Processing row number: 2280000\n",
      "Processing row number: 2290000\n",
      "Processing row number: 2300000\n",
      "Processing row number: 2310000\n",
      "Processing row number: 2320000\n",
      "Processing row number: 2330000\n",
      "Processing row number: 2340000\n",
      "Processing row number: 2350000\n",
      "Processing row number: 2360000\n",
      "Processing row number: 2370000\n",
      "Processing row number: 2380000\n",
      "Processing row number: 2390000\n",
      "Processing row number: 2400000\n",
      "Processing row number: 2410000\n",
      "Processing row number: 2420000\n",
      "Processing row number: 2430000\n",
      "Processing row number: 2440000\n",
      "Processing row number: 2450000\n",
      "Processing row number: 2460000\n",
      "Processing row number: 2470000\n",
      "Processing row number: 2480000\n",
      "Processing row number: 2490000\n",
      "Processing row number: 2500000\n",
      "Processing row number: 2510000\n",
      "Processing row number: 2520000\n",
      "Processing row number: 2530000\n",
      "Processing row number: 2540000\n",
      "Processing row number: 2550000\n",
      "Processing row number: 2560000\n",
      "Processing row number: 2570000\n",
      "Processing row number: 2580000\n",
      "Processing row number: 2590000\n",
      "Processing row number: 2600000\n",
      "Processing row number: 2610000\n",
      "Processing row number: 2620000\n",
      "Processing row number: 2630000\n",
      "Processing row number: 2640000\n",
      "Processing row number: 2650000\n",
      "Processing row number: 2660000\n",
      "Processing row number: 2670000\n",
      "Processing row number: 2680000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing row number: 2690000\n",
      "Processing row number: 2700000\n",
      "Processing row number: 2710000\n",
      "Processing row number: 2720000\n",
      "Processing row number: 2730000\n",
      "Processing row number: 2740000\n",
      "Processing row number: 2750000\n",
      "Processing row number: 2760000\n",
      "Processing row number: 2770000\n",
      "Processing row number: 2780000\n",
      "Processing row number: 2790000\n",
      "Processing row number: 2800000\n",
      "Processing row number: 2810000\n",
      "Processing row number: 2820000\n",
      "Processing row number: 2830000\n",
      "Processing row number: 2840000\n",
      "Processing row number: 2850000\n",
      "Processing row number: 2860000\n",
      "Processing row number: 2870000\n",
      "Processing row number: 2880000\n",
      "Processing row number: 2890000\n",
      "Processing row number: 2900000\n",
      "Processing row number: 2910000\n",
      "Processing row number: 2920000\n",
      "Processing row number: 2930000\n",
      "Processing row number: 2940000\n",
      "Processing row number: 2950000\n",
      "Processing row number: 2960000\n",
      "Processing row number: 2970000\n",
      "Processing row number: 2980000\n",
      "Processing row number: 2990000\n",
      "Processing row number: 3000000\n",
      "Processing row number: 3010000\n",
      "Processing row number: 3020000\n",
      "Processing row number: 3030000\n",
      "Processing row number: 3040000\n",
      "Processing row number: 3050000\n",
      "Processing row number: 3060000\n",
      "Processing row number: 3070000\n",
      "Processing row number: 3080000\n",
      "Processing row number: 3090000\n",
      "Processing row number: 3100000\n",
      "Processing row number: 3110000\n",
      "Processing row number: 3120000\n",
      "Processing row number: 3130000\n",
      "Processing row number: 3140000\n",
      "Processing row number: 3150000\n",
      "Processing row number: 3160000\n",
      "Processing row number: 3170000\n",
      "Processing row number: 3180000\n",
      "Processing row number: 3190000\n",
      "Processing row number: 3200000\n",
      "Processing row number: 3210000\n",
      "Processing row number: 3220000\n",
      "Processing row number: 3230000\n",
      "Processing row number: 3240000\n",
      "Processing row number: 3250000\n",
      "Processing row number: 3260000\n",
      "Processing row number: 3270000\n",
      "Processing row number: 3280000\n",
      "Processing row number: 3290000\n",
      "Processing row number: 3300000\n",
      "Processing row number: 3310000\n",
      "Processing row number: 3320000\n",
      "Processing row number: 3330000\n",
      "Processing row number: 3340000\n",
      "Processing row number: 3350000\n",
      "Processing row number: 3360000\n",
      "Processing row number: 3370000\n",
      "Processing row number: 3380000\n",
      "Processing row number: 3390000\n",
      "Processing row number: 3400000\n",
      "Processing row number: 3410000\n",
      "Processing row number: 3420000\n",
      "Processing row number: 3430000\n",
      "Processing row number: 3440000\n",
      "Processing row number: 3450000\n",
      "Processing row number: 3460000\n",
      "Processing row number: 3470000\n",
      "Processing row number: 3480000\n",
      "Processing row number: 3490000\n",
      "Processing row number: 3500000\n",
      "Processing row number: 3510000\n",
      "Processing row number: 3520000\n",
      "Processing row number: 3530000\n",
      "Processing row number: 3540000\n",
      "Processing row number: 3550000\n",
      "Processing row number: 3560000\n",
      "Processing row number: 3570000\n",
      "Processing row number: 3580000\n",
      "Processing row number: 3590000\n",
      "Processing row number: 3600000\n",
      "Processing row number: 3610000\n",
      "Processing row number: 3620000\n",
      "Processing row number: 3630000\n",
      "Processing row number: 3640000\n",
      "Processing row number: 3650000\n",
      "Processing row number: 3660000\n",
      "Processing row number: 3670000\n",
      "Processing row number: 3680000\n",
      "Processing row number: 3690000\n",
      "Processing row number: 3700000\n",
      "Processing row number: 3710000\n",
      "Processing row number: 3720000\n",
      "Processing row number: 3730000\n",
      "Processing row number: 3740000\n",
      "Processing row number: 3750000\n",
      "Processing row number: 3760000\n",
      "Processing row number: 3770000\n",
      "Processing row number: 3780000\n",
      "Processing row number: 3790000\n",
      "Processing row number: 3800000\n",
      "Processing row number: 3810000\n",
      "Processing row number: 3820000\n",
      "Processing row number: 3830000\n",
      "Processing row number: 3840000\n",
      "Processing row number: 3850000\n",
      "Processing row number: 3860000\n",
      "Processing row number: 3870000\n",
      "Processing row number: 3880000\n",
      "Processing row number: 3890000\n",
      "Processing row number: 3900000\n",
      "Processing row number: 3910000\n",
      "Processing row number: 3920000\n",
      "Processing row number: 3930000\n",
      "Processing row number: 3940000\n",
      "Processing row number: 3950000\n",
      "Processing row number: 3960000\n",
      "Processing row number: 3970000\n",
      "Processing row number: 3980000\n",
      "Processing row number: 3990000\n",
      "Processing row number: 4000000\n",
      "Processing row number: 4010000\n",
      "Processing row number: 4020000\n",
      "Processing row number: 4030000\n",
      "Processing row number: 4040000\n",
      "Processing row number: 4050000\n",
      "Processing row number: 4060000\n",
      "Processing row number: 4070000\n",
      "Processing row number: 4080000\n"
     ]
    }
   ],
   "source": [
    "ref_frame_ids = nfinal_data[nfinal_data['event'].isin(['handoff', 'run', 'pass_outcome_caught'])].groupby('uniqueid')['frameId'].min()\n",
    "nfinal_data = nfinal_data.merge(ref_frame_ids.rename('ref_frameId'), on='uniqueid', how='left')\n",
    "nfinal_data = nfinal_data[nfinal_data['frameId'] >= nfinal_data['ref_frameId']]\n",
    "nfinal_data.drop([\"ref_frameId\"],axis=1, inplace=True)\n",
    "def calculate_distance(x1, y1, x2, y2):\n",
    "    return sqrt((x1 - x2)**2 + (y1 - y2)**2)\n",
    "nfinal_data['tackleOpportunity'] = False\n",
    "row_counter=0\n",
    "for unique_id in nfinal_data['uniqueid'].unique():\n",
    "    play_data = nfinal_data[nfinal_data['uniqueid'] == unique_id]\n",
    "    possession_team = play_data['possessionTeam'].iloc[0]\n",
    "    defensive_team = play_data['defensiveTeam'].iloc[0]\n",
    "    for frame_id in play_data['frameId'].unique():\n",
    "        frame_data = play_data[play_data['frameId'] == frame_id]\n",
    "        ball_carrier_row = frame_data[frame_data['nflId'] == frame_data['ballCarrierId'].iloc[0]]\n",
    "        if not ball_carrier_row.empty:\n",
    "            ball_carrier_x = ball_carrier_row['x'].iloc[0] \n",
    "            ball_carrier_y = ball_carrier_row['y'].iloc[0]\n",
    "            defenders = frame_data[frame_data['club'] == defensive_team]\n",
    "            for _, defender in defenders.iterrows():\n",
    "                row_counter += 1  \n",
    "                if(row_counter % 10000==0):\n",
    "                    print(f\"Processing row number: {row_counter}\")\n",
    "                distance = calculate_distance(ball_carrier_x, ball_carrier_y, defender['x'], defender['y'])\n",
    "                if distance <= 2.5:\n",
    "                    nfinal_data.loc[(nfinal_data['uniqueid'] == unique_id) & (nfinal_data['frameId'] == frame_id) &\n",
    "                                       (nfinal_data['nflId']== defender['nflId']), 'tackleOpportunity'] = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2d5b910b",
   "metadata": {},
   "outputs": [],
   "source": [
    "nfinal_data['tackleOpportunity'] = nfinal_data['tackleOpportunity'].astype(int)\n",
    "defenders_df = nfinal_data[nfinal_data['club'] == nfinal_data['defensiveTeam']]\n",
    "defender_tackle_opportunities = defenders_df.groupby(['frameId', 'uniqueid']).agg({'tackleOpportunity': 'sum'}).rename(columns={'tackleOpportunity': 'defenderTackleOpportunities'})\n",
    "new_cmp = nfinal_data.merge(defender_tackle_opportunities, on=['frameId', 'uniqueid'], how='left')\n",
    "solo_tackle=new_cmp[new_cmp[\"defenderTackleOpportunities\"]==1]\n",
    "def identify_tackler(sub_df):\n",
    "    tackler = sub_df[sub_df['tackleOpportunity'] == 1]['nflId'].iloc[0]\n",
    "    return pd.Series({'tacklerNflId': tackler})\n",
    "tackler_df = solo_tackle.groupby(['uniqueid', 'frameId']).apply(identify_tackler).reset_index()\n",
    "solo_tackle = pd.merge(solo_tackle, tackler_df, on=['uniqueid', 'frameId'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "bd64aeb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "tackles[\"uniqueid\"]=tackles[\"gameId\"]*tackles[\"playId\"]\n",
    "tackles=tackles[(tackles[\"tackle\"]==1) | (tackles[\"assist\"]==1)]\n",
    "index_to_drop = tackles[tackles['uniqueid'] == 3799509190053].index\n",
    "tackles.drop(index_to_drop, inplace=True)\n",
    "combos=tackles[tackles[\"assist\"]==1][[\"uniqueid\",\"nflId\"]].drop_duplicates()\n",
    "tackles=tackles[tackles[\"tackle\"]==1]\n",
    "tackles.drop([\"tackle\",\"gameId\",\"playId\",\"assist\",\"forcedFumble\",\"pff_missedTackle\"],axis=1, inplace=True)\n",
    "solo_tackle = pd.merge(solo_tackle, tackles, on='uniqueid', how='left')\n",
    "solo_tackle['nflId_y'].fillna(0, inplace=True)\n",
    "solo_tackle['tackleMade'] = (solo_tackle['nflId_y'] == solo_tackle['tacklerNflId']).astype(int)\n",
    "solo_tackle.drop([\"nflId_y\"],axis=1,inplace=True)\n",
    "solo_tackle=solo_tackle.sort_values(by=[\"uniqueid\",\"frameId\"])\n",
    "solo_tackle.drop([\"defenderTackleOpportunities\"],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "07040c80",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/0b/4q6tccn90zd2mrdvjhd77ydm0000gn/T/ipykernel_1121/2934679995.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  ntrial['startTackleOpportunity'] = 0\n"
     ]
    }
   ],
   "source": [
    "trial=solo_tackle\n",
    "ntrial=trial[trial[\"tackleOpportunity\"]==1]\n",
    "ntrial.reset_index(drop=True, inplace=True)\n",
    "ntrial['startTackleOpportunity'] = 0\n",
    "ntrial.at[0, 'startTackleOpportunity'] = 1\n",
    "for i in range(1, len(ntrial)):\n",
    "    if (ntrial.at[i, 'nflId_x'] == ntrial.at[i - 1, 'nflId_x']) and \\\n",
    "       (ntrial.at[i, 'uniqueid'] == ntrial.at[i - 1, 'uniqueid']) and \\\n",
    "       (ntrial.at[i, 'frameId'] == ntrial.at[i - 1, 'frameId'] + 1):\n",
    "        ntrial.at[i, 'startTackleOpportunity'] = 0\n",
    "    else:\n",
    "        ntrial.at[i, 'startTackleOpportunity'] = 1\n",
    "ntrial_filtered = ntrial[ntrial['startTackleOpportunity'] == 1]\n",
    "indices = ntrial_filtered.groupby(['nflId_x', 'uniqueid'])['frameId'].idxmax()\n",
    "ntrial_filtered = ntrial_filtered.loc[indices]\n",
    "legal=ntrial_filtered[[\"frameId\",\"uniqueid\"]]\n",
    "solo_tackle_final = solo_tackle.merge(legal, on=['frameId', 'uniqueid'], how='inner')\n",
    "merged_data = solo_tackle.merge(ntrial_filtered, on=['frameId', 'uniqueid'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6f9ba486",
   "metadata": {},
   "outputs": [],
   "source": [
    "solo_tackle_final=solo_tackle_final[solo_tackle_final[\"displayName\"]!=\"football\"]\n",
    "solo_tackle_final[['x', 'y']] = solo_tackle_final[['x', 'y']].apply(pd.to_numeric, errors='coerce')\n",
    "filtered_df = pd.DataFrame()\n",
    "grouped = solo_tackle_final.groupby(['frameId', 'uniqueid'])\n",
    "for (frame, unique_id), group in grouped:\n",
    "    group = group.copy()\n",
    "    ball_carrier = group[group['nflId_x'] == group['ballCarrierId']]\n",
    "    tackler = group[group['tackleOpportunity'] == 1]\n",
    "    if not ball_carrier.empty:\n",
    "        ball_carrier_x, ball_carrier_y = ball_carrier.iloc[0][['x', 'y']]\n",
    "        group['distance_to_ball_carrier'] = ((group['x'] - ball_carrier_x) ** 2 + (group['y'] - ball_carrier_y) ** 2) ** 0.5\n",
    "        distances = group[~group['nflId_x'].isin(ball_carrier['nflId_x']) & ~group['nflId_x'].isin(tackler['nflId_x'])]\n",
    "        closest_players = distances.nsmallest(3, 'distance_to_ball_carrier')\n",
    "        frame_filtered = pd.concat([ball_carrier, tackler, closest_players])\n",
    "        filtered_df = pd.concat([filtered_df, frame_filtered])\n",
    "filtered_df.reset_index(drop=True, inplace=True)\n",
    "data_final=filtered_df\n",
    "data_final.drop([\"playDirection\",\"defenseWinProbability\",\"tackleOpportunity\"],axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "703aa72c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_seconds(time_str):\n",
    "    if pd.isna(time_str): \n",
    "        return None\n",
    "    minutes, seconds = map(int, time_str.split(':'))\n",
    "    return minutes * 60 + seconds\n",
    "data_final['gameClock'] = data_final['gameClock'].apply(convert_to_seconds)\n",
    "data_final = data_final.merge(players[['nflId', 'height', 'weight']], left_on='ballCarrierId', right_on='nflId', how='left')\n",
    "data_final.rename(columns={'height': 'ballCarrierHeight', 'weight': 'ballCarrierWeight'}, inplace=True)\n",
    "data_final.drop(columns='nflId', inplace=True)\n",
    "data_final = data_final.merge(players[['nflId', 'height', 'weight']], left_on='tacklerNflId', right_on='nflId', how='left')\n",
    "data_final.rename(columns={'height': 'tacklerHeight', 'weight': 'tacklerWeight'}, inplace=True)\n",
    "data_final.drop(columns='nflId', inplace=True)\n",
    "def convert_height_to_inches(height):\n",
    "    feet, inches = height.split('-')\n",
    "    return int(feet) * 12 + int(inches)\n",
    "data_final['tacklerHeight'] = data_final['tacklerHeight'].apply(convert_height_to_inches)\n",
    "data_final['ballCarrierHeight'] = data_final['ballCarrierHeight'].apply(convert_height_to_inches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "id": "f16fc817",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_final['side'] = data_final.apply(lambda row: 'offense' if row['club'] == row['possessionTeam'] else 'defense', axis=1)\n",
    "data_final.drop([\"displayName\",\"nflId_x\",\"club\",\"event\",\"possessionTeam\",\"defensiveTeam\",\"distance_to_ball_carrier\"],axis=1, inplace=True)\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "labelencoder=LabelEncoder()\n",
    "data_final[\"offenseFormation\"]=labelencoder.fit_transform(data_final[\"offenseFormation\"])\n",
    "data_final[\"side\"]=labelencoder.fit_transform(data_final[\"side\"])\n",
    "data_final['idx'] = data_final.groupby(['uniqueid','frameId']).cumcount() + 1\n",
    "pivot_df = data_final.pivot(index=['uniqueid','frameId','week_x','ballCarrierId','absoluteYardlineNumber','AbsolutePostPlay',\n",
    "                                   'quarter','down','yardsToGo',\n",
    "                                   'offenseScore','defenseScore','defendersInTheBox','offenseFormation',\"expectedPoints\",\n",
    "                                   'passProbability','offenseWinProbability','gameClock',\n",
    "                                  'tacklerHeight','tacklerWeight','ballCarrierHeight','ballCarrierWeight',\n",
    "                                  'tacklerNflId','tackleMade'], columns='idx')\n",
    "pivot_df.columns = [f'{col[0]}{col[1]}' for col in pivot_df.columns]\n",
    "pivot_df.reset_index(inplace=True)\n",
    "combos.rename(columns={\"nflId\":\"tacklerNflId\",\"uniqueid\":\"uniqueid\"},inplace=True)\n",
    "merged=pd.merge(pivot_df, combos, how=\"left\",indicator=True,on=[\"tacklerNflId\",\"uniqueid\"])\n",
    "pivot_dfnew=merged[merged[\"_merge\"]==\"left_only\"]\n",
    "pivot_dfnew.drop(columns=[\"_merge\"],inplace=True)\n",
    "\n",
    "train=pivot_dfnew[pivot_dfnew[\"week_x\"]>=5]\n",
    "test=pivot_dfnew[pivot_dfnew[\"week_x\"]<5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "aa84d5b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "week_x                    0\n",
      "absoluteYardlineNumber    0\n",
      "quarter                   0\n",
      "down                      0\n",
      "yardsToGo                 0\n",
      "offenseScore              0\n",
      "defenseScore              0\n",
      "defendersInTheBox         0\n",
      "offenseFormation          0\n",
      "expectedPoints            0\n",
      "passProbability           0\n",
      "offenseWinProbability     0\n",
      "gameClock                 0\n",
      "tacklerHeight             0\n",
      "tacklerWeight             0\n",
      "ballCarrierHeight         0\n",
      "ballCarrierWeight         0\n",
      "tackleMade                0\n",
      "x1                        0\n",
      "x2                        0\n",
      "x3                        0\n",
      "x4                        0\n",
      "x5                        0\n",
      "y1                        0\n",
      "y2                        0\n",
      "y3                        0\n",
      "y4                        0\n",
      "y5                        0\n",
      "s1                        0\n",
      "s2                        0\n",
      "s3                        0\n",
      "s4                        0\n",
      "s5                        0\n",
      "a1                        0\n",
      "a2                        0\n",
      "a3                        0\n",
      "a4                        0\n",
      "a5                        0\n",
      "dis1                      0\n",
      "dis2                      0\n",
      "dis3                      0\n",
      "dis4                      0\n",
      "dis5                      0\n",
      "o1                        0\n",
      "o2                        0\n",
      "o3                        0\n",
      "o4                        0\n",
      "o5                        0\n",
      "dir1                      0\n",
      "dir2                      0\n",
      "dir3                      0\n",
      "dir4                      0\n",
      "dir5                      0\n",
      "side1                     0\n",
      "side2                     0\n",
      "side3                     0\n",
      "side4                     0\n",
      "side5                     0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "na_count = train.isna().sum()\n",
    "pd.set_option('display.max_rows', None)\n",
    "print(na_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "9e01b18c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/0b/4q6tccn90zd2mrdvjhd77ydm0000gn/T/ipykernel_1121/1242295977.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train.drop([\"uniqueid\",\"frameId\",\"ballCarrierId\",\"tacklerNflId\",\"AbsolutePostPlay\"], axis=1, inplace=True)\n",
      "/var/folders/0b/4q6tccn90zd2mrdvjhd77ydm0000gn/T/ipykernel_1121/1242295977.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test.drop([\"uniqueid\",\"frameId\",\"ballCarrierId\",\"tacklerNflId\",\"AbsolutePostPlay\"], axis=1, inplace=True)\n"
     ]
    }
   ],
   "source": [
    "train_id=train[\"uniqueid\"].values\n",
    "train_frame=train[\"frameId\"].values\n",
    "train_carrier=train[\"ballCarrierId\"].values\n",
    "train_tackler=train[\"tacklerNflId\"].values\n",
    "test_id=test[\"uniqueid\"].values\n",
    "test_frame=test[\"frameId\"].values\n",
    "test_carrier=test[\"ballCarrierId\"].values\n",
    "test_tackler=test[\"tacklerNflId\"].values\n",
    "train.drop([\"uniqueid\",\"frameId\",\"ballCarrierId\",\"tacklerNflId\",\"AbsolutePostPlay\"], axis=1, inplace=True)\n",
    "test.drop([\"uniqueid\",\"frameId\",\"ballCarrierId\",\"tacklerNflId\",\"AbsolutePostPlay\"], axis=1, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "75d89f74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 43s, sys: 27 s, total: 2min 10s\n",
      "Wall time: 18.4 s\n",
      "Fold 1:  = 0.80\n",
      "Fold 2:  = 0.78\n",
      "Fold 3:  = 0.79\n",
      "Fold 4:  = 0.81\n",
      "Fold 5:  = 0.79\n",
      "Average SCORE: 0.79\n"
     ]
    }
   ],
   "source": [
    "y=train[\"tackleMade\"].values\n",
    "X=train.drop([\"tackleMade\"],axis=1).values\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold\n",
    "import xgboost as xgb\n",
    "\n",
    "xgb_model = xgb.XGBClassifier(\n",
    "    objective='binary:logistic', \n",
    "    eval_metric='logloss'  \n",
    ")\n",
    "param_distributions={\n",
    "    'n_estimators':randint(50,1001),\n",
    "    'learning_rate':uniform(0.01,0.59),\n",
    "    'max_depth':randint(3,11),\n",
    "    'min_child_weight':randint(1,11),\n",
    "    'subsample':uniform(0.5,0.5),\n",
    "    'colsample_bytree':uniform(0.5,0.5),\n",
    "    'gamma':uniform(0.1,0.6),\n",
    "    'reg_alpha':randint(1,8)\n",
    "}\n",
    "random_search_xgb = RandomizedSearchCV(estimator=xgb_model, param_distributions=param_distributions,n_iter=400, \n",
    "                           scoring='roc_auc', cv=5, random_state=39, n_jobs=-1, verbose=1,error_score=\"raise\")\n",
    "random_search_xgb.fit(X,y)\n",
    "# Print the best score\n",
    "print(\"Best Score:\", random_search_xgb.best_score_)\n",
    "\n",
    "# Print the best parameters\n",
    "print(\"Best Parameters:\", random_search_xgb.best_params_)\n",
    "\n",
    "kf=KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "xgb_model=xgb.XGBClassifier(\n",
    "    n_estimators=965,\n",
    "    learning_rate=0.021,\n",
    "    max_depth=9,\n",
    "    min_child_weight=2,\n",
    "    subsample=0.869,\n",
    "    colsample_bytree=0.909,\n",
    "    gamma=0.239,\n",
    "    reg_alpha=1,\n",
    "    objective='binary:logistic',\n",
    "    eval_metric='logloss'\n",
    ")\n",
    "%time scores=cross_val_score(xgb_model, X, y, cv=kf, scoring='roc_auc')\n",
    "for i, score in enumerate(scores):\n",
    "    print(f'Fold {i+1}:  = {score:.2f}')\n",
    "avg_score = np.mean(scores)\n",
    "print(f'Average SCORE: {avg_score:.2f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "edc1fb87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2min 7s, sys: 900 ms, total: 2min 8s\n",
      "Wall time: 2min 8s\n",
      "Fold 1:  = 0.79\n",
      "Fold 2:  = 0.78\n",
      "Fold 3:  = 0.79\n",
      "Fold 4:  = 0.80\n",
      "Fold 5:  = 0.79\n",
      "Average SCORE: 0.79\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rf_model = RandomForestClassifier(random_state=42, n_jobs=-1)\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from scipy.stats import uniform, randint\n",
    "\n",
    "param_distributions = {\n",
    "    'n_estimators': randint(50, 1001),\n",
    "    'max_depth': randint(10, 100),\n",
    "    'min_samples_split': randint(2, 11),\n",
    "    'min_samples_leaf': randint(1, 11),\n",
    "    'bootstrap': [True, False],\n",
    "}\n",
    "random_search_rf = RandomizedSearchCV(\n",
    "    estimator=rf_model, \n",
    "    param_distributions=param_distributions,\n",
    "    n_iter=50, \n",
    "    scoring='roc_auc',\n",
    "    cv=5, \n",
    "    random_state=30, \n",
    "    n_jobs=-1, \n",
    "    verbose=1\n",
    ")\n",
    "%time random_search_rf.fit(X,y)\n",
    "# Print the best score\n",
    "print(\"Best Score:\", random_search_rf.best_score_)\n",
    "\n",
    "# Print the best parameters\n",
    "print(\"Best Parameters:\", random_search_rf.best_params_)\n",
    "\n",
    "np.random.seed(42)\n",
    "kf=KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "rf_model = RandomForestClassifier(bootstrap=False, min_samples_leaf=4, min_samples_split=9, n_estimators=937,random_state=42, max_depth=27,\n",
    "                                 )\n",
    "%time scores=cross_val_score(rf_model, X, y, cv=kf, scoring='roc_auc')\n",
    "for i, score in enumerate(scores):\n",
    "    print(f'Fold {i+1}:  = {score:.2f}')\n",
    "avg_score = np.mean(scores)\n",
    "print(f'Average SCORE: {avg_score:.2f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "c4ec2275",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 19.4 s, sys: 7.36 s, total: 26.7 s\n",
      "Wall time: 7.09 s\n",
      "Fold 1:  = 0.79\n",
      "Fold 2:  = 0.78\n",
      "Fold 3:  = 0.80\n",
      "Fold 4:  = 0.81\n",
      "Fold 5:  = 0.80\n",
      "Average SCORE: 0.80\n"
     ]
    }
   ],
   "source": [
    "from catboost import CatBoostClassifier\n",
    "cat_model = CatBoostClassifier(random_state=42, verbose=0)\n",
    "\n",
    "param_distributions = {\n",
    "    'learning_rate': uniform(0, 1),\n",
    "    'depth': randint(4, 10),\n",
    "    'l2_leaf_reg': uniform(0, 10),\n",
    "    'n_estimators': randint(100, 1001),\n",
    "    'border_count': randint(32, 255),\n",
    "    'min_data_in_leaf': randint(1, 50),\n",
    "    'bagging_temperature': uniform(0, 1),\n",
    "    'random_strength': randint(1, 20),\n",
    "}\n",
    "random_search_cat = RandomizedSearchCV(\n",
    "    estimator=cat_model, \n",
    "    param_distributions=param_distributions,\n",
    "    n_iter=200, \n",
    "    scoring='roc_auc',  # Change scoring if needed\n",
    "    cv=5, \n",
    "    random_state=38, \n",
    "    n_jobs=-1, \n",
    "    verbose=1,\n",
    "    error_score=\"raise\"\n",
    ")\n",
    "%time random_search_cat.fit(X, y)\n",
    "\n",
    "# Print the best score\n",
    "print(\"Best Score:\", random_search_cat.best_score_)\n",
    "\n",
    "# Print the best parameters\n",
    "print(\"Best Parameters:\", random_search_cat.best_params_)\n",
    "\n",
    "np.random.seed(42)\n",
    "cat_model = CatBoostClassifier(iterations=612,\n",
    "                          learning_rate=0.030,\n",
    "                          depth=6,\n",
    "                          eval_metric='Logloss',\n",
    "                          random_seed=35,\n",
    "                          bagging_temperature=0.743,\n",
    "                          border_count=99,\n",
    "                          l2_leaf_reg=9.279,\n",
    "                          min_data_in_leaf=19,\n",
    "                          random_strength=11,\n",
    "                          od_type='Iter',\n",
    "                          metric_period=50,\n",
    "                          od_wait=20,verbose=0\n",
    "                        )\n",
    "%time scores=cross_val_score(cat_model, X, y, cv=kf, scoring='roc_auc',error_score=\"raise\")\n",
    "for i, score in enumerate(scores):\n",
    "    print(f'Fold {i+1}:  = {score:.2f}')\n",
    "avg_score = np.mean(scores)\n",
    "print(f'Average SCORE: {avg_score:.2f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "d833234e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 6min 57s, sys: 1.56 s, total: 6min 59s\n",
      "Wall time: 6min 59s\n",
      "Fold 1:  = 0.80\n",
      "Fold 2:  = 0.78\n",
      "Fold 3:  = 0.79\n",
      "Fold 4:  = 0.81\n",
      "Fold 5:  = 0.78\n",
      "Average SCORE: 0.79\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "gdbt_model = GradientBoostingClassifier(random_state=42, verbose=0)\n",
    "\n",
    "param_distributions = {\n",
    "    'learning_rate': uniform(0.01, 0.3),\n",
    "    'max_depth': randint(3, 10),\n",
    "    'min_samples_split':randint(2,20), \n",
    "    'n_estimators': randint(100, 1001),\n",
    "    'min_samples_leaf': randint(1, 20),\n",
    "}\n",
    "random_search_gdbt = RandomizedSearchCV(\n",
    "    estimator=gdbt_model, \n",
    "    param_distributions=param_distributions,\n",
    "    n_iter=25, \n",
    "    scoring='roc_auc', \n",
    "    cv=5, \n",
    "    random_state=34, \n",
    "    n_jobs=-1, \n",
    "    verbose=1,\n",
    "    error_score=\"raise\"\n",
    ")\n",
    "\n",
    "%time random_search_gdbt.fit(X, y)\n",
    "# Print the best score\n",
    "print(\"Best Score:\", random_search_gdbt.best_score_)\n",
    "\n",
    "# Print the best parameters\n",
    "print(\"Best Parameters:\", random_search_gdbt.best_params_)\n",
    "\n",
    "np.random.seed(25)\n",
    "gdbt_model = GradientBoostingClassifier(learning_rate=0.02, max_depth=8, min_samples_leaf=18, min_samples_split=3, \n",
    "                    n_estimators=617, verbose=0)\n",
    "%time scores=cross_val_score(gdbt_model, X, y, cv=kf, scoring='roc_auc',error_score=\"raise\")\n",
    "for i, score in enumerate(scores):\n",
    "    print(f'Fold {i+1}:  = {score:.2f}')\n",
    "avg_score = np.mean(scores)\n",
    "print(f'Average SCORE: {avg_score:.2f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "d78da295",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.04 s, sys: 7.25 ms, total: 1.04 s\n",
      "Wall time: 1.05 s\n",
      "Fold 1:  = 0.74\n",
      "Fold 2:  = 0.72\n",
      "Fold 3:  = 0.73\n",
      "Fold 4:  = 0.74\n",
      "Fold 5:  = 0.74\n",
      "Average SCORE: 0.73\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "extra_model = ExtraTreesClassifier(random_state=33)\n",
    "\n",
    "param_distributions={\n",
    "    \"n_estimators\":randint(100,1000),\n",
    "    \"min_samples_split\":randint(2,20),\n",
    "    \"min_samples_leaf\":randint(1,20),\n",
    "    \"min_weight_fraction_leaf\":uniform(0,0.5),\n",
    "    \"min_impurity_decrease\":uniform(0,1),\n",
    "}\n",
    "random_search_ext = RandomizedSearchCV(estimator=extra_model, param_distributions=param_distributions,n_iter=500, \n",
    "                           scoring='roc_auc', cv=5, random_state=35, n_jobs=-1, verbose=1,error_score=\"raise\")\n",
    "%time random_search_ext.fit(X,y)\n",
    "# Print the best score\n",
    "print(\"Best Score:\", random_search_ext.best_score_)\n",
    "\n",
    "# Print the best parameters\n",
    "print(\"Best Parameters:\", random_search_ext.best_params_)\n",
    "\n",
    "np.random.seed(34)\n",
    "ext_model = ExtraTreesClassifier(min_impurity_decrease=0.0174,min_samples_leaf=16,min_samples_split=9, \n",
    "                                 min_weight_fraction_leaf=0.1243, n_estimators=272,verbose=0)\n",
    "%time scores=cross_val_score(ext_model, X, y, cv=kf, scoring='roc_auc',error_score=\"raise\")\n",
    "for i, score in enumerate(scores):\n",
    "    print(f'Fold {i+1}:  = {score:.2f}')\n",
    "avg_score = np.mean(scores)\n",
    "print(f'Average SCORE: {avg_score:.2f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "a64df984",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 24.7 s, sys: 353 ms, total: 25.1 s\n",
      "Wall time: 25.2 s\n",
      "Fold 1:  = 0.71\n",
      "Fold 2:  = 0.71\n",
      "Fold 3:  = 0.75\n",
      "Fold 4:  = 0.73\n",
      "Fold 5:  = 0.72\n",
      "Average SCORE: 0.73\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "np.random.seed(34)\n",
    "svm_model = SVC(kernel=\"poly\",probability=True)\n",
    "%time scores=cross_val_score(svm_model, X, y, cv=kf, scoring='roc_auc',error_score=\"raise\")\n",
    "for i, score in enumerate(scores):\n",
    "    print(f'Fold {i+1}:  = {score:.2f}')\n",
    "avg_score = np.mean(scores)\n",
    "print(f'Average SCORE: {avg_score:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "f87225c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.54 s, sys: 823 ms, total: 3.36 s\n",
      "Wall time: 499 ms\n",
      "Fold 1:  = 0.68\n",
      "Fold 2:  = 0.68\n",
      "Fold 3:  = 0.71\n",
      "Fold 4:  = 0.70\n",
      "Fold 5:  = 0.69\n",
      "Average SCORE: 0.69\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "np.random.seed(34)\n",
    "knn_model = KNeighborsClassifier(n_neighbors=70)\n",
    "%time scores=cross_val_score(knn_model, X, y, cv=kf, scoring='roc_auc',error_score=\"raise\")\n",
    "for i, score in enumerate(scores):\n",
    "    print(f'Fold {i+1}:  = {score:.2f}')\n",
    "avg_score = np.mean(scores)\n",
    "print(f'Average SCORE: {avg_score:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "2bdf5031",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2min 42s, sys: 3.48 s, total: 2min 45s\n",
      "Wall time: 22.6 s\n",
      "Fold 1:  = 0.76\n",
      "Fold 2:  = 0.75\n",
      "Fold 3:  = 0.77\n",
      "Fold 4:  = 0.78\n",
      "Fold 5:  = 0.77\n",
      "Average SCORE: 0.77\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "np.random.seed(40)\n",
    "log_model = LogisticRegression(max_iter=10000)\n",
    "%time scores=cross_val_score(log_model, X, y, cv=kf, scoring='roc_auc',error_score=\"raise\")\n",
    "for i, score in enumerate(scores):\n",
    "    print(f'Fold {i+1}:  = {score:.2f}')\n",
    "avg_score = np.mean(scores)\n",
    "print(f'Average SCORE: {avg_score:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "7bc39af5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1h 3min 53s, sys: 1min 24s, total: 1h 5min 17s\n",
      "Wall time: 4h 5min 34s\n",
      "Fold 1:  = 0.75\n",
      "Fold 2:  = 0.76\n",
      "Fold 3:  = 0.77\n",
      "Fold 4:  = 0.78\n",
      "Fold 5:  = 0.77\n",
      "Average SCORE: 0.77\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import StackingClassifier\n",
    "base_models=[\n",
    "    ('RandomForest',rf_model),(\"Catboost\",cat_model),\n",
    "    ('GDBT',gdbt_model),('Ett',extra_model),('SVM',svm_model),('KNN',knn_model),('Logistic',log_model)\n",
    "]\n",
    "stack_clf = StackingClassifier(\n",
    "     estimators=base_models,\n",
    "    final_estimator=xgb_model\n",
    ")\n",
    "%time scores=cross_val_score(stack_clf, X, y, cv=kf, scoring='roc_auc',error_score=\"raise\")\n",
    "for i, score in enumerate(scores):\n",
    "    print(f'Fold {i+1}:  = {score:.2f}')\n",
    "avg_score = np.mean(scores)\n",
    "print(f'Average SCORE: {avg_score:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "id": "55f042c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/0b/4q6tccn90zd2mrdvjhd77ydm0000gn/T/ipykernel_1121/4048281898.py:21: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test[\"tackleProbability\"]=prob\n"
     ]
    }
   ],
   "source": [
    "\n",
    "clf1=xgb_model.fit(X,y)\n",
    "clf2=rf_model.fit(X,y)\n",
    "clf3=cat_model.fit(X,y)\n",
    "clf4=gdbt_model.fit(X,y)\n",
    "clf5=extra_model.fit(X,y)\n",
    "clf6=svm_model.fit(X,y)\n",
    "clf7=knn_model.fit(X,y)\n",
    "clf8=log_model.fit(X,y)\n",
    "weights=[0.2, 0.15, 0.2, 0.1, 0.05,0.05,0.05, 0.2]\n",
    "\n",
    "y_test=test[\"tackleMade\"].values\n",
    "X_test=test.drop([\"tackleMade\"], axis=1).values\n",
    "predictions = np.array([clf1.predict_proba(X_test), clf2.predict_proba(X_test), clf3.predict_proba(X_test),\n",
    "                       clf4.predict_proba(X_test), clf5.predict_proba(X_test),clf6.predict_proba(X_test),\n",
    "                       clf7.predict_proba(X_test), clf8.predict_proba(X_test)])\n",
    "weighted_predictions = np.tensordot(predictions, weights, axes=((0),(0)))\n",
    "final_probabilities = weighted_predictions / weighted_predictions.sum(axis=1, keepdims=True)\n",
    "prob=final_probabilities[:,1]\n",
    "\n",
    "test[\"tackleProbability\"]=prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "id": "bfe523b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC AUC Score: 0.7355629689486061\n",
      "Accuracy: 0.7445147989986747\n",
      "F1 Score: 0.692321333569782\n",
      "ROC AUC Score for Probability: 0.8127177930598933\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/0b/4q6tccn90zd2mrdvjhd77ydm0000gn/T/ipykernel_1121/1003676240.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test[\"predictions\"]=predictions\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score, accuracy_score, f1_score\n",
    "predictions=np.where(prob>=0.5,1,0)\n",
    "test[\"predictions\"]=predictions\n",
    "roc_auc = roc_auc_score(y_test, predictions)\n",
    "print(f'ROC AUC Score: {roc_auc}')\n",
    "accuracy = accuracy_score(y_test, predictions)\n",
    "print(f'Accuracy: {accuracy}')\n",
    "f1 = f1_score(y_test, predictions)\n",
    "print(f'F1 Score: {f1}')\n",
    "roc_auc = roc_auc_score(y_test, prob)\n",
    "print(f'ROC AUC Score for Probability: {roc_auc}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "2e562e8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                             Model  ROC-AUC Score  Training Time(Seconds)\n",
      "0                          XGBoost           0.79                  22.700\n",
      "1                    Random Forest           0.79                 141.000\n",
      "2                         CatBoost           0.80                   7.890\n",
      "3  Gradient Boosting Decision Tree           0.79                 448.000\n",
      "4                      Extra Trees           0.73                   1.430\n",
      "5           Support Vector Machine           0.73                  26.400\n",
      "6               K-Nearest Neighbor           0.69                   0.494\n",
      "7              Logistic Regression           0.77                 149.000\n",
      "8               Stacked Classifier           0.77                3863.000\n",
      "9    Weighted Classifier(Selected)           0.81                 756.000\n"
     ]
    }
   ],
   "source": [
    "table={'Model': [\"XGBoost\",\"Random Forest\",\"CatBoost\",\"Gradient Boosting Decision Tree\",\"Extra Trees\",\"Support Vector Machine\",\"K-Nearest Neighbor\",\"Logistic Regression\",\"Stacked Classifier\",\"Weighted Classifier(Selected)\"],\n",
    "      'ROC-AUC Score':[0.79,0.79,0.80,0.79,0.73,0.73,0.69,0.77,0.77,0.81],\n",
    "      'Training Time(Seconds)':[22.7,141,7.89,448,1.43,26.4,0.494,149,3863,756]}\n",
    "print(pd.DataFrame(table))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "574bc00d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3104,  797],\n",
       "       [ 938, 1952]])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "confusion_mat = confusion_matrix(y_test, predictions)\n",
    "confusion_mat\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "78dda216",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   Feature  Importance\n",
      "54                   side3    0.286513\n",
      "14           tacklerWeight    0.048272\n",
      "28                      s2    0.024707\n",
      "27                      s1    0.020000\n",
      "55                   side4    0.019653\n",
      "17                      x1    0.018991\n",
      "42                      o1    0.017484\n",
      "22                      y1    0.016969\n",
      "37                    dis1    0.016023\n",
      "38                    dis2    0.015715\n",
      "18                      x2    0.014125\n",
      "23                      y2    0.014104\n",
      "48                    dir2    0.014102\n",
      "47                    dir1    0.013511\n",
      "32                      a1    0.013418\n",
      "39                    dis3    0.013276\n",
      "33                      a2    0.013207\n",
      "56                   side5    0.013020\n",
      "15       ballCarrierHeight    0.012853\n",
      "34                      a3    0.012160\n",
      "49                    dir3    0.012134\n",
      "26                      y5    0.012120\n",
      "29                      s3    0.012006\n",
      "43                      o2    0.011870\n",
      "24                      y3    0.011749\n",
      "10         passProbability    0.011552\n",
      "9           expectedPoints    0.011388\n",
      "19                      x3    0.011382\n",
      "41                    dis5    0.011307\n",
      "25                      y4    0.011260\n",
      "35                      a4    0.011256\n",
      "1   absoluteYardlineNumber    0.011181\n",
      "21                      x5    0.011034\n",
      "2                  quarter    0.011009\n",
      "50                    dir4    0.010950\n",
      "6             defenseScore    0.010942\n",
      "46                      o5    0.010898\n",
      "3                     down    0.010789\n",
      "44                      o3    0.010787\n",
      "31                      s5    0.010729\n",
      "13           tacklerHeight    0.010722\n",
      "4                yardsToGo    0.010684\n",
      "36                      a5    0.010682\n",
      "30                      s4    0.010590\n",
      "12               gameClock    0.010518\n",
      "8         offenseFormation    0.010517\n",
      "20                      x4    0.010488\n",
      "51                    dir5    0.010427\n",
      "40                    dis4    0.010427\n",
      "7        defendersInTheBox    0.010406\n",
      "11   offenseWinProbability    0.010379\n",
      "16       ballCarrierWeight    0.010216\n",
      "45                      o4    0.010190\n",
      "0                   week_x    0.009686\n",
      "5             offenseScore    0.009621\n",
      "52                   side1    0.000000\n",
      "53                   side2    0.000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/0b/4q6tccn90zd2mrdvjhd77ydm0000gn/T/ipykernel_1121/3649974738.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train.drop([\"tackleMade\"],axis=1,inplace=True)\n"
     ]
    }
   ],
   "source": [
    "feature_importances = xgb_model.feature_importances_\n",
    "train.drop([\"tackleMade\"],axis=1,inplace=True)\n",
    "feature_names = train.columns\n",
    "importance_df = pd.DataFrame({'Feature': feature_names, 'Importance': feature_importances})\n",
    "importance_df = importance_df.sort_values(by='Importance', ascending=False)\n",
    "print(importance_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "b8aed2ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "min_ids=nfinal_data.groupby('uniqueid')[\"frameId\"].min().reset_index()\n",
    "new_final=pd.merge(nfinal_data, min_ids, on=[\"uniqueid\",\"frameId\"])\n",
    "new_final['iscarrier'] = (new_final['nflId'] == new_final['ballCarrierId']).astype(int)\n",
    "for index, row in new_final.iterrows():\n",
    "    if(row[\"club\"]==row[\"possessionTeam\"]):\n",
    "        new_final.loc[index,\"side\"]=\"Offense\"\n",
    "    else:\n",
    "        new_final.loc[index,\"side\"]=\"Defense\"\n",
    "    if(row[\"displayName\"]==\"football\"):\n",
    "        new_final.loc[index,\"side\"]=\"Football\"\n",
    "new_final.drop([\"displayName\",\"frameId\",\"club\",\"playDirection\",\"event\",\"possessionTeam\",\"defensiveTeam\",\"AbsolutePostPlay\"],axis=1,inplace=True)\n",
    "plays=plays[plays[\"playNullifiedByPenalty\"]=='N']\n",
    "plays[\"uniqueid\"]=plays[\"gameId\"]*plays[\"playId\"]\n",
    "plays=plays[['uniqueid','prePenaltyPlayResult']]\n",
    "new_final=pd.merge(new_final, plays, on=\"uniqueid\",how=\"left\")\n",
    "new_final[\"AbsolutePostPlay\"]=new_final[\"absoluteYardlineNumber\"]+new_final[\"prePenaltyPlayResult\"]\n",
    "new_final.drop([\"prePenaltyPlayResult\"],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "a9a628a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "new_final.drop([\"nflId\",\"ballCarrierId\",\"tackleOpportunity\"],axis=1,inplace=True)\n",
    "new_final['idx'] = new_final.groupby(['uniqueid']).cumcount() + 1\n",
    "new_final = new_final[~new_final['uniqueid'].isin([127391783463,3043263972035,6005641766850])]\n",
    "def calculate_distance(group):\n",
    "    ball_carrier_x = group.loc[group['iscarrier'] == 1, 'x'].iloc[0]\n",
    "    ball_carrier_y = group.loc[group['iscarrier'] == 1, 'y'].iloc[0]\n",
    "    group['distance_to_carrier'] = np.sqrt((group['x'] - ball_carrier_x) ** 2 + (group['y'] - ball_carrier_y) ** 2)\n",
    "    return group\n",
    "\n",
    "new_final = new_final.groupby('uniqueid').apply(calculate_distance).reset_index(drop=True)\n",
    "new_final['side'] = pd.Categorical(new_final['side'], categories=[\"Offense\", \"Defense\", \"Football\"], ordered=True)\n",
    "\n",
    "sorted_final = new_final.sort_values(by=['uniqueid', 'side', 'distance_to_carrier'])\n",
    "sorted_final['idx'] = sorted_final.groupby(['uniqueid']).cumcount() + 1\n",
    "sorted_final.drop([\"defenseWinProbability\",\"iscarrier\",\"side\"],axis=1,inplace=True)\n",
    "pivot_dataf = sorted_final.pivot(index=['uniqueid','week_x','absoluteYardlineNumber','AbsolutePostPlay',\n",
    "                                   'quarter','down','yardsToGo','offenseFormation','expectedPoints',\n",
    "                                   'offenseScore','defenseScore','defendersInTheBox',\n",
    "                                   'passProbability','offenseWinProbability','gameClock'], columns='idx')\n",
    "pivot_dataf.columns = [f'{col[0]}{col[1]}' for col in pivot_dataf.columns]\n",
    "pivot_dataf.reset_index(inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "91f2baf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_seconds(time_str):\n",
    "    if pd.isna(time_str): \n",
    "        return None\n",
    "    minutes, seconds = map(int, time_str.split(':'))\n",
    "    return minutes * 60 + seconds\n",
    "pivot_dataf['gameClock'] = pivot_dataf['gameClock'].apply(convert_to_seconds)\n",
    "pivot_dataf['TD'] = np.where(pivot_dataf['AbsolutePostPlay'] >= 110, 1, 0)\n",
    "pivot_dataf.drop([\"dir23\",\"o23\"],axis=1,inplace=True)\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "label_encoder=LabelEncoder()\n",
    "pivot_dataf[\"offenseFormation\"]=label_encoder.fit_transform(pivot_dataf[\"offenseFormation\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "7f67c4ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "train2=pivot_dataf[pivot_dataf[\"week_x\"]>=5]\n",
    "test2=pivot_dataf[pivot_dataf[\"week_x\"]<=4]\n",
    "y2=train2[\"TD\"].values\n",
    "X2=train2.drop([\"AbsolutePostPlay\",\"TD\",\"uniqueid\"],axis=1).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "id": "7de7a128",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 24s, sys: 21.6 s, total: 1min 46s\n",
      "Wall time: 15.2 s\n",
      "Fold 1:  = 0.92\n",
      "Fold 2:  = 0.89\n",
      "Fold 3:  = 0.94\n",
      "Fold 4:  = 0.90\n",
      "Fold 5:  = 0.93\n",
      "Average SCORE: 0.92\n"
     ]
    }
   ],
   "source": [
    "xgb_model = xgb.XGBClassifier(\n",
    "    objective='binary:logistic', \n",
    "    eval_metric='logloss'  \n",
    ")\n",
    "param_distributions={\n",
    "    'n_estimators':randint(50,1001),\n",
    "    'learning_rate':uniform(0.01,0.59),\n",
    "    'max_depth':randint(3,11),\n",
    "    'min_child_weight':randint(1,11),\n",
    "    'subsample':uniform(0.5,0.5),\n",
    "    'colsample_bytree':uniform(0.5,0.5),\n",
    "    'gamma':uniform(0.1,0.6),\n",
    "    'reg_alpha':randint(1,8)\n",
    "}\n",
    "random_search_xgb = RandomizedSearchCV(estimator=xgb_model, param_distributions=param_distributions,n_iter=400, \n",
    "                           scoring='roc_auc', cv=5, random_state=39, n_jobs=-1, verbose=1,error_score=\"raise\")\n",
    "random_search_xgb.fit(X2,y2)\n",
    "# Print the best score\n",
    "print(\"Best Score:\", random_search_xgb.best_score_)\n",
    "\n",
    "# Print the best parameters\n",
    "print(\"Best Parameters:\", random_search_xgb.best_params_)\n",
    "kf=KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "xgb_model=xgb.XGBClassifier(\n",
    "    n_estimators=965,\n",
    "    learning_rate=0.021,\n",
    "    max_depth=9,\n",
    "    min_child_weight=2,\n",
    "    subsample=0.869,\n",
    "    colsample_bytree=0.909,\n",
    "    gamma=0.239,\n",
    "    reg_alpha=1,\n",
    "    objective='binary:logistic',\n",
    "    eval_metric='logloss'\n",
    ")\n",
    "%time scores=cross_val_score(xgb_model, X22, y2, cv=kf, scoring='roc_auc')\n",
    "for i, score in enumerate(scores):\n",
    "    print(f'Fold {i+1}:  = {score:.2f}')\n",
    "avg_score = np.mean(scores)\n",
    "print(f'Average SCORE: {avg_score:.2f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "id": "cd982dc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 31s, sys: 671 ms, total: 1min 31s\n",
      "Wall time: 1min 32s\n",
      "Fold 1:  = 0.93\n",
      "Fold 2:  = 0.87\n",
      "Fold 3:  = 0.92\n",
      "Fold 4:  = 0.91\n",
      "Fold 5:  = 0.94\n",
      "Average SCORE: 0.91\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rf_model = RandomForestClassifier(random_state=42, n_jobs=-1)\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from scipy.stats import uniform, randint\n",
    "param_distributions = {\n",
    "    'n_estimators': randint(50, 1001),\n",
    "    'max_depth': randint(10, 100),\n",
    "    'min_samples_split': randint(2, 11),\n",
    "    'min_samples_leaf': randint(1, 11),\n",
    "    'bootstrap': [True, False],\n",
    "}\n",
    "random_search_rf = RandomizedSearchCV(\n",
    "    estimator=rf_model, \n",
    "    param_distributions=param_distributions,\n",
    "    n_iter=50, \n",
    "    scoring='roc_auc',\n",
    "    cv=5, \n",
    "    random_state=46, \n",
    "    n_jobs=-1, \n",
    "    verbose=1\n",
    ")\n",
    "%time random_search_rf.fit(X2,y2)\n",
    "# Print the best score\n",
    "print(\"Best Score:\", random_search_rf.best_score_)\n",
    "\n",
    "# Print the best parameters\n",
    "print(\"Best Parameters:\", random_search_rf.best_params_)\n",
    "np.random.seed(42)\n",
    "kf=KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "rf_model = RandomForestClassifier(bootstrap=False, min_samples_leaf=3, min_samples_split=9, n_estimators=460,random_state=42, max_depth=10,\n",
    "                                 )\n",
    "%time scores=cross_val_score(rf_model, X22, y2, cv=kf, scoring='roc_auc')\n",
    "for i, score in enumerate(scores):\n",
    "    print(f'Fold {i+1}:  = {score:.2f}')\n",
    "avg_score = np.mean(scores)\n",
    "print(f'Average SCORE: {avg_score:.2f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "id": "ca9b95f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 6min 48s, sys: 18.8 s, total: 7min 7s\n",
      "Wall time: 1min 7s\n",
      "Fold 1:  = 0.93\n",
      "Fold 2:  = 0.89\n",
      "Fold 3:  = 0.94\n",
      "Fold 4:  = 0.92\n",
      "Fold 5:  = 0.94\n",
      "Average SCORE: 0.92\n"
     ]
    }
   ],
   "source": [
    "from catboost import CatBoostClassifier\n",
    "cat_model = CatBoostClassifier(random_state=42, verbose=0)\n",
    "param_distributions = {\n",
    "    'learning_rate': uniform(0, 1),\n",
    "    'depth': randint(4, 10),\n",
    "    'l2_leaf_reg': uniform(0, 10),\n",
    "    'n_estimators': randint(100, 1001),\n",
    "    'border_count': randint(32, 255),\n",
    "    'min_data_in_leaf': randint(1, 50),\n",
    "    'bagging_temperature': uniform(0, 1),\n",
    "    'random_strength': randint(1, 20),\n",
    "}\n",
    "random_search_cat = RandomizedSearchCV(\n",
    "    estimator=cat_model, \n",
    "    param_distributions=param_distributions,\n",
    "    n_iter=200, \n",
    "    scoring='roc_auc',  # Change scoring if needed\n",
    "    cv=5, \n",
    "    random_state=35, \n",
    "    n_jobs=-1, \n",
    "    verbose=1,\n",
    "    error_score=\"raise\"\n",
    ")\n",
    "%time random_search_cat.fit(X2, y2)\n",
    "\n",
    "# Print the best score\n",
    "print(\"Best Score:\", random_search_cat.best_score_)\n",
    "\n",
    "# Print the best parameters\n",
    "print(\"Best Parameters:\", random_search_cat.best_params_)\n",
    "\n",
    "np.random.seed(42)\n",
    "cat_model = CatBoostClassifier(iterations=877,\n",
    "                          learning_rate=0.007,\n",
    "                          depth=8,\n",
    "                          eval_metric='Logloss',\n",
    "                          random_seed=35,\n",
    "                          bagging_temperature=0.825,\n",
    "                          border_count=187,\n",
    "                          l2_leaf_reg=6.951,\n",
    "                          min_data_in_leaf=31,\n",
    "                          random_strength=1,\n",
    "                          od_type='Iter',\n",
    "                          metric_period=50,\n",
    "                          od_wait=20,verbose=0\n",
    "                        )\n",
    "%time scores=cross_val_score(cat_model, X22, y2, cv=kf, scoring='roc_auc',error_score=\"raise\")\n",
    "for i, score in enumerate(scores):\n",
    "    print(f'Fold {i+1}:  = {score:.2f}')\n",
    "avg_score = np.mean(scores)\n",
    "print(f'Average SCORE: {avg_score:.2f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "id": "a284f25b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 10min 44s, sys: 3.23 s, total: 10min 47s\n",
      "Wall time: 10min 48s\n",
      "Fold 1:  = 0.90\n",
      "Fold 2:  = 0.87\n",
      "Fold 3:  = 0.92\n",
      "Fold 4:  = 0.91\n",
      "Fold 5:  = 0.93\n",
      "Average SCORE: 0.91\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "gdbt_model = GradientBoostingClassifier(random_state=42, verbose=0)\n",
    "param_distributions = {\n",
    "    'learning_rate': uniform(0.01, 0.3),\n",
    "    'max_depth': randint(3, 10),\n",
    "    'min_samples_split':randint(2,20), \n",
    "    'n_estimators': randint(100, 1001),\n",
    "    'min_samples_leaf': randint(1, 20),\n",
    "}\n",
    "random_search_gdbt = RandomizedSearchCV(\n",
    "    estimator=gdbt_model, \n",
    "    param_distributions=param_distributions,\n",
    "    n_iter=20, \n",
    "    scoring='roc_auc', \n",
    "    cv=5, \n",
    "    random_state=34, \n",
    "    n_jobs=-1, \n",
    "    verbose=1,\n",
    "    error_score=\"raise\"\n",
    ")\n",
    "\n",
    "%time random_search_gdbt.fit(X2, y2)\n",
    "# Print the best score\n",
    "print(\"Best Score:\", random_search_gdbt.best_score_)\n",
    "\n",
    "# Print the best parameters\n",
    "print(\"Best Parameters:\", random_search_gdbt.best_params_)\n",
    "\n",
    "np.random.seed(25)\n",
    "gdbt_model = GradientBoostingClassifier(learning_rate=0.01, max_depth=5, min_samples_leaf=15, min_samples_split=8, \n",
    "                    n_estimators=473, verbose=0)\n",
    "%time scores=cross_val_score(gdbt_model, X22, y2, cv=kf, scoring='roc_auc',error_score=\"raise\")\n",
    "for i, score in enumerate(scores):\n",
    "    print(f'Fold {i+1}:  = {score:.2f}')\n",
    "avg_score = np.mean(scores)\n",
    "print(f'Average SCORE: {avg_score:.2f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "id": "5fd0b521",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3.23 s, sys: 38.9 ms, total: 3.26 s\n",
      "Wall time: 3.26 s\n",
      "Fold 1:  = 0.86\n",
      "Fold 2:  = 0.85\n",
      "Fold 3:  = 0.88\n",
      "Fold 4:  = 0.86\n",
      "Fold 5:  = 0.50\n",
      "Average SCORE: 0.79\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "extra_model = ExtraTreesClassifier(random_state=33)\n",
    "param_distributions={\n",
    "    \"n_estimators\":randint(100,1000),\n",
    "    \"min_samples_split\":randint(2,20),\n",
    "    \"min_samples_leaf\":randint(1,20),\n",
    "    \"min_weight_fraction_leaf\":uniform(0,0.5),\n",
    "    \"min_impurity_decrease\":uniform(0,1),\n",
    "}\n",
    "random_search_ext = RandomizedSearchCV(estimator=extra_model, param_distributions=param_distributions,n_iter=100, \n",
    "                           scoring='roc_auc', cv=5, random_state=33, n_jobs=-1, verbose=1,error_score=\"raise\")\n",
    "%time random_search_ext.fit(X2,y2)\n",
    "# Print the best score\n",
    "print(\"Best Score:\", random_search_ext.best_score_)\n",
    "\n",
    "# Print the best parameters\n",
    "print(\"Best Parameters:\", random_search_ext.best_params_)\n",
    "\n",
    "np.random.seed(34)\n",
    "ext_model = ExtraTreesClassifier(min_impurity_decrease=0.0102,min_samples_leaf=1,min_samples_split=10, \n",
    "                                 min_weight_fraction_leaf=0.1086, n_estimators=960,verbose=0)\n",
    "%time scores=cross_val_score(ext_model, X22, y2, cv=kf, scoring='roc_auc',error_score=\"raise\")\n",
    "for i, score in enumerate(scores):\n",
    "    print(f'Fold {i+1}:  = {score:.2f}')\n",
    "avg_score = np.mean(scores)\n",
    "print(f'Average SCORE: {avg_score:.2f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "id": "a458d8b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 6.9 s, sys: 38.2 ms, total: 6.94 s\n",
      "Wall time: 6.94 s\n",
      "Fold 1:  = 0.88\n",
      "Fold 2:  = 0.82\n",
      "Fold 3:  = 0.84\n",
      "Fold 4:  = 0.86\n",
      "Fold 5:  = 0.85\n",
      "Average SCORE: 0.85\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "np.random.seed(34)\n",
    "svm_model = SVC(kernel=\"poly\",probability=True)\n",
    "%time scores=cross_val_score(svm_model, X22, y2, cv=kf, scoring='roc_auc',error_score=\"raise\")\n",
    "for i, score in enumerate(scores):\n",
    "    print(f'Fold {i+1}:  = {score:.2f}')\n",
    "avg_score = np.mean(scores)\n",
    "print(f'Average SCORE: {avg_score:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "id": "3175eaa8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.27 s, sys: 224 ms, total: 1.5 s\n",
      "Wall time: 285 ms\n",
      "Fold 1:  = 0.89\n",
      "Fold 2:  = 0.83\n",
      "Fold 3:  = 0.86\n",
      "Fold 4:  = 0.89\n",
      "Fold 5:  = 0.84\n",
      "Average SCORE: 0.86\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "np.random.seed(34)\n",
    "knn_model = KNeighborsClassifier(n_neighbors=70)\n",
    "%time scores=cross_val_score(knn_model, X22, y2, cv=kf, scoring='roc_auc',error_score=\"raise\")\n",
    "for i, score in enumerate(scores):\n",
    "    print(f'Fold {i+1}:  = {score:.2f}')\n",
    "avg_score = np.mean(scores)\n",
    "print(f'Average SCORE: {avg_score:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "id": "8da98465",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/henryzhan13/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/henryzhan13/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/henryzhan13/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/henryzhan13/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4min 33s, sys: 5.69 s, total: 4min 38s\n",
      "Wall time: 36.9 s\n",
      "Fold 1:  = 0.90\n",
      "Fold 2:  = 0.88\n",
      "Fold 3:  = 0.93\n",
      "Fold 4:  = 0.90\n",
      "Fold 5:  = 0.92\n",
      "Average SCORE: 0.91\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/henryzhan13/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "np.random.seed(40)\n",
    "log_model = LogisticRegression(max_iter=10000)\n",
    "%time scores=cross_val_score(log_model, X22, y2, cv=kf, scoring='roc_auc',error_score=\"raise\")\n",
    "for i, score in enumerate(scores):\n",
    "    print(f'Fold {i+1}:  = {score:.2f}')\n",
    "avg_score = np.mean(scores)\n",
    "print(f'Average SCORE: {avg_score:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "51010e5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/henryzhan13/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/henryzhan13/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/henryzhan13/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/henryzhan13/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/henryzhan13/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/henryzhan13/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/henryzhan13/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/henryzhan13/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/henryzhan13/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/henryzhan13/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/henryzhan13/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/henryzhan13/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/henryzhan13/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/henryzhan13/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/henryzhan13/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/henryzhan13/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/henryzhan13/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/henryzhan13/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/henryzhan13/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/henryzhan13/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/henryzhan13/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/henryzhan13/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/henryzhan13/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/henryzhan13/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/henryzhan13/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/henryzhan13/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/henryzhan13/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/henryzhan13/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/henryzhan13/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/henryzhan13/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2h 22min 39s, sys: 2min 56s, total: 2h 25min 35s\n",
      "Wall time: 12h 1min 26s\n",
      "Fold 1:  = 0.92\n",
      "Fold 2:  = 0.91\n",
      "Fold 3:  = 0.91\n",
      "Fold 4:  = 0.92\n",
      "Fold 5:  = 0.93\n",
      "Average SCORE: 0.92\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import StackingClassifier\n",
    "base_models=[\n",
    "    ('RandomForest',rf_model),(\"Catboost\",cat_model),\n",
    "    ('GDBT',gdbt_model),('Ett',extra_model),('SVM',svm_model),('KNN',knn_model),('Logistic',log_model)\n",
    "]\n",
    "stack_clf = StackingClassifier(\n",
    "     estimators=base_models,\n",
    "    final_estimator=xgb_model\n",
    ")\n",
    "%time scores=cross_val_score(stack_clf, X2, y2, cv=kf, scoring='roc_auc',error_score=\"raise\")\n",
    "for i, score in enumerate(scores):\n",
    "    print(f'Fold {i+1}:  = {score:.2f}')\n",
    "avg_score = np.mean(scores)\n",
    "print(f'Average SCORE: {avg_score:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "id": "578afec2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/henryzhan13/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "clf11=xgb_model.fit(X2,y2)\n",
    "clf21=rf_model.fit(X2,y2)\n",
    "clf31=cat_model.fit(X2,y2)\n",
    "clf41=gdbt_model.fit(X2,y2)\n",
    "clf51=ext_model.fit(X2,y2)\n",
    "clf61=svm_model.fit(X2,y2)\n",
    "clf71=knn_model.fit(X2,y2)\n",
    "clf81=log_model.fit(X2,y2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "282e1cf9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/0b/4q6tccn90zd2mrdvjhd77ydm0000gn/T/ipykernel_1121/559069908.py:21: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test2[\"predictions\"]=predictions2\n"
     ]
    }
   ],
   "source": [
    "\n",
    "clf11=xgb_model.fit(X2,y2)\n",
    "clf21=rf_model.fit(X2,y2)\n",
    "clf31=cat_model.fit(X2,y2)\n",
    "clf41=gdbt_model.fit(X2,y2)\n",
    "clf51=extra_model.fit(X2,y2)\n",
    "clf61=svm_model.fit(X2,y2)\n",
    "clf71=knn_model.fit(X2,y2)\n",
    "clf81=log_model.fit(X2,y2)\n",
    "weights=[0.2, 0.15, 0.15, 0.15, 0.05,0.05,0.05, 0.2]\n",
    "y_test2=test2[\"TD\"].values\n",
    "X_test2=test2.drop([\"TD\",\"uniqueid\",\"AbsolutePostPlay\"], axis=1).values\n",
    "predictions2 = np.array([clf11.predict_proba(X_test2), clf21.predict_proba(X_test2), clf31.predict_proba(X_test2),\n",
    "                       clf41.predict_proba(X_test2), clf51.predict_proba(X_test2),clf61.predict_proba(X_test2),\n",
    "                       clf71.predict_proba(X_test2), clf81.predict_proba(X_test2)])\n",
    "weighted_predictions2 = np.tensordot(predictions2, weights, axes=((0),(0)))\n",
    "final_probabilities2 = weighted_predictions2 / weighted_predictions2.sum(axis=1, keepdims=True)\n",
    "\n",
    "prob2=final_probabilities2[:,1]\n",
    "predictions2=np.where(prob2>=0.25,1,0)\n",
    "test2[\"predictions\"]=predictions2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "id": "14f92e16",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5396039603960396"
      ]
     },
     "execution_count": 233,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "#test2[test2[\"predictions\"]==1]\n",
    "confusion_mat = confusion_matrix(y_test2, predictions2)\n",
    "confusion_mat\n",
    "f1_score(y_test2, predictions2)\n",
    "#roc_auc_score(y_test2, prob22)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "21bec2bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n# Grid Search for xgboost\\nfrom sklearn.model_selection import RandomizedSearchCV\\nfrom scipy.stats import uniform, randint\\n\\nparam_distributions={\\n    \\'n_estimators\\':randint(50,1001),\\n    \\'learning_rate\\':uniform(0.01,0.59),\\n    \\'max_depth\\':randint(3,11),\\n    \\'min_child_weight\\':randint(1,11),\\n    \\'subsample\\':uniform(0.5,0.5),\\n    \\'colsample_bytree\\':uniform(0.5,0.5),\\n    \\'gamma\\':uniform(0.1,0.6),\\n    \\'reg_alpha\\':randint(1,8)\\n}\\nrandom_search_xgb = RandomizedSearchCV(estimator=xgb_model, param_distributions=param_distributions,n_iter=150, \\n                           scoring=\\'neg_mean_squared_error\\', cv=5, random_state=25, n_jobs=-1, verbose=1,error_score=\"raise\")\\n\\n%time random_search_xgb.fit(X3,y3)\\n'"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train3=train2[train2[\"TD\"]==0]\n",
    "y3=train3[\"AbsolutePostPlay\"].values\n",
    "\n",
    "X3=train3.drop([\"AbsolutePostPlay\",\"TD\",\"uniqueid\"],axis=1).values\n",
    "xgb_model = xgb.XGBRegressor(objective='reg:squarederror',eval_metric='rmse')\n",
    "\n",
    "# Grid Search for xgboost\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from scipy.stats import uniform, randint\n",
    "\n",
    "param_distributions={\n",
    "    'n_estimators':randint(50,1001),\n",
    "    'learning_rate':uniform(0.01,0.59),\n",
    "    'max_depth':randint(3,11),\n",
    "    'min_child_weight':randint(1,11),\n",
    "    'subsample':uniform(0.5,0.5),\n",
    "    'colsample_bytree':uniform(0.5,0.5),\n",
    "    'gamma':uniform(0.1,0.6),\n",
    "    'reg_alpha':randint(1,8)\n",
    "}\n",
    "random_search_xgb = RandomizedSearchCV(estimator=xgb_model, param_distributions=param_distributions,n_iter=150, \n",
    "                           scoring='neg_mean_squared_error', cv=5, random_state=25, n_jobs=-1, verbose=1,error_score=\"raise\")\n",
    "\n",
    "%time random_search_xgb.fit(X3,y3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "2ffea5ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 17 s, sys: 3.36 s, total: 20.3 s\n",
      "Wall time: 2.68 s\n",
      "Fold 1: RMSE = 5.64\n",
      "Fold 2: RMSE = 5.77\n",
      "Fold 3: RMSE = 5.45\n",
      "Fold 4: RMSE = 5.94\n",
      "Fold 5: RMSE = 5.75\n",
      "Average RMSE: 5.71\n"
     ]
    }
   ],
   "source": [
    "kf=KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "xgb_model=xgb.XGBRegressor(\n",
    "    n_estimators=279,\n",
    "    learning_rate=0.038,\n",
    "    max_depth=3,\n",
    "    min_child_weight=9,\n",
    "    subsample=0.608,\n",
    "    colsample_bytree=0.571,\n",
    "    gamma=0.445,\n",
    "    reg_alpha=4,\n",
    "    reg_lambda=1,\n",
    "    objective='reg:squarederror',\n",
    "    eval_metric='rmse'\n",
    ")\n",
    "\n",
    "\n",
    "%time scores=cross_val_score(xgb_model, X3, y3, cv=kf, scoring='neg_mean_squared_error')\n",
    "\n",
    "rmse = np.sqrt(-scores)\n",
    "\n",
    "# Display the RMSE for each fold\n",
    "for i, score in enumerate(rmse):\n",
    "    print(f'Fold {i+1}: RMSE = {score:.2f}')\n",
    "\n",
    "# Calculate and display the average RMSE across all folds\n",
    "avg_rmse = np.mean(rmse)\n",
    "print(f'Average RMSE: {avg_rmse:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "791c4163",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nfrom sklearn.model_selection import RandomizedSearchCV\\nfrom scipy.stats import uniform, randint\\n\\nparam_distributions={\\n    \\'n_estimators\\':randint(50,1001),\\n    \\'max_depth\\':randint(10,100),\\n    \\'min_samples_split\\':randint(2,11),\\n    \\'min_samples_leaf\\':randint(1,11),\\n    \\'bootstrap\\':[True, False],\\n}\\nrandom_search_rf = RandomizedSearchCV(estimator=rf_model, param_distributions=param_distributions,n_iter=15, \\n                           scoring=\\'neg_mean_squared_error\\', cv=3, random_state=25, n_jobs=-1, verbose=1,error_score=\"raise\")\\n\\n%time random_search_rf.fit(X3,y3)\\n'"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "rf_model = RandomForestRegressor(criterion=\"squared_error\",random_state=42,n_jobs=-1)\n",
    "\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from scipy.stats import uniform, randint\n",
    "\n",
    "param_distributions={\n",
    "    'n_estimators':randint(50,1001),\n",
    "    'max_depth':randint(10,100),\n",
    "    'min_samples_split':randint(2,11),\n",
    "    'min_samples_leaf':randint(1,11),\n",
    "    'bootstrap':[True, False],\n",
    "}\n",
    "random_search_rf = RandomizedSearchCV(estimator=rf_model, param_distributions=param_distributions,n_iter=15, \n",
    "                           scoring='neg_mean_squared_error', cv=3, random_state=25, n_jobs=-1, verbose=1,error_score=\"raise\")\n",
    "\n",
    "%time random_search_rf.fit(X3,y3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "id": "0420f05c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: {'bootstrap': True, 'max_depth': 24, 'min_samples_leaf': 9, 'min_samples_split': 8, 'n_estimators': 549}\n",
      "Best score: 43.25887672794744\n"
     ]
    }
   ],
   "source": [
    "print(\"Best parameters:\",random_search_rf.best_params_)\n",
    "print(\"Best score:\",-random_search_rf.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "d9183980",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 14min 59s, sys: 2.28 s, total: 15min 2s\n",
      "Wall time: 18min 32s\n",
      "Fold 1: RMSE = 5.71\n",
      "Fold 2: RMSE = 5.79\n",
      "Fold 3: RMSE = 5.58\n",
      "Fold 4: RMSE = 6.00\n",
      "Fold 5: RMSE = 5.88\n",
      "Average RMSE: 5.79\n"
     ]
    }
   ],
   "source": [
    "#print(\"Best parameters:\",random_search_rf.best_params_)\n",
    "#print(\"Best score:\",-random_search_rf.best_score_)\n",
    "# Setup random seed for reproducibility\n",
    "np.random.seed(42)\n",
    "\n",
    "# Initialize RandomForestRegressor\n",
    "rf_regressor = RandomForestRegressor(bootstrap=True, min_samples_leaf=9, min_samples_split=8, n_estimators=549,random_state=42, max_depth=24)\n",
    "\n",
    "# Perform K-Fold CV and calculate RMSE\n",
    "%time mse_scores = cross_val_score(rf_regressor, X3, y3, cv=kf, scoring='neg_mean_squared_error')\n",
    "rmse_scores = np.sqrt(-mse_scores)\n",
    "\n",
    "# Display the RMSE for each fold\n",
    "for i, rmse in enumerate(rmse_scores, 1):\n",
    "    print(f'Fold {i}: RMSE = {rmse:.2f}')\n",
    "\n",
    "# Calculate and display the average RMSE\n",
    "avg_rmse = np.mean(rmse_scores)\n",
    "print(f'Average RMSE: {avg_rmse:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "92282b0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 819 ms, sys: 73.1 ms, total: 892 ms\n",
      "Wall time: 145 ms\n",
      "Fold 1: RMSE = 5.54\n",
      "Fold 2: RMSE = 5.62\n",
      "Fold 3: RMSE = 5.48\n",
      "Fold 4: RMSE = 5.92\n",
      "Fold 5: RMSE = 5.79\n",
      "Average RMSE: 5.67\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import Ridge\n",
    "ridge_model=Ridge(alpha=1)\n",
    "\n",
    "%time mse_scores = cross_val_score(ridge_model, X3, y3, cv=kf, scoring='neg_mean_squared_error')\n",
    "rmse_scores = np.sqrt(-mse_scores)\n",
    "\n",
    "# Display the RMSE for each fold\n",
    "for i, rmse in enumerate(rmse_scores, 1):\n",
    "    print(f'Fold {i}: RMSE = {rmse:.2f}')\n",
    "\n",
    "# Calculate and display the average RMSE\n",
    "avg_rmse = np.mean(rmse_scores)\n",
    "print(f'Average RMSE: {avg_rmse:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "717f8c4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/henryzhan13/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.772e+04, tolerance: 2.680e+02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/henryzhan13/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.190e+04, tolerance: 2.648e+02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/henryzhan13/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.782e+04, tolerance: 2.650e+02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/henryzhan13/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.678e+04, tolerance: 2.619e+02\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 9.18 s, sys: 3.77 s, total: 13 s\n",
      "Wall time: 3.81 s\n",
      "Fold 1: RMSE = 5.52\n",
      "Fold 2: RMSE = 5.60\n",
      "Fold 3: RMSE = 5.45\n",
      "Fold 4: RMSE = 5.89\n",
      "Fold 5: RMSE = 5.78\n",
      "Average RMSE: 5.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/henryzhan13/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.508e+04, tolerance: 2.632e+02\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import Lasso\n",
    "lasso_model=Lasso(alpha=0.1)\n",
    "\n",
    "%time mse_scores = cross_val_score(lasso_model, X3, y3, cv=kf, scoring='neg_mean_squared_error')\n",
    "rmse_scores = np.sqrt(-mse_scores)\n",
    "\n",
    "# Display the RMSE for each fold\n",
    "for i, rmse in enumerate(rmse_scores, 1):\n",
    "    print(f'Fold {i}: RMSE = {rmse:.2f}')\n",
    "\n",
    "# Calculate and display the average RMSE\n",
    "avg_rmse = np.mean(rmse_scores)\n",
    "print(f'Average RMSE: {avg_rmse:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "03e80a6d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nparam_distributions={\\n    \\'learning_rate\\':uniform(0,1),\\n    \\'depth\\':randint(4,10),\\n    \\'l2_leaf_reg\\':uniform(0,10),\\n    \\'n_estimators\\':randint(100,1001),\\n    \\'border_count\\':randint(32,255),\\n    \\'min_data_in_leaf\\':randint(1,50),\\n    \\'bagging_temperature\\':uniform(0,1),\\n    \\'random_strength\\':randint(1,20),\\n}\\nfrom sklearn.model_selection import RandomizedSearchCV\\nrandom_search_cat = RandomizedSearchCV(estimator=cat_model, param_distributions=param_distributions,n_iter=80, \\n                           scoring=\\'neg_mean_squared_error\\', cv=5, random_state=35, n_jobs=-1, verbose=1,error_score=\"raise\")\\n\\n%time random_search_cat.fit(X2,y2)\\n'"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from catboost import CatBoostRegressor\n",
    "\n",
    "cat_model = CatBoostRegressor(random_state=42,verbose=0)\n",
    "from scipy.stats import uniform, randint\n",
    "\n",
    "param_distributions={\n",
    "    'learning_rate':uniform(0,1),\n",
    "    'depth':randint(4,10),\n",
    "    'l2_leaf_reg':uniform(0,10),\n",
    "    'n_estimators':randint(100,1001),\n",
    "    'border_count':randint(32,255),\n",
    "    'min_data_in_leaf':randint(1,50),\n",
    "    'bagging_temperature':uniform(0,1),\n",
    "    'random_strength':randint(1,20),\n",
    "}\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "random_search_cat = RandomizedSearchCV(estimator=cat_model, param_distributions=param_distributions,n_iter=80, \n",
    "                           scoring='neg_mean_squared_error', cv=5, random_state=35, n_jobs=-1, verbose=1,error_score=\"raise\")\n",
    "\n",
    "%time random_search_cat.fit(X2,y2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 520,
   "id": "150181a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: {'bagging_temperature': 0.45805494822409054, 'border_count': 215, 'depth': 5, 'l2_leaf_reg': 2.461068576382439, 'learning_rate': 0.02812563491787612, 'min_data_in_leaf': 41, 'n_estimators': 751, 'random_strength': 12}\n",
      "Best score: 41.36483353733324\n"
     ]
    }
   ],
   "source": [
    "print(\"Best parameters:\",random_search_cat.best_params_)\n",
    "print(\"Best score:\",-random_search_cat.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "aab2f9f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 16s, sys: 6.2 s, total: 1min 22s\n",
      "Wall time: 13.3 s\n",
      "Fold 1: RMSE = 5.68\n",
      "Fold 2: RMSE = 5.93\n",
      "Fold 3: RMSE = 5.54\n",
      "Fold 4: RMSE = 6.08\n",
      "Fold 5: RMSE = 5.88\n",
      "Average RMSE: 5.82\n"
     ]
    }
   ],
   "source": [
    "cat_model = CatBoostRegressor(iterations=751,\n",
    "                          learning_rate=0.028,\n",
    "                          depth=5,\n",
    "                          eval_metric='RMSE',\n",
    "                          random_seed=35,\n",
    "                          bagging_temperature=0.458,\n",
    "                          border_count=215,\n",
    "                          l2_leaf_reg=2.4611,\n",
    "                          min_data_in_leaf=41,\n",
    "                          random_strength=12,\n",
    "                          od_type='Iter',\n",
    "                          metric_period=50,\n",
    "                          od_wait=20,verbose=0)\n",
    "%time mse_scores = cross_val_score(cat_model, X3, y3, cv=kf, scoring='neg_mean_squared_error')\n",
    "rmse_scores = np.sqrt(-mse_scores)\n",
    "\n",
    "# Display the RMSE for each fold\n",
    "for i, rmse in enumerate(rmse_scores, 1):\n",
    "    print(f'Fold {i}: RMSE = {rmse:.2f}')\n",
    "\n",
    "# Calculate and display the average RMSE\n",
    "avg_rmse = np.mean(rmse_scores)\n",
    "print(f'Average RMSE: {avg_rmse:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "7b4b56bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nparam_distributions={\\n    \"n_estimators\":randint(100,1000),\\n    \"min_samples_split\":randint(2,20),\\n    \"min_samples_leaf\":randint(1,20),\\n    \"min_weight_fraction_leaf\":uniform(0,0.5),\\n    \"min_impurity_decrease\":uniform(0,1),\\n}\\n\\nrandom_search_ext = RandomizedSearchCV(estimator=extra_model, param_distributions=param_distributions,n_iter=160, \\n                           scoring=\\'neg_mean_squared_error\\', cv=5, random_state=35, n_jobs=-1, verbose=1,error_score=\"raise\")\\n\\n%time random_search_ext.fit(X2,y2)\\n'"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import ExtraTreesRegressor\n",
    "extra_model = ExtraTreesRegressor(random_state=42)\n",
    "\n",
    "param_distributions={\n",
    "    \"n_estimators\":randint(100,1000),\n",
    "    \"min_samples_split\":randint(2,20),\n",
    "    \"min_samples_leaf\":randint(1,20),\n",
    "    \"min_weight_fraction_leaf\":uniform(0,0.5),\n",
    "    \"min_impurity_decrease\":uniform(0,1),\n",
    "}\n",
    "\n",
    "random_search_ext = RandomizedSearchCV(estimator=extra_model, param_distributions=param_distributions,n_iter=160, \n",
    "                           scoring='neg_mean_squared_error', cv=5, random_state=35, n_jobs=-1, verbose=1,error_score=\"raise\")\n",
    "\n",
    "%time random_search_ext.fit(X2,y2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "id": "995763e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: {'min_impurity_decrease': 0.018532760954094618, 'min_samples_leaf': 5, 'min_samples_split': 6, 'min_weight_fraction_leaf': 0.005714234739480184, 'n_estimators': 594}\n",
      "Best score: 43.93684298036059\n"
     ]
    }
   ],
   "source": [
    "print(\"Best parameters:\",random_search_ext.best_params_)\n",
    "print(\"Best score:\",-random_search_ext.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "381d3b0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 23s, sys: 197 ms, total: 1min 23s\n",
      "Wall time: 1min 23s\n",
      "Fold 1: RMSE = 5.74\n",
      "Fold 2: RMSE = 5.94\n",
      "Fold 3: RMSE = 5.67\n",
      "Fold 4: RMSE = 6.12\n",
      "Fold 5: RMSE = 5.95\n",
      "Average RMSE: 5.88\n"
     ]
    }
   ],
   "source": [
    "\n",
    "extra_model=ExtraTreesRegressor(n_estimators=594, random_state=35,min_impurity_decrease=0.019, min_samples_leaf=5,\n",
    "                               min_samples_split=6,min_weight_fraction_leaf=0.0057)\n",
    "%time mse_scores = cross_val_score(extra_model, X3, y3, cv=kf, scoring='neg_mean_squared_error')\n",
    "rmse_scores = np.sqrt(-mse_scores)\n",
    "\n",
    "# Display the RMSE for each fold\n",
    "for i, rmse in enumerate(rmse_scores, 1):\n",
    "    print(f'Fold {i}: RMSE = {rmse:.2f}')\n",
    "\n",
    "# Calculate and display the average RMSE\n",
    "avg_rmse = np.mean(rmse_scores)\n",
    "print(f'Average RMSE: {avg_rmse:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "c2511666",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/henryzhan13/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.923e+02, tolerance: 2.680e+02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/henryzhan13/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.837e+02, tolerance: 2.648e+02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/henryzhan13/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.672e+02, tolerance: 2.650e+02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/henryzhan13/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.822e+02, tolerance: 2.619e+02\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 10.8 s, sys: 1.33 s, total: 12.2 s\n",
      "Wall time: 3.39 s\n",
      "Fold 1: RMSE = 5.60\n",
      "Fold 2: RMSE = 5.80\n",
      "Fold 3: RMSE = 5.55\n",
      "Fold 4: RMSE = 6.00\n",
      "Fold 5: RMSE = 5.83\n",
      "Average RMSE: 5.76\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/henryzhan13/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.903e+02, tolerance: 2.632e+02\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import ElasticNet\n",
    "\n",
    "elastic_net_model = ElasticNet(alpha=1.0, l1_ratio=0.5)\n",
    "%time mse_scores = cross_val_score(elastic_net_model, X3, y3, cv=kf, scoring='neg_mean_squared_error')\n",
    "rmse_scores = np.sqrt(-mse_scores)\n",
    "\n",
    "# Display the RMSE for each fold\n",
    "for i, rmse in enumerate(rmse_scores, 1):\n",
    "    print(f'Fold {i}: RMSE = {rmse:.2f}')\n",
    "\n",
    "# Calculate and display the average RMSE\n",
    "avg_rmse = np.mean(rmse_scores)\n",
    "print(f'Average RMSE: {avg_rmse:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "4f5b6e62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 14.7 s, sys: 130 ms, total: 14.8 s\n",
      "Wall time: 14.8 s\n",
      "Fold 1: RMSE = 7.41\n",
      "Fold 2: RMSE = 7.55\n",
      "Fold 3: RMSE = 7.21\n",
      "Fold 4: RMSE = 7.73\n",
      "Fold 5: RMSE = 7.79\n",
      "Average RMSE: 7.54\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVR\n",
    "svr_model = SVR(C=1.0, epsilon=0.1, kernel='rbf')\n",
    "%time mse_scores = cross_val_score(svr_model, X3, y3, cv=kf, scoring='neg_mean_squared_error')\n",
    "rmse_scores = np.sqrt(-mse_scores)\n",
    "\n",
    "# Display the RMSE for each fold\n",
    "for i, rmse in enumerate(rmse_scores, 1):\n",
    "    print(f'Fold {i}: RMSE = {rmse:.2f}')\n",
    "\n",
    "# Calculate and display the average RMSE\n",
    "avg_rmse = np.mean(rmse_scores)\n",
    "print(f'Average RMSE: {avg_rmse:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "e3e2f3d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/henryzhan13/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.923e+02, tolerance: 2.680e+02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/henryzhan13/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.432e+02, tolerance: 2.145e+02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/henryzhan13/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.756e+03, tolerance: 2.095e+02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/henryzhan13/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.715e+03, tolerance: 2.168e+02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/henryzhan13/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.036e+03, tolerance: 2.143e+02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/henryzhan13/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.369e+03, tolerance: 2.167e+02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/henryzhan13/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.837e+02, tolerance: 2.648e+02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/henryzhan13/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.459e+02, tolerance: 2.130e+02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/henryzhan13/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.607e+03, tolerance: 2.081e+02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/henryzhan13/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.201e+02, tolerance: 2.149e+02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/henryzhan13/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.377e+03, tolerance: 2.097e+02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/henryzhan13/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.161e+02, tolerance: 2.133e+02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/henryzhan13/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.324e+03, tolerance: 2.648e+02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/henryzhan13/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.672e+02, tolerance: 2.650e+02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/henryzhan13/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.506e+03, tolerance: 2.064e+02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/henryzhan13/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.071e+02, tolerance: 2.149e+02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/henryzhan13/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.563e+03, tolerance: 2.117e+02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/henryzhan13/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.294e+02, tolerance: 2.141e+02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/henryzhan13/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.896e+03, tolerance: 2.650e+02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/henryzhan13/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.822e+02, tolerance: 2.619e+02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/henryzhan13/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.453e+03, tolerance: 2.084e+02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/henryzhan13/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.698e+03, tolerance: 2.049e+02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/henryzhan13/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.787e+03, tolerance: 2.132e+02\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/henryzhan13/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.495e+02, tolerance: 2.102e+02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/henryzhan13/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.359e+02, tolerance: 2.106e+02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/henryzhan13/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.978e+02, tolerance: 2.619e+02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/henryzhan13/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.903e+02, tolerance: 2.632e+02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/henryzhan13/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.315e+02, tolerance: 2.113e+02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/henryzhan13/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.388e+02, tolerance: 2.056e+02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/henryzhan13/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.115e+03, tolerance: 2.138e+02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/henryzhan13/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.067e+03, tolerance: 2.101e+02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/henryzhan13/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.390e+02, tolerance: 2.114e+02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/henryzhan13/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.773e+03, tolerance: 2.632e+02\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1h 28min 6s, sys: 1min 39s, total: 1h 29min 46s\n",
      "Wall time: 12h 2min 10s\n",
      "Fold 1: RMSE = 5.47\n",
      "Fold 2: RMSE = 5.60\n",
      "Fold 3: RMSE = 5.37\n",
      "Fold 4: RMSE = 5.83\n",
      "Fold 5: RMSE = 5.68\n",
      "Average RMSE: 5.59\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import StackingRegressor\n",
    "base_learners = [\n",
    "    ('ridge', ridge_model),\n",
    "    ('lasso', xgb_model),\n",
    "    ('rf', rf_regressor),\n",
    "    ('extra', extra_model),\n",
    "    ('catboost',cat_model),\n",
    "    ('elasticnet',elastic_net_model)\n",
    "]\n",
    "\n",
    "stack_model=StackingRegressor(estimators=base_learners, \n",
    "                             final_estimator=lasso_model)\n",
    "%time mse_scores = cross_val_score(stack_model, X3, y3, cv=kf, scoring='neg_mean_squared_error')\n",
    "rmse_scores = np.sqrt(-mse_scores)\n",
    "\n",
    "# Display the RMSE for each fold\n",
    "for i, rmse in enumerate(rmse_scores, 1):\n",
    "    print(f'Fold {i}: RMSE = {rmse:.2f}')\n",
    "\n",
    "# Calculate and display the average RMSE\n",
    "avg_rmse = np.mean(rmse_scores)\n",
    "print(f'Average RMSE: {avg_rmse:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "c14d6ce4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/henryzhan13/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.367e+02, tolerance: 3.307e+02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/henryzhan13/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.694e+02, tolerance: 2.652e+02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/henryzhan13/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.951e+03, tolerance: 2.587e+02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/henryzhan13/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.811e+02, tolerance: 2.681e+02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/henryzhan13/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.024e+03, tolerance: 2.638e+02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/henryzhan13/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.844e+02, tolerance: 2.668e+02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/henryzhan13/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.980e+04, tolerance: 3.307e+02\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>StackingRegressor(estimators=[(&#x27;ridge&#x27;, Ridge(alpha=1)),\n",
       "                              (&#x27;lasso&#x27;,\n",
       "                               XGBRegressor(base_score=None, booster=None,\n",
       "                                            callbacks=None,\n",
       "                                            colsample_bylevel=None,\n",
       "                                            colsample_bynode=None,\n",
       "                                            colsample_bytree=0.571, device=None,\n",
       "                                            early_stopping_rounds=None,\n",
       "                                            enable_categorical=False,\n",
       "                                            eval_metric=&#x27;rmse&#x27;,\n",
       "                                            feature_types=None, gamma=0.445,\n",
       "                                            grow_policy=None,\n",
       "                                            importance_type=None,\n",
       "                                            interacti...\n",
       "                                                     min_samples_leaf=9,\n",
       "                                                     min_samples_split=8,\n",
       "                                                     n_estimators=549,\n",
       "                                                     random_state=42)),\n",
       "                              (&#x27;extra&#x27;,\n",
       "                               ExtraTreesRegressor(min_impurity_decrease=0.019,\n",
       "                                                   min_samples_leaf=5,\n",
       "                                                   min_samples_split=6,\n",
       "                                                   min_weight_fraction_leaf=0.0057,\n",
       "                                                   n_estimators=594,\n",
       "                                                   random_state=35)),\n",
       "                              (&#x27;catboost&#x27;,\n",
       "                               &lt;catboost.core.CatBoostRegressor object at 0x29ec157d0&gt;),\n",
       "                              (&#x27;elasticnet&#x27;, ElasticNet())],\n",
       "                  final_estimator=Lasso(alpha=0.1))</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">StackingRegressor</label><div class=\"sk-toggleable__content\"><pre>StackingRegressor(estimators=[(&#x27;ridge&#x27;, Ridge(alpha=1)),\n",
       "                              (&#x27;lasso&#x27;,\n",
       "                               XGBRegressor(base_score=None, booster=None,\n",
       "                                            callbacks=None,\n",
       "                                            colsample_bylevel=None,\n",
       "                                            colsample_bynode=None,\n",
       "                                            colsample_bytree=0.571, device=None,\n",
       "                                            early_stopping_rounds=None,\n",
       "                                            enable_categorical=False,\n",
       "                                            eval_metric=&#x27;rmse&#x27;,\n",
       "                                            feature_types=None, gamma=0.445,\n",
       "                                            grow_policy=None,\n",
       "                                            importance_type=None,\n",
       "                                            interacti...\n",
       "                                                     min_samples_leaf=9,\n",
       "                                                     min_samples_split=8,\n",
       "                                                     n_estimators=549,\n",
       "                                                     random_state=42)),\n",
       "                              (&#x27;extra&#x27;,\n",
       "                               ExtraTreesRegressor(min_impurity_decrease=0.019,\n",
       "                                                   min_samples_leaf=5,\n",
       "                                                   min_samples_split=6,\n",
       "                                                   min_weight_fraction_leaf=0.0057,\n",
       "                                                   n_estimators=594,\n",
       "                                                   random_state=35)),\n",
       "                              (&#x27;catboost&#x27;,\n",
       "                               &lt;catboost.core.CatBoostRegressor object at 0x29ec157d0&gt;),\n",
       "                              (&#x27;elasticnet&#x27;, ElasticNet())],\n",
       "                  final_estimator=Lasso(alpha=0.1))</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><label>ridge</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Ridge</label><div class=\"sk-toggleable__content\"><pre>Ridge(alpha=1)</pre></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><label>lasso</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">XGBRegressor</label><div class=\"sk-toggleable__content\"><pre>XGBRegressor(base_score=None, booster=None, callbacks=None,\n",
       "             colsample_bylevel=None, colsample_bynode=None,\n",
       "             colsample_bytree=0.571, device=None, early_stopping_rounds=None,\n",
       "             enable_categorical=False, eval_metric=&#x27;rmse&#x27;, feature_types=None,\n",
       "             gamma=0.445, grow_policy=None, importance_type=None,\n",
       "             interaction_constraints=None, learning_rate=0.038, max_bin=None,\n",
       "             max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "             max_delta_step=None, max_depth=3, max_leaves=None,\n",
       "             min_child_weight=9, missing=nan, monotone_constraints=None,\n",
       "             multi_strategy=None, n_estimators=279, n_jobs=None,\n",
       "             num_parallel_tree=None, random_state=None, ...)</pre></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><label>rf</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestRegressor</label><div class=\"sk-toggleable__content\"><pre>RandomForestRegressor(max_depth=24, min_samples_leaf=9, min_samples_split=8,\n",
       "                      n_estimators=549, random_state=42)</pre></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><label>extra</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" ><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">ExtraTreesRegressor</label><div class=\"sk-toggleable__content\"><pre>ExtraTreesRegressor(min_impurity_decrease=0.019, min_samples_leaf=5,\n",
       "                    min_samples_split=6, min_weight_fraction_leaf=0.0057,\n",
       "                    n_estimators=594, random_state=35)</pre></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><label>catboost</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" ><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">CatBoostRegressor</label><div class=\"sk-toggleable__content\"><pre>&lt;catboost.core.CatBoostRegressor object at 0x29ec157d0&gt;</pre></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><label>elasticnet</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-7\" type=\"checkbox\" ><label for=\"sk-estimator-id-7\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">ElasticNet</label><div class=\"sk-toggleable__content\"><pre>ElasticNet()</pre></div></div></div></div></div></div></div></div><div class=\"sk-item\"><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><label>final_estimator</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-8\" type=\"checkbox\" ><label for=\"sk-estimator-id-8\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Lasso</label><div class=\"sk-toggleable__content\"><pre>Lasso(alpha=0.1)</pre></div></div></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "StackingRegressor(estimators=[('ridge', Ridge(alpha=1)),\n",
       "                              ('lasso',\n",
       "                               XGBRegressor(base_score=None, booster=None,\n",
       "                                            callbacks=None,\n",
       "                                            colsample_bylevel=None,\n",
       "                                            colsample_bynode=None,\n",
       "                                            colsample_bytree=0.571, device=None,\n",
       "                                            early_stopping_rounds=None,\n",
       "                                            enable_categorical=False,\n",
       "                                            eval_metric='rmse',\n",
       "                                            feature_types=None, gamma=0.445,\n",
       "                                            grow_policy=None,\n",
       "                                            importance_type=None,\n",
       "                                            interacti...\n",
       "                                                     min_samples_leaf=9,\n",
       "                                                     min_samples_split=8,\n",
       "                                                     n_estimators=549,\n",
       "                                                     random_state=42)),\n",
       "                              ('extra',\n",
       "                               ExtraTreesRegressor(min_impurity_decrease=0.019,\n",
       "                                                   min_samples_leaf=5,\n",
       "                                                   min_samples_split=6,\n",
       "                                                   min_weight_fraction_leaf=0.0057,\n",
       "                                                   n_estimators=594,\n",
       "                                                   random_state=35)),\n",
       "                              ('catboost',\n",
       "                               <catboost.core.CatBoostRegressor object at 0x29ec157d0>),\n",
       "                              ('elasticnet', ElasticNet())],\n",
       "                  final_estimator=Lasso(alpha=0.1))"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stack_model.fit(X3,y3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 395,
   "id": "86cc4b4c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-3 {color: black;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>StackingRegressor(estimators=[(&#x27;ridge&#x27;, Ridge(alpha=1)),\n",
       "                              (&#x27;lasso&#x27;,\n",
       "                               XGBRegressor(base_score=None, booster=None,\n",
       "                                            callbacks=None,\n",
       "                                            colsample_bylevel=None,\n",
       "                                            colsample_bynode=None,\n",
       "                                            colsample_bytree=0.571, device=None,\n",
       "                                            early_stopping_rounds=None,\n",
       "                                            enable_categorical=False,\n",
       "                                            eval_metric=&#x27;rmse&#x27;,\n",
       "                                            feature_types=None, gamma=0.445,\n",
       "                                            grow_policy=None,\n",
       "                                            importance_type=None,\n",
       "                                            interacti...\n",
       "                                                     min_samples_leaf=9,\n",
       "                                                     min_samples_split=8,\n",
       "                                                     n_estimators=549,\n",
       "                                                     random_state=42)),\n",
       "                              (&#x27;extra&#x27;,\n",
       "                               ExtraTreesRegressor(min_impurity_decrease=0.019,\n",
       "                                                   min_samples_leaf=5,\n",
       "                                                   min_samples_split=6,\n",
       "                                                   min_weight_fraction_leaf=0.0057,\n",
       "                                                   n_estimators=594,\n",
       "                                                   random_state=35)),\n",
       "                              (&#x27;catboost&#x27;,\n",
       "                               &lt;catboost.core.CatBoostRegressor object at 0x29ec157d0&gt;),\n",
       "                              (&#x27;elasticnet&#x27;, ElasticNet())],\n",
       "                  final_estimator=Lasso(alpha=0.1))</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-17\" type=\"checkbox\" ><label for=\"sk-estimator-id-17\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">StackingRegressor</label><div class=\"sk-toggleable__content\"><pre>StackingRegressor(estimators=[(&#x27;ridge&#x27;, Ridge(alpha=1)),\n",
       "                              (&#x27;lasso&#x27;,\n",
       "                               XGBRegressor(base_score=None, booster=None,\n",
       "                                            callbacks=None,\n",
       "                                            colsample_bylevel=None,\n",
       "                                            colsample_bynode=None,\n",
       "                                            colsample_bytree=0.571, device=None,\n",
       "                                            early_stopping_rounds=None,\n",
       "                                            enable_categorical=False,\n",
       "                                            eval_metric=&#x27;rmse&#x27;,\n",
       "                                            feature_types=None, gamma=0.445,\n",
       "                                            grow_policy=None,\n",
       "                                            importance_type=None,\n",
       "                                            interacti...\n",
       "                                                     min_samples_leaf=9,\n",
       "                                                     min_samples_split=8,\n",
       "                                                     n_estimators=549,\n",
       "                                                     random_state=42)),\n",
       "                              (&#x27;extra&#x27;,\n",
       "                               ExtraTreesRegressor(min_impurity_decrease=0.019,\n",
       "                                                   min_samples_leaf=5,\n",
       "                                                   min_samples_split=6,\n",
       "                                                   min_weight_fraction_leaf=0.0057,\n",
       "                                                   n_estimators=594,\n",
       "                                                   random_state=35)),\n",
       "                              (&#x27;catboost&#x27;,\n",
       "                               &lt;catboost.core.CatBoostRegressor object at 0x29ec157d0&gt;),\n",
       "                              (&#x27;elasticnet&#x27;, ElasticNet())],\n",
       "                  final_estimator=Lasso(alpha=0.1))</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><label>ridge</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-18\" type=\"checkbox\" ><label for=\"sk-estimator-id-18\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Ridge</label><div class=\"sk-toggleable__content\"><pre>Ridge(alpha=1)</pre></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><label>lasso</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-19\" type=\"checkbox\" ><label for=\"sk-estimator-id-19\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">XGBRegressor</label><div class=\"sk-toggleable__content\"><pre>XGBRegressor(base_score=None, booster=None, callbacks=None,\n",
       "             colsample_bylevel=None, colsample_bynode=None,\n",
       "             colsample_bytree=0.571, device=None, early_stopping_rounds=None,\n",
       "             enable_categorical=False, eval_metric=&#x27;rmse&#x27;, feature_types=None,\n",
       "             gamma=0.445, grow_policy=None, importance_type=None,\n",
       "             interaction_constraints=None, learning_rate=0.038, max_bin=None,\n",
       "             max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "             max_delta_step=None, max_depth=3, max_leaves=None,\n",
       "             min_child_weight=9, missing=nan, monotone_constraints=None,\n",
       "             multi_strategy=None, n_estimators=279, n_jobs=None,\n",
       "             num_parallel_tree=None, random_state=None, ...)</pre></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><label>rf</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-20\" type=\"checkbox\" ><label for=\"sk-estimator-id-20\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestRegressor</label><div class=\"sk-toggleable__content\"><pre>RandomForestRegressor(max_depth=24, min_samples_leaf=9, min_samples_split=8,\n",
       "                      n_estimators=549, random_state=42)</pre></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><label>extra</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-21\" type=\"checkbox\" ><label for=\"sk-estimator-id-21\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">ExtraTreesRegressor</label><div class=\"sk-toggleable__content\"><pre>ExtraTreesRegressor(min_impurity_decrease=0.019, min_samples_leaf=5,\n",
       "                    min_samples_split=6, min_weight_fraction_leaf=0.0057,\n",
       "                    n_estimators=594, random_state=35)</pre></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><label>catboost</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-22\" type=\"checkbox\" ><label for=\"sk-estimator-id-22\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">CatBoostRegressor</label><div class=\"sk-toggleable__content\"><pre>&lt;catboost.core.CatBoostRegressor object at 0x29ec157d0&gt;</pre></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><label>elasticnet</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-23\" type=\"checkbox\" ><label for=\"sk-estimator-id-23\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">ElasticNet</label><div class=\"sk-toggleable__content\"><pre>ElasticNet()</pre></div></div></div></div></div></div></div></div><div class=\"sk-item\"><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><label>final_estimator</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-24\" type=\"checkbox\" ><label for=\"sk-estimator-id-24\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Lasso</label><div class=\"sk-toggleable__content\"><pre>Lasso(alpha=0.1)</pre></div></div></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "StackingRegressor(estimators=[('ridge', Ridge(alpha=1)),\n",
       "                              ('lasso',\n",
       "                               XGBRegressor(base_score=None, booster=None,\n",
       "                                            callbacks=None,\n",
       "                                            colsample_bylevel=None,\n",
       "                                            colsample_bynode=None,\n",
       "                                            colsample_bytree=0.571, device=None,\n",
       "                                            early_stopping_rounds=None,\n",
       "                                            enable_categorical=False,\n",
       "                                            eval_metric='rmse',\n",
       "                                            feature_types=None, gamma=0.445,\n",
       "                                            grow_policy=None,\n",
       "                                            importance_type=None,\n",
       "                                            interacti...\n",
       "                                                     min_samples_leaf=9,\n",
       "                                                     min_samples_split=8,\n",
       "                                                     n_estimators=549,\n",
       "                                                     random_state=42)),\n",
       "                              ('extra',\n",
       "                               ExtraTreesRegressor(min_impurity_decrease=0.019,\n",
       "                                                   min_samples_leaf=5,\n",
       "                                                   min_samples_split=6,\n",
       "                                                   min_weight_fraction_leaf=0.0057,\n",
       "                                                   n_estimators=594,\n",
       "                                                   random_state=35)),\n",
       "                              ('catboost',\n",
       "                               <catboost.core.CatBoostRegressor object at 0x29ec157d0>),\n",
       "                              ('elasticnet', ElasticNet())],\n",
       "                  final_estimator=Lasso(alpha=0.1))"
      ]
     },
     "execution_count": 395,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stack_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "id": "3c6d8db0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/0b/4q6tccn90zd2mrdvjhd77ydm0000gn/T/ipykernel_1121/2659737244.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test3[\"predictions\"]=pred3\n",
      "/var/folders/0b/4q6tccn90zd2mrdvjhd77ydm0000gn/T/ipykernel_1121/2659737244.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test3['residuals'] =  test3['predictions'] - test3['AbsolutePostPlay']\n",
      "/Users/henryzhan13/anaconda3/lib/python3.11/site-packages/seaborn/_oldcore.py:1498: FutureWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, CategoricalDtype) instead\n",
      "  if pd.api.types.is_categorical_dtype(vector):\n",
      "/Users/henryzhan13/anaconda3/lib/python3.11/site-packages/seaborn/_oldcore.py:1119: FutureWarning: use_inf_as_na option is deprecated and will be removed in a future version. Convert inf values to NaN before operating instead.\n",
      "  with pd.option_context('mode.use_inf_as_na', True):\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test3=test2[test2[\"TD\"]==0]\n",
    "X_test3=test3.drop([\"uniqueid\",\"AbsolutePostPlay\",\"TD\",\"predictions2\"],axis=1).values\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "test3[\"predictions\"]=pred3\n",
    "test3['residuals'] =  test3['predictions'] - test3['AbsolutePostPlay']\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.scatter(test3['predictions'], test3['residuals'])\n",
    "plt.title('Residuals vs. Predictions')\n",
    "plt.xlabel('Predictions (pred3)')\n",
    "plt.ylabel('Residuals')\n",
    "plt.axhline(y=0, color='r', linestyle='-')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "sns.histplot(test3['residuals'], kde=True)\n",
    "plt.title('Distribution of Residuals')\n",
    "plt.xlabel('Residuals')\n",
    "plt.ylabel('Frequency')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "id": "d7f96bac",
   "metadata": {},
   "outputs": [],
   "source": [
    "made_tackle=data_final[(data_final[\"tackleMade\"]==1) & (data_final[\"week_x\"]<=4)]\n",
    "nfinal_data.drop([\"AbsolutePostPlay\"], axis=1, inplace=True)\n",
    "nfinal_data=pd.merge(nfinal_data,plays,on=\"uniqueid\",how=\"left\")\n",
    "nfinal_data[\"AbsolutePostplay\"]=nfinal_data[\"absoluteYardlineNumber\"]+nfinal_data[\"prePenaltyPlayResult\"]\n",
    "nfinal_data.drop([\"prePenaltyPlayResult\"],axis=1,inplace=True)\n",
    "combos=made_tackle[['uniqueid','frameId','tacklerNflId']].drop_duplicates()\n",
    "nfinal_data=nfinal_data.merge(combos, on=[\"uniqueid\",\"frameId\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "id": "d70221c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, row in nfinal_data.iterrows():\n",
    "    if(row[\"club\"]==row[\"possessionTeam_x\"]):\n",
    "        nfinal_data.loc[index,\"side\"]=\"Offense\"\n",
    "    else:\n",
    "        nfinal_data.loc[index,\"side\"]=\"Defense\"\n",
    "    if(row[\"displayName\"]==\"football\"):\n",
    "        nfinal_data.loc[index,\"side\"]=\"Football\"\n",
    "nfinal_data['iscarrier'] = (nfinal_data['nflId'] == nfinal_data['ballCarrierId_x']).astype(int)\n",
    "def calculate_distance(group):\n",
    "    ball_carrier_x = group.loc[group['iscarrier'] == 1, 'x'].iloc[0]\n",
    "    ball_carrier_y = group.loc[group['iscarrier'] == 1, 'y'].iloc[0]\n",
    "    group['distance_to_carrier'] = np.sqrt((group['x'] - ball_carrier_x) ** 2 + (group['y'] - ball_carrier_y) ** 2)\n",
    "    return group\n",
    "nfinal_data = nfinal_data.groupby('uniqueid').apply(calculate_distance).reset_index(drop=True)\n",
    "nfinal_data['side'] = pd.Categorical(nfinal_data['side'], categories=[\"Offense\", \"Defense\", \"Football\"], ordered=True)\n",
    "sorted_final2 = nfinal_data.sort_values(by=['uniqueid', 'side', 'distance_to_carrier'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "id": "d0e2b59e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_coordinates(group):\n",
    "    row_22_x = group.iloc[21]['x']\n",
    "    row_22_y = group.iloc[21]['y']\n",
    "    group.loc[group['nflId'] == group['tacklerNflId'], 'x'] = row_22_x+0.05\n",
    "    group.loc[group['nflId'] == group['tacklerNflId'], 'y'] = row_22_y-0.05\n",
    "    return group\n",
    "sorted_final2 = sorted_final2.groupby(\"uniqueid\").apply(update_coordinates)\n",
    "sorted_final2=sorted_final2.reset_index(level=\"uniqueid\",drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "id": "130b6f8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_seconds(time_str):\n",
    "    if pd.isna(time_str):  \n",
    "        return None\n",
    "    minutes, seconds = map(int, time_str.split(':'))\n",
    "    return minutes * 60 + seconds\n",
    "sorted_final2['gameClock_x'] = sorted_final2['gameClock_x'].apply(convert_to_seconds)\n",
    "sorted_final2 = sorted_final2.groupby('uniqueid').apply(calculate_distance).reset_index(drop=True)\n",
    "sorted_final3 = sorted_final2.sort_values(by=['uniqueid', 'side', 'distance_to_carrier'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "id": "810d125d",
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_final3[\"offenseFormation_x\"]=label_encoder.fit_transform(sorted_final2[\"offenseFormation_x\"])\n",
    "sorted_final3[\"side\"]=label_encoder.fit_transform(sorted_final2[\"side\"])\n",
    "sorted_final3.drop([\"displayName\",\"nflId\",\"club\",\"playDirection\",\"event\",\"ballCarrierId_x\",\"tackleOpportunity\",\"possessionTeam_x\",\"defensiveTeam_x\"],axis=1,inplace=True)\n",
    "sorted_final3['idx'] = sorted_final3.groupby(['uniqueid']).cumcount() + 1\n",
    "sorted_final2.drop([\"tacklerNflId\"],axis=1,inplace=True)\n",
    "sorted_final3 = sorted_final3.groupby('uniqueid').apply(calculate_distance).reset_index(drop=True)\n",
    "sorted_final2['side'] = pd.Categorical(sorted_final2['side'], categories=[\"Offense\", \"Defense\", \"Football\"], ordered=True)\n",
    "sorted_final2 = sorted_final2.sort_values(by=['uniqueid', 'side', 'distance_to_carrier'])\n",
    "sorted_final2.drop([\"side\",\"iscarrier\"],axis=1,inplace=True)\n",
    "\n",
    "sorted_final3.drop([\"side\",\"iscarrier\"],axis=1,inplace=True)\n",
    "pivot_df2 = sorted_final3.pivot(index=['uniqueid','week_x','absoluteYardlineNumber_x','AbsolutePostplay','frameId',\n",
    "                                   'quarter_x','down_x','yardsToGo_x','offenseFormation_x',\"expectedPoints_x\",\"tacklerNflId\",\n",
    "                                   'offenseScore','defenseScore','defendersInTheBox_x',\n",
    "                                   'passProbability_x','offenseWinProbability','defenseWinProbability','gameClock_x'], columns='idx')\n",
    "pivot_df2.columns = [f'{col[0]}{col[1]}' for col in pivot_df2.columns]\n",
    "pivot_df2.reset_index(inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "id": "fe0a321c",
   "metadata": {},
   "outputs": [],
   "source": [
    "pivot_df2.drop([\"dir23\",\"o23\"],axis=1, inplace=True)\n",
    "y_true=pivot_df2[\"AbsolutePostplay\"].values\n",
    "X_predict=pivot_df2.drop([\"AbsolutePostplay\",\"defenseWinProbability\",\"tacklerNflId\",\"uniqueid\",\"frameId\"],axis=1).values\n",
    "predTD = np.array([clf11.predict_proba(X_predict), clf21.predict_proba(X_predict), clf31.predict_proba(X_predict),\n",
    "                       clf41.predict_proba(X_predict), clf51.predict_proba(X_predict),clf61.predict_proba(X_predict),\n",
    "                       clf71.predict_proba(X_predict), clf81.predict_proba(X_predict)])\n",
    "weighted_predictions3 = np.tensordot(predTD, weights, axes=((0),(0)))\n",
    "final_probabilities3 = weighted_predictions3 / weighted_predictions3.sum(axis=1, keepdims=True)\n",
    "\n",
    "prob3=final_probabilities3[:,1]\n",
    "predictions3=np.where(prob3>=0.25,1,0)\n",
    "pivot_df2[\"TD\"]=predictions3\n",
    "\n",
    "y_predict=stack_model.predict(X_predict)\n",
    "pivot_df2[\"withoutTackler\"]=y_predict\n",
    "pivot_df2[\"yardssaved\"]=pivot_df2[\"withoutTackler\"]-pivot_df2[\"AbsolutePostplay\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "id": "60482101",
   "metadata": {},
   "outputs": [],
   "source": [
    "pivot_df3=pivot_df2[pivot_df2[\"TD\"]==0]\n",
    "predYards=pivot_df3.drop([\"TD\",\"AbsolutePostplay\",\"uniqueid\",\"frameId\",\"defenseWinProbability\",\"tacklerNflId\"],axis=1).values\n",
    "res=stack_model.predict(predYards)\n",
    "pivot_df3[\"withoutTackler\"]=res\n",
    "TDs=pivot_df2[pivot_df2[\"TD\"]==1]\n",
    "TDs[\"withoutTackler\"]=110\n",
    "FINAL=pd.concat([TDs,pivot_df3])\n",
    "FINAL[\"yardssaved\"]=FINAL[\"withoutTackler\"]-FINAL[\"AbsolutePostplay\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 378,
   "id": "9c6c1970",
   "metadata": {},
   "outputs": [],
   "source": [
    "test[\"AbsolutePostplay\"]=test[\"absoluteYardlineNumber\"]+test[\"prePenaltyPlayResult\"]\n",
    "final_result=pd.merge(test,FINAL[[\"uniqueid\",\"withoutTackler\",\"yardssaved\"]],on=\"uniqueid\",how=\"left\")\n",
    "final_result.loc[final_result['tackleMade'] == 0, [\"yardssaved\"]] = np.nan\n",
    "final_result.loc[final_result['tackleMade'] == 0, [\"withoutTackler\"]] = np.nan\n",
    "final_result[\"potentialSaved\"]=final_result[\"AbsolutePostplay\"]-final_result[\"x1\"]-3\n",
    "final_result.loc[final_result['tackleMade'] == 1, [\"potentialSaved\"]] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "id": "d81df3c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_result['1Dsaved'] = np.where(\n",
    "    (final_result['withoutTackler'] - final_result['absoluteYardlineNumber'] > final_result['yardsToGo']) &\n",
    "    (final_result['AbsolutePostplay'] - final_result['absoluteYardlineNumber'] < final_result['yardsToGo']),\n",
    "    1, \n",
    "    0  \n",
    ")\n",
    "final_result['TDsaved'] = np.where(\n",
    "    (final_result['withoutTackler'] >=110) &\n",
    "    (final_result['AbsolutePostplay']<110),\n",
    "    1, \n",
    "    0  \n",
    ")\n",
    "final_result['potential1Dsaved'] = np.where(\n",
    "    (final_result['AbsolutePostplay'] -final_result[\"potentialSaved\"]- final_result['absoluteYardlineNumber'] < final_result['yardsToGo']) &\n",
    "    (final_result['AbsolutePostplay'] - final_result['absoluteYardlineNumber'] > final_result['yardsToGo']),\n",
    "    1,  \n",
    "    0  \n",
    ")\n",
    "final_result['potentialTDsaved'] = np.where(\n",
    "    (final_result['AbsolutePostplay']>=110) &\n",
    "    (final_result['AbsolutePostplay'] - final_result['potentialSaved'] < 110),\n",
    "    1, \n",
    "    0   \n",
    ")\n",
    "final_result.loc[final_result['tackleMade'] == 0, [\"1Dsaved\",\"TDsaved\"]] = np.nan\n",
    "final_result.loc[final_result['tackleMade'] == 1, [\"potential1Dsaved\",\"potentialTDsaved\"]] = np.nan\n",
    "final_result[\"tacklerNflId\"]=test_tackler\n",
    "final_result = final_result.rename(columns={'tacklerNflId': 'nflId'})\n",
    "final_res=pd.merge(final_result, players[[\"nflId\",\"displayName\"]], on=\"nflId\",how=\"left\")\n",
    "result=final_res[[\"tackleMade\",\"tackleProbability\",\"displayName\",\"withoutTackler\",\"potentialSaved\",\"yardssaved\",\"1Dsaved\",\"TDsaved\",\"potential1Dsaved\",\"potentialTDsaved\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 384,
   "id": "74a5bf9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/0b/4q6tccn90zd2mrdvjhd77ydm0000gn/T/ipykernel_1121/2214313689.py:24: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  result['impactScore'] = result.apply(calculate_impact_score, axis=1)\n"
     ]
    }
   ],
   "source": [
    "def calculate_impact_score(row):\n",
    "    if row['tackleMade'] == 1:\n",
    "        if row['TDsaved'] == 1:\n",
    "            score = (row['yardssaved'] * 0.2 + 7)\n",
    "        else:\n",
    "            score = (row['yardssaved'] * 0.2 +\n",
    "                     row['1Dsaved'] * 3)\n",
    "    else:\n",
    "        if row['potentialTDsaved'] == 1:\n",
    "            score = (-row['potentialSaved'] * 0.2 - 7)\n",
    "        else:\n",
    "            score = (-row['potentialSaved'] * 0.2 -\n",
    "                     row['potential1Dsaved'] * 3)\n",
    "    return score\n",
    "result['impactScore'] = result.apply(calculate_impact_score, axis=1)\n",
    "\n",
    "def calculate_points_added(row):\n",
    "    if row['impactScore'] > 0:\n",
    "        return row['impactScore'] * (1 + (1 - row['tackleProbability']))\n",
    "    else:\n",
    "        return row['impactScore'] * row['tackleProbability']\n",
    "result['SITR'] = result.apply(calculate_points_added, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 391,
   "id": "8959ea20",
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped = result.groupby('displayName')['SITR']\n",
    "average_points_added = grouped.mean()\n",
    "total_points_added = grouped.sum()\n",
    "combined_stats = pd.DataFrame({\n",
    "    'Average SITR': average_points_added,\n",
    "    'Total SITR': total_points_added\n",
    "}).reset_index()\n",
    "combined_stats[\"tackleOpportunities\"]=combined_stats[\"Total SITR\"]/combined_stats[\"Average SITR\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 433,
   "id": "7bcf195c",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined2=combined_stats[combined_stats[\"tackleOpportunities\"]>7]\n",
    "combined3=pd.merge(combined2, players, on=\"displayName\",how=\"left\")\n",
    "combined3.drop([\"nflId\",\"height\",\"weight\",\"birthDate\",\"collegeName\"],axis=1,inplace=True)\n",
    "combined3.loc[combined3['position'].isin(['QB','OLB','ILB','MLB']), 'position'] = 'LB'\n",
    "combined3.loc[combined3['position'].isin(['G', 'RB','CB','FS','SS','DB']), 'position'] = 'DB'\n",
    "combined3.loc[combined3['position'].isin(['DT','DE','NT']),'position']='DL'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 431,
   "id": "20dea881",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>displayName</th>\n",
       "      <th>Average SITR</th>\n",
       "      <th>Total SITR</th>\n",
       "      <th>tackleOpportunities</th>\n",
       "      <th>position</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>129</th>\n",
       "      <td>Dre'Mont Jones</td>\n",
       "      <td>2.540556</td>\n",
       "      <td>22.865000</td>\n",
       "      <td>9.0</td>\n",
       "      <td>DL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>203</th>\n",
       "      <td>John Franklin-Myers</td>\n",
       "      <td>2.234186</td>\n",
       "      <td>24.576044</td>\n",
       "      <td>11.0</td>\n",
       "      <td>DL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>Jermaine Johnson</td>\n",
       "      <td>2.230881</td>\n",
       "      <td>17.847051</td>\n",
       "      <td>8.0</td>\n",
       "      <td>DL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>Christian Wilkins</td>\n",
       "      <td>2.071867</td>\n",
       "      <td>35.221735</td>\n",
       "      <td>17.0</td>\n",
       "      <td>DL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>161</th>\n",
       "      <td>Hassan Ridgeway</td>\n",
       "      <td>1.734139</td>\n",
       "      <td>13.873109</td>\n",
       "      <td>8.0</td>\n",
       "      <td>DL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Al Woods</td>\n",
       "      <td>1.670947</td>\n",
       "      <td>25.064206</td>\n",
       "      <td>15.0</td>\n",
       "      <td>DL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>Folorunso Fatukasi</td>\n",
       "      <td>1.629233</td>\n",
       "      <td>21.180027</td>\n",
       "      <td>13.0</td>\n",
       "      <td>DL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>225</th>\n",
       "      <td>Josh Sweat</td>\n",
       "      <td>1.456566</td>\n",
       "      <td>27.674757</td>\n",
       "      <td>19.0</td>\n",
       "      <td>DL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>320</th>\n",
       "      <td>Osa Odighizuwa</td>\n",
       "      <td>1.434030</td>\n",
       "      <td>27.246563</td>\n",
       "      <td>19.0</td>\n",
       "      <td>DL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Aaron Donald</td>\n",
       "      <td>1.341627</td>\n",
       "      <td>28.174170</td>\n",
       "      <td>21.0</td>\n",
       "      <td>DL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>321</th>\n",
       "      <td>Otito Ogbonnia</td>\n",
       "      <td>1.288613</td>\n",
       "      <td>10.308900</td>\n",
       "      <td>8.0</td>\n",
       "      <td>DL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>357</th>\n",
       "      <td>Sebastian Joseph</td>\n",
       "      <td>1.288591</td>\n",
       "      <td>16.751681</td>\n",
       "      <td>13.0</td>\n",
       "      <td>DL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>264</th>\n",
       "      <td>Lawrence Guy</td>\n",
       "      <td>1.189592</td>\n",
       "      <td>9.516737</td>\n",
       "      <td>8.0</td>\n",
       "      <td>DL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>Demarcus Lawrence</td>\n",
       "      <td>1.165084</td>\n",
       "      <td>10.485757</td>\n",
       "      <td>9.0</td>\n",
       "      <td>DL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>302</th>\n",
       "      <td>Montez Sweat</td>\n",
       "      <td>1.131448</td>\n",
       "      <td>15.840269</td>\n",
       "      <td>14.0</td>\n",
       "      <td>DL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>163</th>\n",
       "      <td>Isaac Rochell</td>\n",
       "      <td>1.131094</td>\n",
       "      <td>11.310935</td>\n",
       "      <td>10.0</td>\n",
       "      <td>DL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>208</th>\n",
       "      <td>Jonathan Bullard</td>\n",
       "      <td>1.063646</td>\n",
       "      <td>10.636462</td>\n",
       "      <td>10.0</td>\n",
       "      <td>DL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>361</th>\n",
       "      <td>Shy Tuttle</td>\n",
       "      <td>1.059902</td>\n",
       "      <td>8.479219</td>\n",
       "      <td>8.0</td>\n",
       "      <td>DL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>Broderick Washington</td>\n",
       "      <td>0.925971</td>\n",
       "      <td>7.407766</td>\n",
       "      <td>8.0</td>\n",
       "      <td>DL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>249</th>\n",
       "      <td>Kevin Strong</td>\n",
       "      <td>0.915132</td>\n",
       "      <td>9.151320</td>\n",
       "      <td>10.0</td>\n",
       "      <td>DL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>244</th>\n",
       "      <td>Kenny Clark</td>\n",
       "      <td>0.913475</td>\n",
       "      <td>17.356019</td>\n",
       "      <td>19.0</td>\n",
       "      <td>DL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>Calais Campbell</td>\n",
       "      <td>0.892151</td>\n",
       "      <td>8.029361</td>\n",
       "      <td>9.0</td>\n",
       "      <td>DL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>310</th>\n",
       "      <td>Neville Gallimore</td>\n",
       "      <td>0.880754</td>\n",
       "      <td>7.046032</td>\n",
       "      <td>8.0</td>\n",
       "      <td>DL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>209</th>\n",
       "      <td>Jonathan Greenard</td>\n",
       "      <td>0.866641</td>\n",
       "      <td>14.732902</td>\n",
       "      <td>17.0</td>\n",
       "      <td>DL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162</th>\n",
       "      <td>Henry Anderson</td>\n",
       "      <td>0.857550</td>\n",
       "      <td>8.575502</td>\n",
       "      <td>10.0</td>\n",
       "      <td>DL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>385</th>\n",
       "      <td>Trey Hendrickson</td>\n",
       "      <td>0.826068</td>\n",
       "      <td>10.738880</td>\n",
       "      <td>13.0</td>\n",
       "      <td>DL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>300</th>\n",
       "      <td>Mike Purcell</td>\n",
       "      <td>0.823257</td>\n",
       "      <td>9.055822</td>\n",
       "      <td>11.0</td>\n",
       "      <td>DL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>164</th>\n",
       "      <td>Isaiah Buggs</td>\n",
       "      <td>0.816521</td>\n",
       "      <td>10.614774</td>\n",
       "      <td>13.0</td>\n",
       "      <td>DL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>254</th>\n",
       "      <td>Kwity Paye</td>\n",
       "      <td>0.815738</td>\n",
       "      <td>12.236066</td>\n",
       "      <td>15.0</td>\n",
       "      <td>DL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>154</th>\n",
       "      <td>Greg Gaines</td>\n",
       "      <td>0.808657</td>\n",
       "      <td>12.129852</td>\n",
       "      <td>15.0</td>\n",
       "      <td>DL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>234</th>\n",
       "      <td>Justin Madubuike</td>\n",
       "      <td>0.750990</td>\n",
       "      <td>10.513864</td>\n",
       "      <td>14.0</td>\n",
       "      <td>DL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Adam Gotsis</td>\n",
       "      <td>0.727404</td>\n",
       "      <td>6.546637</td>\n",
       "      <td>9.0</td>\n",
       "      <td>DL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>D.J. Jones</td>\n",
       "      <td>0.723783</td>\n",
       "      <td>13.028102</td>\n",
       "      <td>18.0</td>\n",
       "      <td>DL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>157</th>\n",
       "      <td>Grover Stewart</td>\n",
       "      <td>0.700409</td>\n",
       "      <td>20.311847</td>\n",
       "      <td>29.0</td>\n",
       "      <td>DL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>Chris Wormley</td>\n",
       "      <td>0.675875</td>\n",
       "      <td>9.462256</td>\n",
       "      <td>14.0</td>\n",
       "      <td>DL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>Bilal Nichols</td>\n",
       "      <td>0.668139</td>\n",
       "      <td>5.345115</td>\n",
       "      <td>8.0</td>\n",
       "      <td>DL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>337</th>\n",
       "      <td>Randy Gregory</td>\n",
       "      <td>0.661716</td>\n",
       "      <td>5.955447</td>\n",
       "      <td>9.0</td>\n",
       "      <td>DL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>Davon Hamilton</td>\n",
       "      <td>0.635328</td>\n",
       "      <td>9.529917</td>\n",
       "      <td>15.0</td>\n",
       "      <td>DL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>288</th>\n",
       "      <td>Maxx Crosby</td>\n",
       "      <td>0.620724</td>\n",
       "      <td>15.518092</td>\n",
       "      <td>25.0</td>\n",
       "      <td>DL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>D.J. Reader</td>\n",
       "      <td>0.618260</td>\n",
       "      <td>6.182595</td>\n",
       "      <td>10.0</td>\n",
       "      <td>DL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>336</th>\n",
       "      <td>Rakeem Nunez-Roches</td>\n",
       "      <td>0.600482</td>\n",
       "      <td>8.406746</td>\n",
       "      <td>14.0</td>\n",
       "      <td>DL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>David Onyemata</td>\n",
       "      <td>0.577789</td>\n",
       "      <td>6.933474</td>\n",
       "      <td>12.0</td>\n",
       "      <td>DL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>Bryan Mone</td>\n",
       "      <td>0.553275</td>\n",
       "      <td>6.086024</td>\n",
       "      <td>11.0</td>\n",
       "      <td>DL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>356</th>\n",
       "      <td>Sam Hubbard</td>\n",
       "      <td>0.546988</td>\n",
       "      <td>7.110842</td>\n",
       "      <td>13.0</td>\n",
       "      <td>DL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>Carl Granderson</td>\n",
       "      <td>0.542648</td>\n",
       "      <td>5.969126</td>\n",
       "      <td>11.0</td>\n",
       "      <td>DL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>Cameron Heyward</td>\n",
       "      <td>0.541751</td>\n",
       "      <td>9.751523</td>\n",
       "      <td>18.0</td>\n",
       "      <td>DL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>404</th>\n",
       "      <td>Zach Sieler</td>\n",
       "      <td>0.538624</td>\n",
       "      <td>8.617986</td>\n",
       "      <td>16.0</td>\n",
       "      <td>DL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>Dean Lowry</td>\n",
       "      <td>0.536755</td>\n",
       "      <td>5.904305</td>\n",
       "      <td>11.0</td>\n",
       "      <td>DL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>207</th>\n",
       "      <td>Jonathan Allen</td>\n",
       "      <td>0.506765</td>\n",
       "      <td>8.108240</td>\n",
       "      <td>16.0</td>\n",
       "      <td>DL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Andrew Billings</td>\n",
       "      <td>0.503869</td>\n",
       "      <td>7.558034</td>\n",
       "      <td>15.0</td>\n",
       "      <td>DL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>285</th>\n",
       "      <td>Matt Ioannidis</td>\n",
       "      <td>0.494260</td>\n",
       "      <td>6.919646</td>\n",
       "      <td>14.0</td>\n",
       "      <td>DL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>212</th>\n",
       "      <td>Jordan Davis</td>\n",
       "      <td>0.487137</td>\n",
       "      <td>4.384237</td>\n",
       "      <td>9.0</td>\n",
       "      <td>DL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>Cameron Jordan</td>\n",
       "      <td>0.486904</td>\n",
       "      <td>11.198786</td>\n",
       "      <td>23.0</td>\n",
       "      <td>DL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Al-Quadin Muhammad</td>\n",
       "      <td>0.473118</td>\n",
       "      <td>5.204296</td>\n",
       "      <td>11.0</td>\n",
       "      <td>DL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>Chandler Jones</td>\n",
       "      <td>0.464411</td>\n",
       "      <td>5.108526</td>\n",
       "      <td>11.0</td>\n",
       "      <td>DL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>312</th>\n",
       "      <td>Nicholas Williams</td>\n",
       "      <td>0.459663</td>\n",
       "      <td>7.814273</td>\n",
       "      <td>17.0</td>\n",
       "      <td>DL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>400</th>\n",
       "      <td>Yannick Ngakoue</td>\n",
       "      <td>0.435350</td>\n",
       "      <td>6.094897</td>\n",
       "      <td>14.0</td>\n",
       "      <td>DL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>372</th>\n",
       "      <td>Taven Bryan</td>\n",
       "      <td>0.406066</td>\n",
       "      <td>4.466727</td>\n",
       "      <td>11.0</td>\n",
       "      <td>DL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>Deatrich Wise</td>\n",
       "      <td>0.382218</td>\n",
       "      <td>4.968831</td>\n",
       "      <td>13.0</td>\n",
       "      <td>DL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>355</th>\n",
       "      <td>Roy Robertson-Harris</td>\n",
       "      <td>0.381544</td>\n",
       "      <td>10.301699</td>\n",
       "      <td>27.0</td>\n",
       "      <td>DL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>192</th>\n",
       "      <td>Jeffery Simmons</td>\n",
       "      <td>0.366643</td>\n",
       "      <td>6.599567</td>\n",
       "      <td>18.0</td>\n",
       "      <td>DL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151</th>\n",
       "      <td>Grady Jarrett</td>\n",
       "      <td>0.358297</td>\n",
       "      <td>9.315727</td>\n",
       "      <td>26.0</td>\n",
       "      <td>DL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>333</th>\n",
       "      <td>Quinnen Williams</td>\n",
       "      <td>0.349614</td>\n",
       "      <td>9.439579</td>\n",
       "      <td>27.0</td>\n",
       "      <td>DL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>186</th>\n",
       "      <td>Javon Kinlaw</td>\n",
       "      <td>0.346402</td>\n",
       "      <td>3.117615</td>\n",
       "      <td>9.0</td>\n",
       "      <td>DL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A'Shawn Robinson</td>\n",
       "      <td>0.345686</td>\n",
       "      <td>4.148234</td>\n",
       "      <td>12.0</td>\n",
       "      <td>DL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Abdullah Anderson</td>\n",
       "      <td>0.319921</td>\n",
       "      <td>2.879288</td>\n",
       "      <td>9.0</td>\n",
       "      <td>DL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>185</th>\n",
       "      <td>Javon Hargrave</td>\n",
       "      <td>0.318849</td>\n",
       "      <td>3.188487</td>\n",
       "      <td>10.0</td>\n",
       "      <td>DL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>Dalvin Tomlinson</td>\n",
       "      <td>0.311510</td>\n",
       "      <td>4.672646</td>\n",
       "      <td>15.0</td>\n",
       "      <td>DL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>363</th>\n",
       "      <td>Solomon Thomas</td>\n",
       "      <td>0.305936</td>\n",
       "      <td>4.283111</td>\n",
       "      <td>14.0</td>\n",
       "      <td>DL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>328</th>\n",
       "      <td>Poona Ford</td>\n",
       "      <td>0.267476</td>\n",
       "      <td>5.349521</td>\n",
       "      <td>20.0</td>\n",
       "      <td>DL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>Chris Jones</td>\n",
       "      <td>0.257376</td>\n",
       "      <td>5.404898</td>\n",
       "      <td>21.0</td>\n",
       "      <td>DL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>378</th>\n",
       "      <td>Tershawn Wharton</td>\n",
       "      <td>0.247390</td>\n",
       "      <td>2.226513</td>\n",
       "      <td>9.0</td>\n",
       "      <td>DL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Alex Wright</td>\n",
       "      <td>0.245987</td>\n",
       "      <td>2.213885</td>\n",
       "      <td>9.0</td>\n",
       "      <td>DL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>391</th>\n",
       "      <td>Vita Vea</td>\n",
       "      <td>0.203980</td>\n",
       "      <td>1.835822</td>\n",
       "      <td>9.0</td>\n",
       "      <td>DL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>248</th>\n",
       "      <td>Kevin Givens</td>\n",
       "      <td>0.203454</td>\n",
       "      <td>1.627636</td>\n",
       "      <td>8.0</td>\n",
       "      <td>DL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>343</th>\n",
       "      <td>Rasheem Green</td>\n",
       "      <td>0.197370</td>\n",
       "      <td>1.973695</td>\n",
       "      <td>10.0</td>\n",
       "      <td>DL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156</th>\n",
       "      <td>Gregory Rousseau</td>\n",
       "      <td>0.171271</td>\n",
       "      <td>1.541443</td>\n",
       "      <td>9.0</td>\n",
       "      <td>DL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>167</th>\n",
       "      <td>J.J. Watt</td>\n",
       "      <td>0.170044</td>\n",
       "      <td>1.700442</td>\n",
       "      <td>10.0</td>\n",
       "      <td>DL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>354</th>\n",
       "      <td>Roy Lopez</td>\n",
       "      <td>0.161224</td>\n",
       "      <td>1.612237</td>\n",
       "      <td>10.0</td>\n",
       "      <td>DL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>334</th>\n",
       "      <td>Quinton Bohanna</td>\n",
       "      <td>0.143672</td>\n",
       "      <td>1.436719</td>\n",
       "      <td>10.0</td>\n",
       "      <td>DL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>Derrick Brown</td>\n",
       "      <td>0.133872</td>\n",
       "      <td>1.874215</td>\n",
       "      <td>14.0</td>\n",
       "      <td>DL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>Daron Payne</td>\n",
       "      <td>0.121773</td>\n",
       "      <td>2.070143</td>\n",
       "      <td>17.0</td>\n",
       "      <td>DL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>Austin Johnson</td>\n",
       "      <td>0.118024</td>\n",
       "      <td>1.770360</td>\n",
       "      <td>15.0</td>\n",
       "      <td>DL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>DeForest Buckner</td>\n",
       "      <td>0.116612</td>\n",
       "      <td>1.749186</td>\n",
       "      <td>15.0</td>\n",
       "      <td>DL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>Frank Clark</td>\n",
       "      <td>0.116529</td>\n",
       "      <td>1.048762</td>\n",
       "      <td>9.0</td>\n",
       "      <td>DL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Angelo Blackson</td>\n",
       "      <td>0.113124</td>\n",
       "      <td>1.923108</td>\n",
       "      <td>17.0</td>\n",
       "      <td>DL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>233</th>\n",
       "      <td>Justin Jones</td>\n",
       "      <td>0.108981</td>\n",
       "      <td>2.506553</td>\n",
       "      <td>23.0</td>\n",
       "      <td>DL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>Carl Davis</td>\n",
       "      <td>0.100040</td>\n",
       "      <td>0.900361</td>\n",
       "      <td>9.0</td>\n",
       "      <td>DL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>Jerry Tillery</td>\n",
       "      <td>0.086168</td>\n",
       "      <td>0.689342</td>\n",
       "      <td>8.0</td>\n",
       "      <td>DL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>402</th>\n",
       "      <td>Zach Allen</td>\n",
       "      <td>0.078377</td>\n",
       "      <td>1.018897</td>\n",
       "      <td>13.0</td>\n",
       "      <td>DL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>Davon Godchaux</td>\n",
       "      <td>0.064443</td>\n",
       "      <td>1.095538</td>\n",
       "      <td>17.0</td>\n",
       "      <td>DL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139</th>\n",
       "      <td>Emmanuel Ogbah</td>\n",
       "      <td>0.046731</td>\n",
       "      <td>0.373846</td>\n",
       "      <td>8.0</td>\n",
       "      <td>DL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127</th>\n",
       "      <td>Dorance Armstrong</td>\n",
       "      <td>0.024131</td>\n",
       "      <td>0.386098</td>\n",
       "      <td>16.0</td>\n",
       "      <td>DL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144</th>\n",
       "      <td>Fletcher Cox</td>\n",
       "      <td>0.005922</td>\n",
       "      <td>0.076982</td>\n",
       "      <td>13.0</td>\n",
       "      <td>DL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>267</th>\n",
       "      <td>Leonard Floyd</td>\n",
       "      <td>0.002994</td>\n",
       "      <td>0.038926</td>\n",
       "      <td>13.0</td>\n",
       "      <td>DL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>273</th>\n",
       "      <td>Maliek Collins</td>\n",
       "      <td>-0.004793</td>\n",
       "      <td>-0.081486</td>\n",
       "      <td>17.0</td>\n",
       "      <td>DL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>367</th>\n",
       "      <td>Ta'Quon Graham</td>\n",
       "      <td>-0.022626</td>\n",
       "      <td>-0.362016</td>\n",
       "      <td>16.0</td>\n",
       "      <td>DL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>230</th>\n",
       "      <td>Justin Ellis</td>\n",
       "      <td>-0.033907</td>\n",
       "      <td>-0.339070</td>\n",
       "      <td>10.0</td>\n",
       "      <td>DL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>342</th>\n",
       "      <td>Rashard Lawrence</td>\n",
       "      <td>-0.044399</td>\n",
       "      <td>-0.443992</td>\n",
       "      <td>10.0</td>\n",
       "      <td>DL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>184</th>\n",
       "      <td>Jarran Reed</td>\n",
       "      <td>-0.063465</td>\n",
       "      <td>-0.634648</td>\n",
       "      <td>10.0</td>\n",
       "      <td>DL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>314</th>\n",
       "      <td>Nick Bosa</td>\n",
       "      <td>-0.076467</td>\n",
       "      <td>-0.994077</td>\n",
       "      <td>13.0</td>\n",
       "      <td>DL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>386</th>\n",
       "      <td>Trysten Hill</td>\n",
       "      <td>-0.093641</td>\n",
       "      <td>-1.310973</td>\n",
       "      <td>14.0</td>\n",
       "      <td>DL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>335</th>\n",
       "      <td>Quinton Jefferson</td>\n",
       "      <td>-0.109362</td>\n",
       "      <td>-0.874893</td>\n",
       "      <td>8.0</td>\n",
       "      <td>DL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>Derrick Nnadi</td>\n",
       "      <td>-0.126829</td>\n",
       "      <td>-1.014630</td>\n",
       "      <td>8.0</td>\n",
       "      <td>DL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>380</th>\n",
       "      <td>Travis Jones</td>\n",
       "      <td>-0.128345</td>\n",
       "      <td>-1.026759</td>\n",
       "      <td>8.0</td>\n",
       "      <td>DL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159</th>\n",
       "      <td>Harrison Phillips</td>\n",
       "      <td>-0.137766</td>\n",
       "      <td>-2.204260</td>\n",
       "      <td>16.0</td>\n",
       "      <td>DL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>379</th>\n",
       "      <td>Tim Settle</td>\n",
       "      <td>-0.145522</td>\n",
       "      <td>-1.309698</td>\n",
       "      <td>9.0</td>\n",
       "      <td>DL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Aidan Hutchinson</td>\n",
       "      <td>-0.150795</td>\n",
       "      <td>-2.563517</td>\n",
       "      <td>17.0</td>\n",
       "      <td>DL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>319</th>\n",
       "      <td>Ogbonnia Okoronkwo</td>\n",
       "      <td>-0.168842</td>\n",
       "      <td>-1.857264</td>\n",
       "      <td>11.0</td>\n",
       "      <td>DL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>D.J. Davidson</td>\n",
       "      <td>-0.172964</td>\n",
       "      <td>-1.383709</td>\n",
       "      <td>8.0</td>\n",
       "      <td>DL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>374</th>\n",
       "      <td>Tedarrell Slaton</td>\n",
       "      <td>-0.194361</td>\n",
       "      <td>-1.749249</td>\n",
       "      <td>9.0</td>\n",
       "      <td>DL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Alim McNeill</td>\n",
       "      <td>-0.195925</td>\n",
       "      <td>-3.330717</td>\n",
       "      <td>17.0</td>\n",
       "      <td>DL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>262</th>\n",
       "      <td>Larry Ogunjobi</td>\n",
       "      <td>-0.204298</td>\n",
       "      <td>-3.064471</td>\n",
       "      <td>15.0</td>\n",
       "      <td>DL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>246</th>\n",
       "      <td>Kentavius Street</td>\n",
       "      <td>-0.215116</td>\n",
       "      <td>-1.936047</td>\n",
       "      <td>9.0</td>\n",
       "      <td>DL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>266</th>\n",
       "      <td>Leki Fotu</td>\n",
       "      <td>-0.218512</td>\n",
       "      <td>-1.966604</td>\n",
       "      <td>9.0</td>\n",
       "      <td>DL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>394</th>\n",
       "      <td>William Gholston</td>\n",
       "      <td>-0.238660</td>\n",
       "      <td>-4.295882</td>\n",
       "      <td>18.0</td>\n",
       "      <td>DL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>294</th>\n",
       "      <td>Michael Dwumfour</td>\n",
       "      <td>-0.238755</td>\n",
       "      <td>-2.626310</td>\n",
       "      <td>11.0</td>\n",
       "      <td>DL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299</th>\n",
       "      <td>Mike Pennel</td>\n",
       "      <td>-0.306237</td>\n",
       "      <td>-2.449893</td>\n",
       "      <td>8.0</td>\n",
       "      <td>DL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>387</th>\n",
       "      <td>Tyquan Lewis</td>\n",
       "      <td>-0.335563</td>\n",
       "      <td>-3.691193</td>\n",
       "      <td>11.0</td>\n",
       "      <td>DL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>305</th>\n",
       "      <td>Myles Garrett</td>\n",
       "      <td>-0.346655</td>\n",
       "      <td>-3.119894</td>\n",
       "      <td>9.0</td>\n",
       "      <td>DL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>Carl Lawson</td>\n",
       "      <td>-0.355666</td>\n",
       "      <td>-2.845325</td>\n",
       "      <td>8.0</td>\n",
       "      <td>DL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>253</th>\n",
       "      <td>Kurt Hinish</td>\n",
       "      <td>-0.361706</td>\n",
       "      <td>-3.978761</td>\n",
       "      <td>11.0</td>\n",
       "      <td>DL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>DeShawn Williams</td>\n",
       "      <td>-0.396161</td>\n",
       "      <td>-4.753927</td>\n",
       "      <td>12.0</td>\n",
       "      <td>DL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>Jerry Hughes</td>\n",
       "      <td>-0.508333</td>\n",
       "      <td>-8.133322</td>\n",
       "      <td>16.0</td>\n",
       "      <td>DL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>B.J. Hill</td>\n",
       "      <td>-0.650958</td>\n",
       "      <td>-5.858625</td>\n",
       "      <td>9.0</td>\n",
       "      <td>DL</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              displayName  Average SITR  Total SITR  tackleOpportunities  \\\n",
       "129        Dre'Mont Jones      2.540556   22.865000                  9.0   \n",
       "203   John Franklin-Myers      2.234186   24.576044                 11.0   \n",
       "195      Jermaine Johnson      2.230881   17.847051                  8.0   \n",
       "76      Christian Wilkins      2.071867   35.221735                 17.0   \n",
       "161       Hassan Ridgeway      1.734139   13.873109                  8.0   \n",
       "13               Al Woods      1.670947   25.064206                 15.0   \n",
       "145    Folorunso Fatukasi      1.629233   21.180027                 13.0   \n",
       "225            Josh Sweat      1.456566   27.674757                 19.0   \n",
       "320        Osa Odighizuwa      1.434030   27.246563                 19.0   \n",
       "2            Aaron Donald      1.341627   28.174170                 21.0   \n",
       "321        Otito Ogbonnia      1.288613   10.308900                  8.0   \n",
       "357      Sebastian Joseph      1.288591   16.751681                 13.0   \n",
       "264          Lawrence Guy      1.189592    9.516737                  8.0   \n",
       "110     Demarcus Lawrence      1.165084   10.485757                  9.0   \n",
       "302          Montez Sweat      1.131448   15.840269                 14.0   \n",
       "163         Isaac Rochell      1.131094   11.310935                 10.0   \n",
       "208      Jonathan Bullard      1.063646   10.636462                 10.0   \n",
       "361            Shy Tuttle      1.059902    8.479219                  8.0   \n",
       "47   Broderick Washington      0.925971    7.407766                  8.0   \n",
       "249          Kevin Strong      0.915132    9.151320                 10.0   \n",
       "244           Kenny Clark      0.913475   17.356019                 19.0   \n",
       "55        Calais Campbell      0.892151    8.029361                  9.0   \n",
       "310     Neville Gallimore      0.880754    7.046032                  8.0   \n",
       "209     Jonathan Greenard      0.866641   14.732902                 17.0   \n",
       "162        Henry Anderson      0.857550    8.575502                 10.0   \n",
       "385      Trey Hendrickson      0.826068   10.738880                 13.0   \n",
       "300          Mike Purcell      0.823257    9.055822                 11.0   \n",
       "164          Isaiah Buggs      0.816521   10.614774                 13.0   \n",
       "254            Kwity Paye      0.815738   12.236066                 15.0   \n",
       "154           Greg Gaines      0.808657   12.129852                 15.0   \n",
       "234      Justin Madubuike      0.750990   10.513864                 14.0   \n",
       "4             Adam Gotsis      0.727404    6.546637                  9.0   \n",
       "83             D.J. Jones      0.723783   13.028102                 18.0   \n",
       "157        Grover Stewart      0.700409   20.311847                 29.0   \n",
       "74          Chris Wormley      0.675875    9.462256                 14.0   \n",
       "37          Bilal Nichols      0.668139    5.345115                  8.0   \n",
       "337         Randy Gregory      0.661716    5.955447                  9.0   \n",
       "103        Davon Hamilton      0.635328    9.529917                 15.0   \n",
       "288           Maxx Crosby      0.620724   15.518092                 25.0   \n",
       "84            D.J. Reader      0.618260    6.182595                 10.0   \n",
       "336   Rakeem Nunez-Roches      0.600482    8.406746                 14.0   \n",
       "101        David Onyemata      0.577789    6.933474                 12.0   \n",
       "48             Bryan Mone      0.553275    6.086024                 11.0   \n",
       "356           Sam Hubbard      0.546988    7.110842                 13.0   \n",
       "63        Carl Granderson      0.542648    5.969126                 11.0   \n",
       "58        Cameron Heyward      0.541751    9.751523                 18.0   \n",
       "404           Zach Sieler      0.538624    8.617986                 16.0   \n",
       "108            Dean Lowry      0.536755    5.904305                 11.0   \n",
       "207        Jonathan Allen      0.506765    8.108240                 16.0   \n",
       "24        Andrew Billings      0.503869    7.558034                 15.0   \n",
       "285        Matt Ioannidis      0.494260    6.919646                 14.0   \n",
       "212          Jordan Davis      0.487137    4.384237                  9.0   \n",
       "59         Cameron Jordan      0.486904   11.198786                 23.0   \n",
       "14     Al-Quadin Muhammad      0.473118    5.204296                 11.0   \n",
       "67         Chandler Jones      0.464411    5.108526                 11.0   \n",
       "312     Nicholas Williams      0.459663    7.814273                 17.0   \n",
       "400       Yannick Ngakoue      0.435350    6.094897                 14.0   \n",
       "372           Taven Bryan      0.406066    4.466727                 11.0   \n",
       "109         Deatrich Wise      0.382218    4.968831                 13.0   \n",
       "355  Roy Robertson-Harris      0.381544   10.301699                 27.0   \n",
       "192       Jeffery Simmons      0.366643    6.599567                 18.0   \n",
       "151         Grady Jarrett      0.358297    9.315727                 26.0   \n",
       "333      Quinnen Williams      0.349614    9.439579                 27.0   \n",
       "186          Javon Kinlaw      0.346402    3.117615                  9.0   \n",
       "0        A'Shawn Robinson      0.345686    4.148234                 12.0   \n",
       "3       Abdullah Anderson      0.319921    2.879288                  9.0   \n",
       "185        Javon Hargrave      0.318849    3.188487                 10.0   \n",
       "87       Dalvin Tomlinson      0.311510    4.672646                 15.0   \n",
       "363        Solomon Thomas      0.305936    4.283111                 14.0   \n",
       "328            Poona Ford      0.267476    5.349521                 20.0   \n",
       "73            Chris Jones      0.257376    5.404898                 21.0   \n",
       "378      Tershawn Wharton      0.247390    2.226513                  9.0   \n",
       "18            Alex Wright      0.245987    2.213885                  9.0   \n",
       "391              Vita Vea      0.203980    1.835822                  9.0   \n",
       "248          Kevin Givens      0.203454    1.627636                  8.0   \n",
       "343         Rasheem Green      0.197370    1.973695                 10.0   \n",
       "156      Gregory Rousseau      0.171271    1.541443                  9.0   \n",
       "167             J.J. Watt      0.170044    1.700442                 10.0   \n",
       "354             Roy Lopez      0.161224    1.612237                 10.0   \n",
       "334       Quinton Bohanna      0.143672    1.436719                 10.0   \n",
       "116         Derrick Brown      0.133872    1.874215                 14.0   \n",
       "96            Daron Payne      0.121773    2.070143                 17.0   \n",
       "32         Austin Johnson      0.118024    1.770360                 15.0   \n",
       "105      DeForest Buckner      0.116612    1.749186                 15.0   \n",
       "147           Frank Clark      0.116529    1.048762                  9.0   \n",
       "25        Angelo Blackson      0.113124    1.923108                 17.0   \n",
       "233          Justin Jones      0.108981    2.506553                 23.0   \n",
       "62             Carl Davis      0.100040    0.900361                  9.0   \n",
       "198         Jerry Tillery      0.086168    0.689342                  8.0   \n",
       "402            Zach Allen      0.078377    1.018897                 13.0   \n",
       "102        Davon Godchaux      0.064443    1.095538                 17.0   \n",
       "139        Emmanuel Ogbah      0.046731    0.373846                  8.0   \n",
       "127     Dorance Armstrong      0.024131    0.386098                 16.0   \n",
       "144          Fletcher Cox      0.005922    0.076982                 13.0   \n",
       "267         Leonard Floyd      0.002994    0.038926                 13.0   \n",
       "273        Maliek Collins     -0.004793   -0.081486                 17.0   \n",
       "367        Ta'Quon Graham     -0.022626   -0.362016                 16.0   \n",
       "230          Justin Ellis     -0.033907   -0.339070                 10.0   \n",
       "342      Rashard Lawrence     -0.044399   -0.443992                 10.0   \n",
       "184           Jarran Reed     -0.063465   -0.634648                 10.0   \n",
       "314             Nick Bosa     -0.076467   -0.994077                 13.0   \n",
       "386          Trysten Hill     -0.093641   -1.310973                 14.0   \n",
       "335     Quinton Jefferson     -0.109362   -0.874893                  8.0   \n",
       "117         Derrick Nnadi     -0.126829   -1.014630                  8.0   \n",
       "380          Travis Jones     -0.128345   -1.026759                  8.0   \n",
       "159     Harrison Phillips     -0.137766   -2.204260                 16.0   \n",
       "379            Tim Settle     -0.145522   -1.309698                  9.0   \n",
       "11       Aidan Hutchinson     -0.150795   -2.563517                 17.0   \n",
       "319    Ogbonnia Okoronkwo     -0.168842   -1.857264                 11.0   \n",
       "82          D.J. Davidson     -0.172964   -1.383709                  8.0   \n",
       "374      Tedarrell Slaton     -0.194361   -1.749249                  9.0   \n",
       "19           Alim McNeill     -0.195925   -3.330717                 17.0   \n",
       "262        Larry Ogunjobi     -0.204298   -3.064471                 15.0   \n",
       "246      Kentavius Street     -0.215116   -1.936047                  9.0   \n",
       "266             Leki Fotu     -0.218512   -1.966604                  9.0   \n",
       "394      William Gholston     -0.238660   -4.295882                 18.0   \n",
       "294      Michael Dwumfour     -0.238755   -2.626310                 11.0   \n",
       "299           Mike Pennel     -0.306237   -2.449893                  8.0   \n",
       "387          Tyquan Lewis     -0.335563   -3.691193                 11.0   \n",
       "305         Myles Garrett     -0.346655   -3.119894                  9.0   \n",
       "64            Carl Lawson     -0.355666   -2.845325                  8.0   \n",
       "253           Kurt Hinish     -0.361706   -3.978761                 11.0   \n",
       "106      DeShawn Williams     -0.396161   -4.753927                 12.0   \n",
       "197          Jerry Hughes     -0.508333   -8.133322                 16.0   \n",
       "34              B.J. Hill     -0.650958   -5.858625                  9.0   \n",
       "\n",
       "    position  \n",
       "129       DL  \n",
       "203       DL  \n",
       "195       DL  \n",
       "76        DL  \n",
       "161       DL  \n",
       "13        DL  \n",
       "145       DL  \n",
       "225       DL  \n",
       "320       DL  \n",
       "2         DL  \n",
       "321       DL  \n",
       "357       DL  \n",
       "264       DL  \n",
       "110       DL  \n",
       "302       DL  \n",
       "163       DL  \n",
       "208       DL  \n",
       "361       DL  \n",
       "47        DL  \n",
       "249       DL  \n",
       "244       DL  \n",
       "55        DL  \n",
       "310       DL  \n",
       "209       DL  \n",
       "162       DL  \n",
       "385       DL  \n",
       "300       DL  \n",
       "164       DL  \n",
       "254       DL  \n",
       "154       DL  \n",
       "234       DL  \n",
       "4         DL  \n",
       "83        DL  \n",
       "157       DL  \n",
       "74        DL  \n",
       "37        DL  \n",
       "337       DL  \n",
       "103       DL  \n",
       "288       DL  \n",
       "84        DL  \n",
       "336       DL  \n",
       "101       DL  \n",
       "48        DL  \n",
       "356       DL  \n",
       "63        DL  \n",
       "58        DL  \n",
       "404       DL  \n",
       "108       DL  \n",
       "207       DL  \n",
       "24        DL  \n",
       "285       DL  \n",
       "212       DL  \n",
       "59        DL  \n",
       "14        DL  \n",
       "67        DL  \n",
       "312       DL  \n",
       "400       DL  \n",
       "372       DL  \n",
       "109       DL  \n",
       "355       DL  \n",
       "192       DL  \n",
       "151       DL  \n",
       "333       DL  \n",
       "186       DL  \n",
       "0         DL  \n",
       "3         DL  \n",
       "185       DL  \n",
       "87        DL  \n",
       "363       DL  \n",
       "328       DL  \n",
       "73        DL  \n",
       "378       DL  \n",
       "18        DL  \n",
       "391       DL  \n",
       "248       DL  \n",
       "343       DL  \n",
       "156       DL  \n",
       "167       DL  \n",
       "354       DL  \n",
       "334       DL  \n",
       "116       DL  \n",
       "96        DL  \n",
       "32        DL  \n",
       "105       DL  \n",
       "147       DL  \n",
       "25        DL  \n",
       "233       DL  \n",
       "62        DL  \n",
       "198       DL  \n",
       "402       DL  \n",
       "102       DL  \n",
       "139       DL  \n",
       "127       DL  \n",
       "144       DL  \n",
       "267       DL  \n",
       "273       DL  \n",
       "367       DL  \n",
       "230       DL  \n",
       "342       DL  \n",
       "184       DL  \n",
       "314       DL  \n",
       "386       DL  \n",
       "335       DL  \n",
       "117       DL  \n",
       "380       DL  \n",
       "159       DL  \n",
       "379       DL  \n",
       "11        DL  \n",
       "319       DL  \n",
       "82        DL  \n",
       "374       DL  \n",
       "19        DL  \n",
       "262       DL  \n",
       "246       DL  \n",
       "266       DL  \n",
       "394       DL  \n",
       "294       DL  \n",
       "299       DL  \n",
       "387       DL  \n",
       "305       DL  \n",
       "64        DL  \n",
       "253       DL  \n",
       "106       DL  \n",
       "197       DL  \n",
       "34        DL  "
      ]
     },
     "execution_count": 431,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined3[combined3[\"position\"]==\"DL\"].sort_values(by=\"Average SITR\",ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 434,
   "id": "b6079fdb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>displayName</th>\n",
       "      <th>Average SITR</th>\n",
       "      <th>Total SITR</th>\n",
       "      <th>tackleOpportunities</th>\n",
       "      <th>position</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>206</th>\n",
       "      <td>Jonas Griffith</td>\n",
       "      <td>3.466160</td>\n",
       "      <td>41.593916</td>\n",
       "      <td>12.0</td>\n",
       "      <td>LB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>Bobby Okereke</td>\n",
       "      <td>3.429262</td>\n",
       "      <td>68.585240</td>\n",
       "      <td>20.0</td>\n",
       "      <td>LB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>331</th>\n",
       "      <td>Quay Walker</td>\n",
       "      <td>3.327539</td>\n",
       "      <td>26.620308</td>\n",
       "      <td>8.0</td>\n",
       "      <td>LB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>250</th>\n",
       "      <td>Khalil Mack</td>\n",
       "      <td>3.313411</td>\n",
       "      <td>26.507288</td>\n",
       "      <td>8.0</td>\n",
       "      <td>LB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>239</th>\n",
       "      <td>Kamu Grugier-Hill</td>\n",
       "      <td>3.195736</td>\n",
       "      <td>67.110462</td>\n",
       "      <td>21.0</td>\n",
       "      <td>LB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120</th>\n",
       "      <td>Devin Bush</td>\n",
       "      <td>2.882395</td>\n",
       "      <td>34.588737</td>\n",
       "      <td>12.0</td>\n",
       "      <td>LB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>382</th>\n",
       "      <td>Tremaine Edmunds</td>\n",
       "      <td>2.805190</td>\n",
       "      <td>58.908990</td>\n",
       "      <td>21.0</td>\n",
       "      <td>LB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>Cole Holcomb</td>\n",
       "      <td>2.605566</td>\n",
       "      <td>41.689062</td>\n",
       "      <td>16.0</td>\n",
       "      <td>LB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>Jerome Baker</td>\n",
       "      <td>2.517002</td>\n",
       "      <td>47.823041</td>\n",
       "      <td>19.0</td>\n",
       "      <td>LB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>313</th>\n",
       "      <td>Nick Bolton</td>\n",
       "      <td>2.469760</td>\n",
       "      <td>39.516161</td>\n",
       "      <td>16.0</td>\n",
       "      <td>LB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201</th>\n",
       "      <td>Jihad Ward</td>\n",
       "      <td>2.468682</td>\n",
       "      <td>24.686823</td>\n",
       "      <td>10.0</td>\n",
       "      <td>LB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>327</th>\n",
       "      <td>Pete Werner</td>\n",
       "      <td>2.438530</td>\n",
       "      <td>68.278852</td>\n",
       "      <td>28.0</td>\n",
       "      <td>LB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>272</th>\n",
       "      <td>Malcolm Rodriguez</td>\n",
       "      <td>2.408633</td>\n",
       "      <td>50.581292</td>\n",
       "      <td>21.0</td>\n",
       "      <td>LB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131</th>\n",
       "      <td>Duke Riley</td>\n",
       "      <td>2.338314</td>\n",
       "      <td>23.383137</td>\n",
       "      <td>10.0</td>\n",
       "      <td>LB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>366</th>\n",
       "      <td>T.J. Edwards</td>\n",
       "      <td>2.329899</td>\n",
       "      <td>65.237168</td>\n",
       "      <td>28.0</td>\n",
       "      <td>LB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Akeem Davis-Gaither</td>\n",
       "      <td>2.317131</td>\n",
       "      <td>18.537045</td>\n",
       "      <td>8.0</td>\n",
       "      <td>LB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>377</th>\n",
       "      <td>Terrell Lewis</td>\n",
       "      <td>2.229057</td>\n",
       "      <td>17.832456</td>\n",
       "      <td>8.0</td>\n",
       "      <td>LB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>358</th>\n",
       "      <td>Shaq Thompson</td>\n",
       "      <td>2.192535</td>\n",
       "      <td>37.273103</td>\n",
       "      <td>17.0</td>\n",
       "      <td>LB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>Cody Barton</td>\n",
       "      <td>2.164552</td>\n",
       "      <td>56.278361</td>\n",
       "      <td>26.0</td>\n",
       "      <td>LB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>316</th>\n",
       "      <td>Nick Vigil</td>\n",
       "      <td>2.114520</td>\n",
       "      <td>27.488760</td>\n",
       "      <td>13.0</td>\n",
       "      <td>LB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>255</th>\n",
       "      <td>Kwon Alexander</td>\n",
       "      <td>2.102588</td>\n",
       "      <td>29.436225</td>\n",
       "      <td>14.0</td>\n",
       "      <td>LB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>307</th>\n",
       "      <td>Myles Jack</td>\n",
       "      <td>2.101765</td>\n",
       "      <td>56.747664</td>\n",
       "      <td>27.0</td>\n",
       "      <td>LB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>263</th>\n",
       "      <td>Lavonte David</td>\n",
       "      <td>2.059687</td>\n",
       "      <td>45.313118</td>\n",
       "      <td>22.0</td>\n",
       "      <td>LB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>269</th>\n",
       "      <td>Logan Wilson</td>\n",
       "      <td>2.048205</td>\n",
       "      <td>30.723074</td>\n",
       "      <td>15.0</td>\n",
       "      <td>LB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123</th>\n",
       "      <td>Devin White</td>\n",
       "      <td>2.018146</td>\n",
       "      <td>38.344781</td>\n",
       "      <td>19.0</td>\n",
       "      <td>LB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>Frankie Luvu</td>\n",
       "      <td>2.012672</td>\n",
       "      <td>64.405489</td>\n",
       "      <td>32.0</td>\n",
       "      <td>LB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Anthony Walker</td>\n",
       "      <td>1.959723</td>\n",
       "      <td>17.637506</td>\n",
       "      <td>9.0</td>\n",
       "      <td>LB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>259</th>\n",
       "      <td>Kyzir White</td>\n",
       "      <td>1.958792</td>\n",
       "      <td>33.299459</td>\n",
       "      <td>17.0</td>\n",
       "      <td>LB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>214</th>\n",
       "      <td>Jordan Hicks</td>\n",
       "      <td>1.950072</td>\n",
       "      <td>52.651941</td>\n",
       "      <td>27.0</td>\n",
       "      <td>LB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150</th>\n",
       "      <td>Germaine Pratt</td>\n",
       "      <td>1.924433</td>\n",
       "      <td>36.564222</td>\n",
       "      <td>19.0</td>\n",
       "      <td>LB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128</th>\n",
       "      <td>Dre Greenlaw</td>\n",
       "      <td>1.897343</td>\n",
       "      <td>49.330913</td>\n",
       "      <td>26.0</td>\n",
       "      <td>LB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130</th>\n",
       "      <td>Drue Tranquill</td>\n",
       "      <td>1.836622</td>\n",
       "      <td>36.732435</td>\n",
       "      <td>20.0</td>\n",
       "      <td>LB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134</th>\n",
       "      <td>E.J. Speed</td>\n",
       "      <td>1.834264</td>\n",
       "      <td>23.845430</td>\n",
       "      <td>13.0</td>\n",
       "      <td>LB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Alex Anzalone</td>\n",
       "      <td>1.791830</td>\n",
       "      <td>50.171235</td>\n",
       "      <td>28.0</td>\n",
       "      <td>LB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>Foyesade Oluokun</td>\n",
       "      <td>1.721150</td>\n",
       "      <td>41.307591</td>\n",
       "      <td>24.0</td>\n",
       "      <td>LB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>De'Vondre Campbell</td>\n",
       "      <td>1.698299</td>\n",
       "      <td>40.759168</td>\n",
       "      <td>24.0</td>\n",
       "      <td>LB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>406</th>\n",
       "      <td>Zaven Collins</td>\n",
       "      <td>1.675093</td>\n",
       "      <td>40.202235</td>\n",
       "      <td>24.0</td>\n",
       "      <td>LB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>174</th>\n",
       "      <td>Jahlani Tavai</td>\n",
       "      <td>1.668611</td>\n",
       "      <td>13.348891</td>\n",
       "      <td>8.0</td>\n",
       "      <td>LB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>217</th>\n",
       "      <td>Jordyn Brooks</td>\n",
       "      <td>1.667445</td>\n",
       "      <td>51.690799</td>\n",
       "      <td>31.0</td>\n",
       "      <td>LB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158</th>\n",
       "      <td>Haason Reddick</td>\n",
       "      <td>1.640141</td>\n",
       "      <td>24.602113</td>\n",
       "      <td>15.0</td>\n",
       "      <td>LB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>243</th>\n",
       "      <td>Kenneth Murray</td>\n",
       "      <td>1.607919</td>\n",
       "      <td>19.295031</td>\n",
       "      <td>12.0</td>\n",
       "      <td>LB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136</th>\n",
       "      <td>Elandon Roberts</td>\n",
       "      <td>1.587908</td>\n",
       "      <td>19.054898</td>\n",
       "      <td>12.0</td>\n",
       "      <td>LB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>Brian Burns</td>\n",
       "      <td>1.573931</td>\n",
       "      <td>26.756829</td>\n",
       "      <td>17.0</td>\n",
       "      <td>LB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>287</th>\n",
       "      <td>Matt Milano</td>\n",
       "      <td>1.555609</td>\n",
       "      <td>35.779016</td>\n",
       "      <td>23.0</td>\n",
       "      <td>LB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Alex Singleton</td>\n",
       "      <td>1.511479</td>\n",
       "      <td>13.603313</td>\n",
       "      <td>9.0</td>\n",
       "      <td>LB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>190</th>\n",
       "      <td>Jayon Brown</td>\n",
       "      <td>1.493973</td>\n",
       "      <td>26.891514</td>\n",
       "      <td>18.0</td>\n",
       "      <td>LB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>David Long</td>\n",
       "      <td>1.483389</td>\n",
       "      <td>43.018267</td>\n",
       "      <td>29.0</td>\n",
       "      <td>LB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>Danielle Hunter</td>\n",
       "      <td>1.479938</td>\n",
       "      <td>26.638881</td>\n",
       "      <td>18.0</td>\n",
       "      <td>LB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>353</th>\n",
       "      <td>Roquan Smith</td>\n",
       "      <td>1.438544</td>\n",
       "      <td>41.717789</td>\n",
       "      <td>29.0</td>\n",
       "      <td>LB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>265</th>\n",
       "      <td>Leighton Vander Esch</td>\n",
       "      <td>1.367203</td>\n",
       "      <td>25.976858</td>\n",
       "      <td>19.0</td>\n",
       "      <td>LB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>172</th>\n",
       "      <td>Jacob Phillips</td>\n",
       "      <td>1.341122</td>\n",
       "      <td>17.434584</td>\n",
       "      <td>13.0</td>\n",
       "      <td>LB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121</th>\n",
       "      <td>Devin Lloyd</td>\n",
       "      <td>1.332275</td>\n",
       "      <td>39.968257</td>\n",
       "      <td>30.0</td>\n",
       "      <td>LB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Alex Highsmith</td>\n",
       "      <td>1.332133</td>\n",
       "      <td>25.310530</td>\n",
       "      <td>19.0</td>\n",
       "      <td>LB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>303</th>\n",
       "      <td>Mykal Walker</td>\n",
       "      <td>1.324902</td>\n",
       "      <td>41.071955</td>\n",
       "      <td>31.0</td>\n",
       "      <td>LB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>332</th>\n",
       "      <td>Quincy Williams</td>\n",
       "      <td>1.303303</td>\n",
       "      <td>22.156154</td>\n",
       "      <td>17.0</td>\n",
       "      <td>LB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>232</th>\n",
       "      <td>Justin Hollins</td>\n",
       "      <td>1.297732</td>\n",
       "      <td>9.084126</td>\n",
       "      <td>7.0</td>\n",
       "      <td>LB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>Christian Kirksey</td>\n",
       "      <td>1.282750</td>\n",
       "      <td>25.655004</td>\n",
       "      <td>20.0</td>\n",
       "      <td>LB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>359</th>\n",
       "      <td>Shaquil Barrett</td>\n",
       "      <td>1.277948</td>\n",
       "      <td>23.003067</td>\n",
       "      <td>18.0</td>\n",
       "      <td>LB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140</th>\n",
       "      <td>Eric Kendricks</td>\n",
       "      <td>1.269816</td>\n",
       "      <td>21.586879</td>\n",
       "      <td>17.0</td>\n",
       "      <td>LB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143</th>\n",
       "      <td>Ernest Jones</td>\n",
       "      <td>1.208574</td>\n",
       "      <td>20.545758</td>\n",
       "      <td>17.0</td>\n",
       "      <td>LB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>C.J. Mosley</td>\n",
       "      <td>1.140280</td>\n",
       "      <td>27.366731</td>\n",
       "      <td>24.0</td>\n",
       "      <td>LB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>324</th>\n",
       "      <td>Patrick Queen</td>\n",
       "      <td>1.131540</td>\n",
       "      <td>22.630801</td>\n",
       "      <td>20.0</td>\n",
       "      <td>LB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202</th>\n",
       "      <td>Joe Tryon</td>\n",
       "      <td>1.123586</td>\n",
       "      <td>16.853794</td>\n",
       "      <td>15.0</td>\n",
       "      <td>LB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>338</th>\n",
       "      <td>Rashaan Evans</td>\n",
       "      <td>1.119715</td>\n",
       "      <td>27.992882</td>\n",
       "      <td>25.0</td>\n",
       "      <td>LB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>Demario Davis</td>\n",
       "      <td>1.075139</td>\n",
       "      <td>20.427632</td>\n",
       "      <td>19.0</td>\n",
       "      <td>LB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124</th>\n",
       "      <td>Divine Deablo</td>\n",
       "      <td>0.971886</td>\n",
       "      <td>15.550179</td>\n",
       "      <td>16.0</td>\n",
       "      <td>LB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>218</th>\n",
       "      <td>Josey Jewell</td>\n",
       "      <td>0.929725</td>\n",
       "      <td>20.453941</td>\n",
       "      <td>22.0</td>\n",
       "      <td>LB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>381</th>\n",
       "      <td>Travon Walker</td>\n",
       "      <td>0.924001</td>\n",
       "      <td>16.632011</td>\n",
       "      <td>18.0</td>\n",
       "      <td>LB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>405</th>\n",
       "      <td>Zaire Franklin</td>\n",
       "      <td>0.898633</td>\n",
       "      <td>25.161711</td>\n",
       "      <td>28.0</td>\n",
       "      <td>LB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>348</th>\n",
       "      <td>Robert Spillane</td>\n",
       "      <td>0.896023</td>\n",
       "      <td>13.440351</td>\n",
       "      <td>15.0</td>\n",
       "      <td>LB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>Cory Littleton</td>\n",
       "      <td>0.887880</td>\n",
       "      <td>8.878797</td>\n",
       "      <td>10.0</td>\n",
       "      <td>LB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>Fred Warner</td>\n",
       "      <td>0.885600</td>\n",
       "      <td>11.512800</td>\n",
       "      <td>13.0</td>\n",
       "      <td>LB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>Boye Mafe</td>\n",
       "      <td>0.883486</td>\n",
       "      <td>11.485318</td>\n",
       "      <td>13.0</td>\n",
       "      <td>LB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>182</th>\n",
       "      <td>Jamin Davis</td>\n",
       "      <td>0.863879</td>\n",
       "      <td>12.958181</td>\n",
       "      <td>15.0</td>\n",
       "      <td>LB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>401</th>\n",
       "      <td>Za'Darius Smith</td>\n",
       "      <td>0.856728</td>\n",
       "      <td>8.567277</td>\n",
       "      <td>10.0</td>\n",
       "      <td>LB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>D.J. Wonnum</td>\n",
       "      <td>0.818588</td>\n",
       "      <td>8.185876</td>\n",
       "      <td>10.0</td>\n",
       "      <td>LB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Anthony Barr</td>\n",
       "      <td>0.799464</td>\n",
       "      <td>12.791431</td>\n",
       "      <td>16.0</td>\n",
       "      <td>LB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>396</th>\n",
       "      <td>Willie Gay</td>\n",
       "      <td>0.789123</td>\n",
       "      <td>14.204216</td>\n",
       "      <td>18.0</td>\n",
       "      <td>LB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>Bobby Wagner</td>\n",
       "      <td>0.780853</td>\n",
       "      <td>16.397915</td>\n",
       "      <td>21.0</td>\n",
       "      <td>LB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>341</th>\n",
       "      <td>Rashan Gary</td>\n",
       "      <td>0.757967</td>\n",
       "      <td>7.579667</td>\n",
       "      <td>10.0</td>\n",
       "      <td>LB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>257</th>\n",
       "      <td>Kyle Van Noy</td>\n",
       "      <td>0.713160</td>\n",
       "      <td>7.131599</td>\n",
       "      <td>10.0</td>\n",
       "      <td>LB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>221</th>\n",
       "      <td>Josh Bynes</td>\n",
       "      <td>0.595299</td>\n",
       "      <td>11.310672</td>\n",
       "      <td>19.0</td>\n",
       "      <td>LB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>311</th>\n",
       "      <td>Nicholas Morrow</td>\n",
       "      <td>0.568852</td>\n",
       "      <td>13.083599</td>\n",
       "      <td>23.0</td>\n",
       "      <td>LB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>383</th>\n",
       "      <td>Trevis Gipson</td>\n",
       "      <td>0.546869</td>\n",
       "      <td>4.921820</td>\n",
       "      <td>9.0</td>\n",
       "      <td>LB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>193</th>\n",
       "      <td>Jeremiah Owusu-Koramoah</td>\n",
       "      <td>0.532449</td>\n",
       "      <td>9.584085</td>\n",
       "      <td>18.0</td>\n",
       "      <td>LB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>392</th>\n",
       "      <td>Von Miller</td>\n",
       "      <td>0.487374</td>\n",
       "      <td>4.873742</td>\n",
       "      <td>10.0</td>\n",
       "      <td>LB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Adetokunbo Ogundeji</td>\n",
       "      <td>0.483197</td>\n",
       "      <td>9.180742</td>\n",
       "      <td>19.0</td>\n",
       "      <td>LB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>289</th>\n",
       "      <td>Melvin Ingram</td>\n",
       "      <td>0.437843</td>\n",
       "      <td>4.378429</td>\n",
       "      <td>10.0</td>\n",
       "      <td>LB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>Ja'Whaun Bentley</td>\n",
       "      <td>0.337772</td>\n",
       "      <td>5.066576</td>\n",
       "      <td>15.0</td>\n",
       "      <td>LB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>362</th>\n",
       "      <td>Sione Takitaki</td>\n",
       "      <td>0.330009</td>\n",
       "      <td>3.630104</td>\n",
       "      <td>11.0</td>\n",
       "      <td>LB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>329</th>\n",
       "      <td>Preston Smith</td>\n",
       "      <td>0.322425</td>\n",
       "      <td>3.869095</td>\n",
       "      <td>12.0</td>\n",
       "      <td>LB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>368</th>\n",
       "      <td>Tae Crowder</td>\n",
       "      <td>0.217525</td>\n",
       "      <td>5.220604</td>\n",
       "      <td>24.0</td>\n",
       "      <td>LB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>286</th>\n",
       "      <td>Matt Judon</td>\n",
       "      <td>0.213457</td>\n",
       "      <td>1.921116</td>\n",
       "      <td>9.0</td>\n",
       "      <td>LB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>Charles Harris</td>\n",
       "      <td>0.162418</td>\n",
       "      <td>2.598696</td>\n",
       "      <td>16.0</td>\n",
       "      <td>LB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>Baron Browning</td>\n",
       "      <td>0.091204</td>\n",
       "      <td>0.820833</td>\n",
       "      <td>9.0</td>\n",
       "      <td>LB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133</th>\n",
       "      <td>Dylan Cole</td>\n",
       "      <td>0.006832</td>\n",
       "      <td>0.061488</td>\n",
       "      <td>9.0</td>\n",
       "      <td>LB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>220</th>\n",
       "      <td>Josh Allen</td>\n",
       "      <td>-0.053489</td>\n",
       "      <td>-0.748843</td>\n",
       "      <td>14.0</td>\n",
       "      <td>LB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>219</th>\n",
       "      <td>Josh Allen</td>\n",
       "      <td>-0.053489</td>\n",
       "      <td>-0.748843</td>\n",
       "      <td>14.0</td>\n",
       "      <td>LB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>275</th>\n",
       "      <td>Malik Reed</td>\n",
       "      <td>-0.094332</td>\n",
       "      <td>-0.848985</td>\n",
       "      <td>9.0</td>\n",
       "      <td>LB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>290</th>\n",
       "      <td>Micah Parsons</td>\n",
       "      <td>-0.104527</td>\n",
       "      <td>-1.567899</td>\n",
       "      <td>15.0</td>\n",
       "      <td>LB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>270</th>\n",
       "      <td>Lorenzo Carter</td>\n",
       "      <td>-0.161785</td>\n",
       "      <td>-2.103201</td>\n",
       "      <td>13.0</td>\n",
       "      <td>LB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>Bradley Chubb</td>\n",
       "      <td>-0.170731</td>\n",
       "      <td>-1.707305</td>\n",
       "      <td>10.0</td>\n",
       "      <td>LB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>390</th>\n",
       "      <td>Uchenna Nwosu</td>\n",
       "      <td>-0.177240</td>\n",
       "      <td>-2.304119</td>\n",
       "      <td>13.0</td>\n",
       "      <td>LB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>340</th>\n",
       "      <td>Rashad Weaver</td>\n",
       "      <td>-0.185322</td>\n",
       "      <td>-1.482575</td>\n",
       "      <td>8.0</td>\n",
       "      <td>LB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Darrell Taylor</td>\n",
       "      <td>-0.247495</td>\n",
       "      <td>-4.207417</td>\n",
       "      <td>17.0</td>\n",
       "      <td>LB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>Chris Board</td>\n",
       "      <td>-0.299019</td>\n",
       "      <td>-2.990187</td>\n",
       "      <td>10.0</td>\n",
       "      <td>LB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>282</th>\n",
       "      <td>Marquis Haynes</td>\n",
       "      <td>-0.305316</td>\n",
       "      <td>-3.358473</td>\n",
       "      <td>11.0</td>\n",
       "      <td>LB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>347</th>\n",
       "      <td>Robert Quinn</td>\n",
       "      <td>-0.352354</td>\n",
       "      <td>-5.637666</td>\n",
       "      <td>16.0</td>\n",
       "      <td>LB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>318</th>\n",
       "      <td>Odafe Oweh</td>\n",
       "      <td>-0.463068</td>\n",
       "      <td>-6.482946</td>\n",
       "      <td>14.0</td>\n",
       "      <td>LB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>271</th>\n",
       "      <td>Mack Wilson</td>\n",
       "      <td>-0.464744</td>\n",
       "      <td>-4.182693</td>\n",
       "      <td>9.0</td>\n",
       "      <td>LB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>173</th>\n",
       "      <td>Jaelan Phillips</td>\n",
       "      <td>-0.541979</td>\n",
       "      <td>-7.587708</td>\n",
       "      <td>14.0</td>\n",
       "      <td>LB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>403</th>\n",
       "      <td>Zach Cunningham</td>\n",
       "      <td>-1.318743</td>\n",
       "      <td>-10.549943</td>\n",
       "      <td>8.0</td>\n",
       "      <td>LB</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 displayName  Average SITR  Total SITR  tackleOpportunities  \\\n",
       "206           Jonas Griffith      3.466160   41.593916                 12.0   \n",
       "39             Bobby Okereke      3.429262   68.585240                 20.0   \n",
       "331              Quay Walker      3.327539   26.620308                  8.0   \n",
       "250              Khalil Mack      3.313411   26.507288                  8.0   \n",
       "239        Kamu Grugier-Hill      3.195736   67.110462                 21.0   \n",
       "120               Devin Bush      2.882395   34.588737                 12.0   \n",
       "382         Tremaine Edmunds      2.805190   58.908990                 21.0   \n",
       "80              Cole Holcomb      2.605566   41.689062                 16.0   \n",
       "196             Jerome Baker      2.517002   47.823041                 19.0   \n",
       "313              Nick Bolton      2.469760   39.516161                 16.0   \n",
       "201               Jihad Ward      2.468682   24.686823                 10.0   \n",
       "327              Pete Werner      2.438530   68.278852                 28.0   \n",
       "272        Malcolm Rodriguez      2.408633   50.581292                 21.0   \n",
       "131               Duke Riley      2.338314   23.383137                 10.0   \n",
       "366             T.J. Edwards      2.329899   65.237168                 28.0   \n",
       "12       Akeem Davis-Gaither      2.317131   18.537045                  8.0   \n",
       "377            Terrell Lewis      2.229057   17.832456                  8.0   \n",
       "358            Shaq Thompson      2.192535   37.273103                 17.0   \n",
       "79               Cody Barton      2.164552   56.278361                 26.0   \n",
       "316               Nick Vigil      2.114520   27.488760                 13.0   \n",
       "255           Kwon Alexander      2.102588   29.436225                 14.0   \n",
       "307               Myles Jack      2.101765   56.747664                 27.0   \n",
       "263            Lavonte David      2.059687   45.313118                 22.0   \n",
       "269             Logan Wilson      2.048205   30.723074                 15.0   \n",
       "123              Devin White      2.018146   38.344781                 19.0   \n",
       "148             Frankie Luvu      2.012672   64.405489                 32.0   \n",
       "28            Anthony Walker      1.959723   17.637506                  9.0   \n",
       "259              Kyzir White      1.958792   33.299459                 17.0   \n",
       "214             Jordan Hicks      1.950072   52.651941                 27.0   \n",
       "150           Germaine Pratt      1.924433   36.564222                 19.0   \n",
       "128             Dre Greenlaw      1.897343   49.330913                 26.0   \n",
       "130           Drue Tranquill      1.836622   36.732435                 20.0   \n",
       "134               E.J. Speed      1.834264   23.845430                 13.0   \n",
       "15             Alex Anzalone      1.791830   50.171235                 28.0   \n",
       "146         Foyesade Oluokun      1.721150   41.307591                 24.0   \n",
       "104       De'Vondre Campbell      1.698299   40.759168                 24.0   \n",
       "406            Zaven Collins      1.675093   40.202235                 24.0   \n",
       "174            Jahlani Tavai      1.668611   13.348891                  8.0   \n",
       "217            Jordyn Brooks      1.667445   51.690799                 31.0   \n",
       "158           Haason Reddick      1.640141   24.602113                 15.0   \n",
       "243           Kenneth Murray      1.607919   19.295031                 12.0   \n",
       "136          Elandon Roberts      1.587908   19.054898                 12.0   \n",
       "46               Brian Burns      1.573931   26.756829                 17.0   \n",
       "287              Matt Milano      1.555609   35.779016                 23.0   \n",
       "17            Alex Singleton      1.511479   13.603313                  9.0   \n",
       "190              Jayon Brown      1.493973   26.891514                 18.0   \n",
       "100               David Long      1.483389   43.018267                 29.0   \n",
       "90           Danielle Hunter      1.479938   26.638881                 18.0   \n",
       "353             Roquan Smith      1.438544   41.717789                 29.0   \n",
       "265     Leighton Vander Esch      1.367203   25.976858                 19.0   \n",
       "172           Jacob Phillips      1.341122   17.434584                 13.0   \n",
       "121              Devin Lloyd      1.332275   39.968257                 30.0   \n",
       "16            Alex Highsmith      1.332133   25.310530                 19.0   \n",
       "303             Mykal Walker      1.324902   41.071955                 31.0   \n",
       "332          Quincy Williams      1.303303   22.156154                 17.0   \n",
       "232           Justin Hollins      1.297732    9.084126                  7.0   \n",
       "75         Christian Kirksey      1.282750   25.655004                 20.0   \n",
       "359          Shaquil Barrett      1.277948   23.003067                 18.0   \n",
       "140           Eric Kendricks      1.269816   21.586879                 17.0   \n",
       "143             Ernest Jones      1.208574   20.545758                 17.0   \n",
       "53               C.J. Mosley      1.140280   27.366731                 24.0   \n",
       "324            Patrick Queen      1.131540   22.630801                 20.0   \n",
       "202                Joe Tryon      1.123586   16.853794                 15.0   \n",
       "338            Rashaan Evans      1.119715   27.992882                 25.0   \n",
       "111            Demario Davis      1.075139   20.427632                 19.0   \n",
       "124            Divine Deablo      0.971886   15.550179                 16.0   \n",
       "218             Josey Jewell      0.929725   20.453941                 22.0   \n",
       "381            Travon Walker      0.924001   16.632011                 18.0   \n",
       "405           Zaire Franklin      0.898633   25.161711                 28.0   \n",
       "348          Robert Spillane      0.896023   13.440351                 15.0   \n",
       "81            Cory Littleton      0.887880    8.878797                 10.0   \n",
       "149              Fred Warner      0.885600   11.512800                 13.0   \n",
       "41                 Boye Mafe      0.883486   11.485318                 13.0   \n",
       "182              Jamin Davis      0.863879   12.958181                 15.0   \n",
       "401          Za'Darius Smith      0.856728    8.567277                 10.0   \n",
       "86               D.J. Wonnum      0.818588    8.185876                 10.0   \n",
       "26              Anthony Barr      0.799464   12.791431                 16.0   \n",
       "396               Willie Gay      0.789123   14.204216                 18.0   \n",
       "40              Bobby Wagner      0.780853   16.397915                 21.0   \n",
       "341              Rashan Gary      0.757967    7.579667                 10.0   \n",
       "257             Kyle Van Noy      0.713160    7.131599                 10.0   \n",
       "221               Josh Bynes      0.595299   11.310672                 19.0   \n",
       "311          Nicholas Morrow      0.568852   13.083599                 23.0   \n",
       "383            Trevis Gipson      0.546869    4.921820                  9.0   \n",
       "193  Jeremiah Owusu-Koramoah      0.532449    9.584085                 18.0   \n",
       "392               Von Miller      0.487374    4.873742                 10.0   \n",
       "5        Adetokunbo Ogundeji      0.483197    9.180742                 19.0   \n",
       "289            Melvin Ingram      0.437843    4.378429                 10.0   \n",
       "168         Ja'Whaun Bentley      0.337772    5.066576                 15.0   \n",
       "362           Sione Takitaki      0.330009    3.630104                 11.0   \n",
       "329            Preston Smith      0.322425    3.869095                 12.0   \n",
       "368              Tae Crowder      0.217525    5.220604                 24.0   \n",
       "286               Matt Judon      0.213457    1.921116                  9.0   \n",
       "69            Charles Harris      0.162418    2.598696                 16.0   \n",
       "35            Baron Browning      0.091204    0.820833                  9.0   \n",
       "133               Dylan Cole      0.006832    0.061488                  9.0   \n",
       "220               Josh Allen     -0.053489   -0.748843                 14.0   \n",
       "219               Josh Allen     -0.053489   -0.748843                 14.0   \n",
       "275               Malik Reed     -0.094332   -0.848985                  9.0   \n",
       "290            Micah Parsons     -0.104527   -1.567899                 15.0   \n",
       "270           Lorenzo Carter     -0.161785   -2.103201                 13.0   \n",
       "42             Bradley Chubb     -0.170731   -1.707305                 10.0   \n",
       "390            Uchenna Nwosu     -0.177240   -2.304119                 13.0   \n",
       "340            Rashad Weaver     -0.185322   -1.482575                  8.0   \n",
       "97            Darrell Taylor     -0.247495   -4.207417                 17.0   \n",
       "72               Chris Board     -0.299019   -2.990187                 10.0   \n",
       "282           Marquis Haynes     -0.305316   -3.358473                 11.0   \n",
       "347             Robert Quinn     -0.352354   -5.637666                 16.0   \n",
       "318               Odafe Oweh     -0.463068   -6.482946                 14.0   \n",
       "271              Mack Wilson     -0.464744   -4.182693                  9.0   \n",
       "173          Jaelan Phillips     -0.541979   -7.587708                 14.0   \n",
       "403          Zach Cunningham     -1.318743  -10.549943                  8.0   \n",
       "\n",
       "    position  \n",
       "206       LB  \n",
       "39        LB  \n",
       "331       LB  \n",
       "250       LB  \n",
       "239       LB  \n",
       "120       LB  \n",
       "382       LB  \n",
       "80        LB  \n",
       "196       LB  \n",
       "313       LB  \n",
       "201       LB  \n",
       "327       LB  \n",
       "272       LB  \n",
       "131       LB  \n",
       "366       LB  \n",
       "12        LB  \n",
       "377       LB  \n",
       "358       LB  \n",
       "79        LB  \n",
       "316       LB  \n",
       "255       LB  \n",
       "307       LB  \n",
       "263       LB  \n",
       "269       LB  \n",
       "123       LB  \n",
       "148       LB  \n",
       "28        LB  \n",
       "259       LB  \n",
       "214       LB  \n",
       "150       LB  \n",
       "128       LB  \n",
       "130       LB  \n",
       "134       LB  \n",
       "15        LB  \n",
       "146       LB  \n",
       "104       LB  \n",
       "406       LB  \n",
       "174       LB  \n",
       "217       LB  \n",
       "158       LB  \n",
       "243       LB  \n",
       "136       LB  \n",
       "46        LB  \n",
       "287       LB  \n",
       "17        LB  \n",
       "190       LB  \n",
       "100       LB  \n",
       "90        LB  \n",
       "353       LB  \n",
       "265       LB  \n",
       "172       LB  \n",
       "121       LB  \n",
       "16        LB  \n",
       "303       LB  \n",
       "332       LB  \n",
       "232       LB  \n",
       "75        LB  \n",
       "359       LB  \n",
       "140       LB  \n",
       "143       LB  \n",
       "53        LB  \n",
       "324       LB  \n",
       "202       LB  \n",
       "338       LB  \n",
       "111       LB  \n",
       "124       LB  \n",
       "218       LB  \n",
       "381       LB  \n",
       "405       LB  \n",
       "348       LB  \n",
       "81        LB  \n",
       "149       LB  \n",
       "41        LB  \n",
       "182       LB  \n",
       "401       LB  \n",
       "86        LB  \n",
       "26        LB  \n",
       "396       LB  \n",
       "40        LB  \n",
       "341       LB  \n",
       "257       LB  \n",
       "221       LB  \n",
       "311       LB  \n",
       "383       LB  \n",
       "193       LB  \n",
       "392       LB  \n",
       "5         LB  \n",
       "289       LB  \n",
       "168       LB  \n",
       "362       LB  \n",
       "329       LB  \n",
       "368       LB  \n",
       "286       LB  \n",
       "69        LB  \n",
       "35        LB  \n",
       "133       LB  \n",
       "220       LB  \n",
       "219       LB  \n",
       "275       LB  \n",
       "290       LB  \n",
       "270       LB  \n",
       "42        LB  \n",
       "390       LB  \n",
       "340       LB  \n",
       "97        LB  \n",
       "72        LB  \n",
       "282       LB  \n",
       "347       LB  \n",
       "318       LB  \n",
       "271       LB  \n",
       "173       LB  \n",
       "403       LB  "
      ]
     },
     "execution_count": 434,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined3[combined3[\"position\"]==\"LB\"].sort_values(by=\"Average SITR\",ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 435,
   "id": "6e8c5efe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>displayName</th>\n",
       "      <th>Average SITR</th>\n",
       "      <th>Total SITR</th>\n",
       "      <th>tackleOpportunities</th>\n",
       "      <th>position</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>309</th>\n",
       "      <td>Nate Hobbs</td>\n",
       "      <td>3.889093</td>\n",
       "      <td>77.781852</td>\n",
       "      <td>20.0</td>\n",
       "      <td>DB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Anthony Brown</td>\n",
       "      <td>3.883124</td>\n",
       "      <td>66.013108</td>\n",
       "      <td>17.0</td>\n",
       "      <td>DB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>268</th>\n",
       "      <td>Levi Wallace</td>\n",
       "      <td>3.511717</td>\n",
       "      <td>35.117167</td>\n",
       "      <td>10.0</td>\n",
       "      <td>DB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>304</th>\n",
       "      <td>Myles Bryant</td>\n",
       "      <td>3.510983</td>\n",
       "      <td>31.598847</td>\n",
       "      <td>9.0</td>\n",
       "      <td>DB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>238</th>\n",
       "      <td>Kaiir Elam</td>\n",
       "      <td>3.491266</td>\n",
       "      <td>34.912662</td>\n",
       "      <td>10.0</td>\n",
       "      <td>DB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>325</th>\n",
       "      <td>Patrick Surtain</td>\n",
       "      <td>3.440946</td>\n",
       "      <td>37.850403</td>\n",
       "      <td>11.0</td>\n",
       "      <td>DB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>Caleb Farley</td>\n",
       "      <td>3.244830</td>\n",
       "      <td>32.448297</td>\n",
       "      <td>10.0</td>\n",
       "      <td>DB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>375</th>\n",
       "      <td>Terrance Mitchell</td>\n",
       "      <td>3.234276</td>\n",
       "      <td>29.108480</td>\n",
       "      <td>9.0</td>\n",
       "      <td>DB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>283</th>\n",
       "      <td>Marshon Lattimore</td>\n",
       "      <td>3.133794</td>\n",
       "      <td>34.471731</td>\n",
       "      <td>11.0</td>\n",
       "      <td>DB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>Derwin James</td>\n",
       "      <td>3.127214</td>\n",
       "      <td>43.780998</td>\n",
       "      <td>14.0</td>\n",
       "      <td>DB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132</th>\n",
       "      <td>Duron Harmon</td>\n",
       "      <td>3.095674</td>\n",
       "      <td>27.861068</td>\n",
       "      <td>9.0</td>\n",
       "      <td>DB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>301</th>\n",
       "      <td>Minkah Fitzpatrick</td>\n",
       "      <td>3.085678</td>\n",
       "      <td>43.199495</td>\n",
       "      <td>14.0</td>\n",
       "      <td>DB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Antoine Winfield</td>\n",
       "      <td>3.076562</td>\n",
       "      <td>58.454678</td>\n",
       "      <td>19.0</td>\n",
       "      <td>DB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>351</th>\n",
       "      <td>Roger McCreary</td>\n",
       "      <td>3.007161</td>\n",
       "      <td>78.186195</td>\n",
       "      <td>26.0</td>\n",
       "      <td>DB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>297</th>\n",
       "      <td>Mike Hilton</td>\n",
       "      <td>2.999184</td>\n",
       "      <td>59.983686</td>\n",
       "      <td>20.0</td>\n",
       "      <td>DB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>237</th>\n",
       "      <td>Kader Kohou</td>\n",
       "      <td>2.989692</td>\n",
       "      <td>44.845386</td>\n",
       "      <td>15.0</td>\n",
       "      <td>DB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>352</th>\n",
       "      <td>Ronald Darby</td>\n",
       "      <td>2.891377</td>\n",
       "      <td>23.131013</td>\n",
       "      <td>8.0</td>\n",
       "      <td>DB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>179</th>\n",
       "      <td>Jalen Thompson</td>\n",
       "      <td>2.758804</td>\n",
       "      <td>55.176081</td>\n",
       "      <td>20.0</td>\n",
       "      <td>DB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>Cameron Dantzler</td>\n",
       "      <td>2.724820</td>\n",
       "      <td>57.221224</td>\n",
       "      <td>21.0</td>\n",
       "      <td>DB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>371</th>\n",
       "      <td>Taron Johnson</td>\n",
       "      <td>2.693577</td>\n",
       "      <td>43.097233</td>\n",
       "      <td>16.0</td>\n",
       "      <td>DB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>C.J. Henderson</td>\n",
       "      <td>2.666398</td>\n",
       "      <td>45.328768</td>\n",
       "      <td>17.0</td>\n",
       "      <td>DB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>Chidobe Awuzie</td>\n",
       "      <td>2.655477</td>\n",
       "      <td>45.143111</td>\n",
       "      <td>17.0</td>\n",
       "      <td>DB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>169</th>\n",
       "      <td>Jabrill Peppers</td>\n",
       "      <td>2.612947</td>\n",
       "      <td>26.129475</td>\n",
       "      <td>10.0</td>\n",
       "      <td>DB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>323</th>\n",
       "      <td>Patrick Peterson</td>\n",
       "      <td>2.575056</td>\n",
       "      <td>33.475727</td>\n",
       "      <td>13.0</td>\n",
       "      <td>DB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>Darnell Savage</td>\n",
       "      <td>2.559314</td>\n",
       "      <td>25.593139</td>\n",
       "      <td>10.0</td>\n",
       "      <td>DB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141</th>\n",
       "      <td>Eric Rowe</td>\n",
       "      <td>2.548800</td>\n",
       "      <td>38.231995</td>\n",
       "      <td>15.0</td>\n",
       "      <td>DB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>339</th>\n",
       "      <td>Rashad Fenton</td>\n",
       "      <td>2.546861</td>\n",
       "      <td>43.296634</td>\n",
       "      <td>17.0</td>\n",
       "      <td>DB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>277</th>\n",
       "      <td>Marcus Epps</td>\n",
       "      <td>2.525892</td>\n",
       "      <td>37.888376</td>\n",
       "      <td>15.0</td>\n",
       "      <td>DB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>Darius Slay</td>\n",
       "      <td>2.518904</td>\n",
       "      <td>25.189043</td>\n",
       "      <td>10.0</td>\n",
       "      <td>DB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>188</th>\n",
       "      <td>Jaylen Watson</td>\n",
       "      <td>2.500694</td>\n",
       "      <td>42.511800</td>\n",
       "      <td>17.0</td>\n",
       "      <td>DB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175</th>\n",
       "      <td>Jaire Alexander</td>\n",
       "      <td>2.488693</td>\n",
       "      <td>27.375620</td>\n",
       "      <td>11.0</td>\n",
       "      <td>DB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>360</th>\n",
       "      <td>Shaquill Griffin</td>\n",
       "      <td>2.467858</td>\n",
       "      <td>27.146434</td>\n",
       "      <td>11.0</td>\n",
       "      <td>DB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284</th>\n",
       "      <td>Martin Emerson</td>\n",
       "      <td>2.432105</td>\n",
       "      <td>43.777895</td>\n",
       "      <td>18.0</td>\n",
       "      <td>DB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>Jessie Bates</td>\n",
       "      <td>2.423645</td>\n",
       "      <td>21.812806</td>\n",
       "      <td>9.0</td>\n",
       "      <td>DB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>DeShon Elliott</td>\n",
       "      <td>2.380703</td>\n",
       "      <td>49.994754</td>\n",
       "      <td>21.0</td>\n",
       "      <td>DB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>260</th>\n",
       "      <td>L'Jarius Sneed</td>\n",
       "      <td>2.352531</td>\n",
       "      <td>61.165803</td>\n",
       "      <td>26.0</td>\n",
       "      <td>DB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>398</th>\n",
       "      <td>Xavier McKinney</td>\n",
       "      <td>2.349140</td>\n",
       "      <td>21.142260</td>\n",
       "      <td>9.0</td>\n",
       "      <td>DB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Darrick Forrest</td>\n",
       "      <td>2.340266</td>\n",
       "      <td>35.103992</td>\n",
       "      <td>15.0</td>\n",
       "      <td>DB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>Damar Hamlin</td>\n",
       "      <td>2.325578</td>\n",
       "      <td>32.558092</td>\n",
       "      <td>14.0</td>\n",
       "      <td>DB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>Budda Baker</td>\n",
       "      <td>2.285331</td>\n",
       "      <td>52.562603</td>\n",
       "      <td>23.0</td>\n",
       "      <td>DB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>226</th>\n",
       "      <td>Jourdan Lewis</td>\n",
       "      <td>2.269121</td>\n",
       "      <td>31.767699</td>\n",
       "      <td>14.0</td>\n",
       "      <td>DB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>204</th>\n",
       "      <td>John Johnson</td>\n",
       "      <td>2.260945</td>\n",
       "      <td>45.218896</td>\n",
       "      <td>20.0</td>\n",
       "      <td>DB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>315</th>\n",
       "      <td>Nick Scott</td>\n",
       "      <td>2.209050</td>\n",
       "      <td>33.135754</td>\n",
       "      <td>15.0</td>\n",
       "      <td>DB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>349</th>\n",
       "      <td>Rock Ya-Sin</td>\n",
       "      <td>2.195933</td>\n",
       "      <td>21.959330</td>\n",
       "      <td>10.0</td>\n",
       "      <td>DB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>278</th>\n",
       "      <td>Marcus Maye</td>\n",
       "      <td>2.089815</td>\n",
       "      <td>18.808331</td>\n",
       "      <td>9.0</td>\n",
       "      <td>DB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>Denzel Ward</td>\n",
       "      <td>2.087084</td>\n",
       "      <td>29.219178</td>\n",
       "      <td>14.0</td>\n",
       "      <td>DB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>364</th>\n",
       "      <td>Stephon Gilmore</td>\n",
       "      <td>2.069300</td>\n",
       "      <td>35.178092</td>\n",
       "      <td>17.0</td>\n",
       "      <td>DB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Adrian Amos</td>\n",
       "      <td>2.068171</td>\n",
       "      <td>22.749881</td>\n",
       "      <td>11.0</td>\n",
       "      <td>DB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>160</th>\n",
       "      <td>Harrison Smith</td>\n",
       "      <td>2.059329</td>\n",
       "      <td>45.305249</td>\n",
       "      <td>22.0</td>\n",
       "      <td>DB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>395</th>\n",
       "      <td>William Jackson</td>\n",
       "      <td>2.051855</td>\n",
       "      <td>30.777827</td>\n",
       "      <td>15.0</td>\n",
       "      <td>DB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>344</th>\n",
       "      <td>Rasul Douglas</td>\n",
       "      <td>2.042756</td>\n",
       "      <td>34.726850</td>\n",
       "      <td>17.0</td>\n",
       "      <td>DB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>306</th>\n",
       "      <td>Myles Hartsfield</td>\n",
       "      <td>2.025386</td>\n",
       "      <td>22.279241</td>\n",
       "      <td>11.0</td>\n",
       "      <td>DB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>205</th>\n",
       "      <td>Johnathan Abram</td>\n",
       "      <td>2.001862</td>\n",
       "      <td>46.042820</td>\n",
       "      <td>23.0</td>\n",
       "      <td>DB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>180</th>\n",
       "      <td>Jamel Dean</td>\n",
       "      <td>1.998070</td>\n",
       "      <td>27.972982</td>\n",
       "      <td>14.0</td>\n",
       "      <td>DB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>293</th>\n",
       "      <td>Michael Davis</td>\n",
       "      <td>1.981813</td>\n",
       "      <td>17.836318</td>\n",
       "      <td>9.0</td>\n",
       "      <td>DB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>165</th>\n",
       "      <td>Isaiah Simmons</td>\n",
       "      <td>1.950829</td>\n",
       "      <td>21.459121</td>\n",
       "      <td>11.0</td>\n",
       "      <td>DB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135</th>\n",
       "      <td>Eddie Jackson</td>\n",
       "      <td>1.935292</td>\n",
       "      <td>29.029385</td>\n",
       "      <td>15.0</td>\n",
       "      <td>DB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>365</th>\n",
       "      <td>Steven Nelson</td>\n",
       "      <td>1.925498</td>\n",
       "      <td>38.509956</td>\n",
       "      <td>20.0</td>\n",
       "      <td>DB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>Coby Bryant</td>\n",
       "      <td>1.924182</td>\n",
       "      <td>15.393455</td>\n",
       "      <td>8.0</td>\n",
       "      <td>DB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>Asante Samuel</td>\n",
       "      <td>1.889717</td>\n",
       "      <td>34.014911</td>\n",
       "      <td>18.0</td>\n",
       "      <td>DB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>D.J. Reed</td>\n",
       "      <td>1.884899</td>\n",
       "      <td>26.388580</td>\n",
       "      <td>14.0</td>\n",
       "      <td>DB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>Brandon Stephens</td>\n",
       "      <td>1.872171</td>\n",
       "      <td>14.977369</td>\n",
       "      <td>8.0</td>\n",
       "      <td>DB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>Bryce Callahan</td>\n",
       "      <td>1.864746</td>\n",
       "      <td>20.512201</td>\n",
       "      <td>11.0</td>\n",
       "      <td>DB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126</th>\n",
       "      <td>Donte Jackson</td>\n",
       "      <td>1.852490</td>\n",
       "      <td>20.377393</td>\n",
       "      <td>11.0</td>\n",
       "      <td>DB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>Dane Jackson</td>\n",
       "      <td>1.818129</td>\n",
       "      <td>16.363162</td>\n",
       "      <td>9.0</td>\n",
       "      <td>DB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>242</th>\n",
       "      <td>Kendall Fuller</td>\n",
       "      <td>1.818112</td>\n",
       "      <td>27.271674</td>\n",
       "      <td>15.0</td>\n",
       "      <td>DB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>178</th>\n",
       "      <td>Jalen Ramsey</td>\n",
       "      <td>1.812703</td>\n",
       "      <td>30.815956</td>\n",
       "      <td>17.0</td>\n",
       "      <td>DB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>281</th>\n",
       "      <td>Marlon Humphrey</td>\n",
       "      <td>1.794575</td>\n",
       "      <td>28.713196</td>\n",
       "      <td>16.0</td>\n",
       "      <td>DB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194</th>\n",
       "      <td>Jeremy Chinn</td>\n",
       "      <td>1.793478</td>\n",
       "      <td>30.489128</td>\n",
       "      <td>17.0</td>\n",
       "      <td>DB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>191</th>\n",
       "      <td>Jeff Okudah</td>\n",
       "      <td>1.771464</td>\n",
       "      <td>40.743681</td>\n",
       "      <td>23.0</td>\n",
       "      <td>DB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>256</th>\n",
       "      <td>Kyle Dugger</td>\n",
       "      <td>1.766667</td>\n",
       "      <td>14.133338</td>\n",
       "      <td>8.0</td>\n",
       "      <td>DB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>Carlton Davis</td>\n",
       "      <td>1.746110</td>\n",
       "      <td>36.668316</td>\n",
       "      <td>21.0</td>\n",
       "      <td>DB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>152</th>\n",
       "      <td>Grant Delpit</td>\n",
       "      <td>1.727344</td>\n",
       "      <td>32.819535</td>\n",
       "      <td>19.0</td>\n",
       "      <td>DB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Adoree' Jackson</td>\n",
       "      <td>1.727261</td>\n",
       "      <td>34.545215</td>\n",
       "      <td>20.0</td>\n",
       "      <td>DB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Andre Cisco</td>\n",
       "      <td>1.718458</td>\n",
       "      <td>17.184580</td>\n",
       "      <td>10.0</td>\n",
       "      <td>DB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>388</th>\n",
       "      <td>Tyrann Mathieu</td>\n",
       "      <td>1.702920</td>\n",
       "      <td>30.652562</td>\n",
       "      <td>18.0</td>\n",
       "      <td>DB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>236</th>\n",
       "      <td>K'Waun Williams</td>\n",
       "      <td>1.681621</td>\n",
       "      <td>23.542691</td>\n",
       "      <td>14.0</td>\n",
       "      <td>DB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Adrian Phillips</td>\n",
       "      <td>1.678014</td>\n",
       "      <td>26.848228</td>\n",
       "      <td>16.0</td>\n",
       "      <td>DB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>247</th>\n",
       "      <td>Kevin Byard</td>\n",
       "      <td>1.660428</td>\n",
       "      <td>23.245995</td>\n",
       "      <td>14.0</td>\n",
       "      <td>DB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>Derek Stingley</td>\n",
       "      <td>1.644843</td>\n",
       "      <td>29.607179</td>\n",
       "      <td>18.0</td>\n",
       "      <td>DB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>241</th>\n",
       "      <td>Keisean Nixon</td>\n",
       "      <td>1.643375</td>\n",
       "      <td>13.147004</td>\n",
       "      <td>8.0</td>\n",
       "      <td>DB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155</th>\n",
       "      <td>Greg Newsome</td>\n",
       "      <td>1.607329</td>\n",
       "      <td>20.895279</td>\n",
       "      <td>13.0</td>\n",
       "      <td>DB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119</th>\n",
       "      <td>Desmond King</td>\n",
       "      <td>1.573658</td>\n",
       "      <td>23.604873</td>\n",
       "      <td>15.0</td>\n",
       "      <td>DB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137</th>\n",
       "      <td>Eli Apple</td>\n",
       "      <td>1.570681</td>\n",
       "      <td>17.277486</td>\n",
       "      <td>11.0</td>\n",
       "      <td>DB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>235</th>\n",
       "      <td>Justin Reid</td>\n",
       "      <td>1.547586</td>\n",
       "      <td>15.475855</td>\n",
       "      <td>10.0</td>\n",
       "      <td>DB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>350</th>\n",
       "      <td>Rodney McLeod</td>\n",
       "      <td>1.541276</td>\n",
       "      <td>16.954035</td>\n",
       "      <td>11.0</td>\n",
       "      <td>DB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>Darnay Holmes</td>\n",
       "      <td>1.527467</td>\n",
       "      <td>12.219738</td>\n",
       "      <td>8.0</td>\n",
       "      <td>DB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>384</th>\n",
       "      <td>Trevon Diggs</td>\n",
       "      <td>1.522768</td>\n",
       "      <td>24.364293</td>\n",
       "      <td>16.0</td>\n",
       "      <td>DB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142</th>\n",
       "      <td>Eric Stokes</td>\n",
       "      <td>1.506437</td>\n",
       "      <td>21.090121</td>\n",
       "      <td>14.0</td>\n",
       "      <td>DB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>224</th>\n",
       "      <td>Josh Metellus</td>\n",
       "      <td>1.501581</td>\n",
       "      <td>19.520549</td>\n",
       "      <td>13.0</td>\n",
       "      <td>DB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>231</th>\n",
       "      <td>Justin Evans</td>\n",
       "      <td>1.497175</td>\n",
       "      <td>14.971747</td>\n",
       "      <td>10.0</td>\n",
       "      <td>DB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>David Long</td>\n",
       "      <td>1.483389</td>\n",
       "      <td>43.018267</td>\n",
       "      <td>29.0</td>\n",
       "      <td>DB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Ahmad Gardner</td>\n",
       "      <td>1.473317</td>\n",
       "      <td>16.206487</td>\n",
       "      <td>11.0</td>\n",
       "      <td>DB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>326</th>\n",
       "      <td>Paulson Adebo</td>\n",
       "      <td>1.471207</td>\n",
       "      <td>13.240865</td>\n",
       "      <td>9.0</td>\n",
       "      <td>DB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>176</th>\n",
       "      <td>Jalen Mills</td>\n",
       "      <td>1.463396</td>\n",
       "      <td>17.560749</td>\n",
       "      <td>12.0</td>\n",
       "      <td>DB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>166</th>\n",
       "      <td>J.C. Jackson</td>\n",
       "      <td>1.444251</td>\n",
       "      <td>14.442513</td>\n",
       "      <td>10.0</td>\n",
       "      <td>DB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125</th>\n",
       "      <td>Donovan Wilson</td>\n",
       "      <td>1.441346</td>\n",
       "      <td>40.357675</td>\n",
       "      <td>28.0</td>\n",
       "      <td>DB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>Brandon Jones</td>\n",
       "      <td>1.409938</td>\n",
       "      <td>23.968946</td>\n",
       "      <td>17.0</td>\n",
       "      <td>DB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138</th>\n",
       "      <td>Emmanuel Moseley</td>\n",
       "      <td>1.408837</td>\n",
       "      <td>19.723721</td>\n",
       "      <td>14.0</td>\n",
       "      <td>DB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>215</th>\n",
       "      <td>Jordan Poyer</td>\n",
       "      <td>1.392230</td>\n",
       "      <td>11.137839</td>\n",
       "      <td>8.0</td>\n",
       "      <td>DB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Ahkello Witherspoon</td>\n",
       "      <td>1.380964</td>\n",
       "      <td>19.333499</td>\n",
       "      <td>14.0</td>\n",
       "      <td>DB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>Byron Murphy</td>\n",
       "      <td>1.380311</td>\n",
       "      <td>13.803112</td>\n",
       "      <td>10.0</td>\n",
       "      <td>DB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200</th>\n",
       "      <td>Jevon Holland</td>\n",
       "      <td>1.354452</td>\n",
       "      <td>17.607881</td>\n",
       "      <td>13.0</td>\n",
       "      <td>DB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>298</th>\n",
       "      <td>Mike Hughes</td>\n",
       "      <td>1.348831</td>\n",
       "      <td>20.232463</td>\n",
       "      <td>15.0</td>\n",
       "      <td>DB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>Arthur Maulet</td>\n",
       "      <td>1.296658</td>\n",
       "      <td>15.559899</td>\n",
       "      <td>12.0</td>\n",
       "      <td>DB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>Chauncey Gardner-Johnson</td>\n",
       "      <td>1.295536</td>\n",
       "      <td>29.797339</td>\n",
       "      <td>23.0</td>\n",
       "      <td>DB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Amani Oruwariye</td>\n",
       "      <td>1.267790</td>\n",
       "      <td>25.355802</td>\n",
       "      <td>20.0</td>\n",
       "      <td>DB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>Casey Hayward</td>\n",
       "      <td>1.267481</td>\n",
       "      <td>19.012222</td>\n",
       "      <td>15.0</td>\n",
       "      <td>DB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>369</th>\n",
       "      <td>Talanoa Hufanga</td>\n",
       "      <td>1.243675</td>\n",
       "      <td>14.924100</td>\n",
       "      <td>12.0</td>\n",
       "      <td>DB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>223</th>\n",
       "      <td>Josh Jones</td>\n",
       "      <td>1.223792</td>\n",
       "      <td>29.371016</td>\n",
       "      <td>24.0</td>\n",
       "      <td>DB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>222</th>\n",
       "      <td>Josh Jones</td>\n",
       "      <td>1.223792</td>\n",
       "      <td>29.371016</td>\n",
       "      <td>24.0</td>\n",
       "      <td>DB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>399</th>\n",
       "      <td>Xavier Woods</td>\n",
       "      <td>1.214540</td>\n",
       "      <td>23.076252</td>\n",
       "      <td>19.0</td>\n",
       "      <td>DB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>240</th>\n",
       "      <td>Kareem Jackson</td>\n",
       "      <td>1.204259</td>\n",
       "      <td>15.655361</td>\n",
       "      <td>13.0</td>\n",
       "      <td>DB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>171</th>\n",
       "      <td>Jack Jones</td>\n",
       "      <td>1.185413</td>\n",
       "      <td>13.039545</td>\n",
       "      <td>11.0</td>\n",
       "      <td>DB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A.J. Terrell</td>\n",
       "      <td>1.153087</td>\n",
       "      <td>18.449396</td>\n",
       "      <td>16.0</td>\n",
       "      <td>DB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>227</th>\n",
       "      <td>Juan Thornhill</td>\n",
       "      <td>1.143074</td>\n",
       "      <td>10.287663</td>\n",
       "      <td>9.0</td>\n",
       "      <td>DB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>Cameron Sutton</td>\n",
       "      <td>1.139252</td>\n",
       "      <td>21.645790</td>\n",
       "      <td>19.0</td>\n",
       "      <td>DB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>187</th>\n",
       "      <td>Jaycee Horn</td>\n",
       "      <td>1.098237</td>\n",
       "      <td>15.375318</td>\n",
       "      <td>14.0</td>\n",
       "      <td>DB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>274</th>\n",
       "      <td>Malik Hooker</td>\n",
       "      <td>1.083263</td>\n",
       "      <td>11.915895</td>\n",
       "      <td>11.0</td>\n",
       "      <td>DB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153</th>\n",
       "      <td>Grant Haley</td>\n",
       "      <td>1.054259</td>\n",
       "      <td>10.542587</td>\n",
       "      <td>10.0</td>\n",
       "      <td>DB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>376</th>\n",
       "      <td>Terrell Edmunds</td>\n",
       "      <td>1.053873</td>\n",
       "      <td>13.700351</td>\n",
       "      <td>13.0</td>\n",
       "      <td>DB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>211</th>\n",
       "      <td>Jonathan Owens</td>\n",
       "      <td>1.031180</td>\n",
       "      <td>24.748331</td>\n",
       "      <td>24.0</td>\n",
       "      <td>DB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>Benjamin St-Juste</td>\n",
       "      <td>1.025567</td>\n",
       "      <td>18.460206</td>\n",
       "      <td>18.0</td>\n",
       "      <td>DB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>Bradley Roby</td>\n",
       "      <td>1.023593</td>\n",
       "      <td>17.401084</td>\n",
       "      <td>17.0</td>\n",
       "      <td>DB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>346</th>\n",
       "      <td>Richie Grant</td>\n",
       "      <td>0.993625</td>\n",
       "      <td>19.872497</td>\n",
       "      <td>20.0</td>\n",
       "      <td>DB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>280</th>\n",
       "      <td>Marcus Williams</td>\n",
       "      <td>0.993208</td>\n",
       "      <td>21.850575</td>\n",
       "      <td>22.0</td>\n",
       "      <td>DB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>296</th>\n",
       "      <td>Mike Edwards</td>\n",
       "      <td>0.992743</td>\n",
       "      <td>16.876634</td>\n",
       "      <td>17.0</td>\n",
       "      <td>DB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>Chandon Sullivan</td>\n",
       "      <td>0.969049</td>\n",
       "      <td>9.690487</td>\n",
       "      <td>10.0</td>\n",
       "      <td>DB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>229</th>\n",
       "      <td>Julian Love</td>\n",
       "      <td>0.952705</td>\n",
       "      <td>11.432456</td>\n",
       "      <td>12.0</td>\n",
       "      <td>DB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>Chuck Clark</td>\n",
       "      <td>0.942075</td>\n",
       "      <td>17.899420</td>\n",
       "      <td>19.0</td>\n",
       "      <td>DB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>279</th>\n",
       "      <td>Marcus Peters</td>\n",
       "      <td>0.935741</td>\n",
       "      <td>8.421672</td>\n",
       "      <td>9.0</td>\n",
       "      <td>DB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>183</th>\n",
       "      <td>Jaquan Brisker</td>\n",
       "      <td>0.932422</td>\n",
       "      <td>26.107816</td>\n",
       "      <td>28.0</td>\n",
       "      <td>DB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>322</th>\n",
       "      <td>P.J. Williams</td>\n",
       "      <td>0.905647</td>\n",
       "      <td>7.245176</td>\n",
       "      <td>8.0</td>\n",
       "      <td>DB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>317</th>\n",
       "      <td>Nik Needham</td>\n",
       "      <td>0.898578</td>\n",
       "      <td>12.580095</td>\n",
       "      <td>14.0</td>\n",
       "      <td>DB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>210</th>\n",
       "      <td>Jonathan Jones</td>\n",
       "      <td>0.838211</td>\n",
       "      <td>10.896739</td>\n",
       "      <td>13.0</td>\n",
       "      <td>DB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>389</th>\n",
       "      <td>Tyson Campbell</td>\n",
       "      <td>0.834853</td>\n",
       "      <td>12.522791</td>\n",
       "      <td>15.0</td>\n",
       "      <td>DB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>213</th>\n",
       "      <td>Jordan Fuller</td>\n",
       "      <td>0.825027</td>\n",
       "      <td>6.600212</td>\n",
       "      <td>8.0</td>\n",
       "      <td>DB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>370</th>\n",
       "      <td>Tariq Woolen</td>\n",
       "      <td>0.811018</td>\n",
       "      <td>8.921197</td>\n",
       "      <td>11.0</td>\n",
       "      <td>DB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>177</th>\n",
       "      <td>Jalen Pitre</td>\n",
       "      <td>0.760364</td>\n",
       "      <td>17.488379</td>\n",
       "      <td>23.0</td>\n",
       "      <td>DB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>Derion Kendrick</td>\n",
       "      <td>0.737061</td>\n",
       "      <td>10.318860</td>\n",
       "      <td>14.0</td>\n",
       "      <td>DB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>Avonte Maddox</td>\n",
       "      <td>0.694584</td>\n",
       "      <td>9.724177</td>\n",
       "      <td>14.0</td>\n",
       "      <td>DB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>Bobby McCain</td>\n",
       "      <td>0.691009</td>\n",
       "      <td>8.983119</td>\n",
       "      <td>13.0</td>\n",
       "      <td>DB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>252</th>\n",
       "      <td>Kristian Fulton</td>\n",
       "      <td>0.684779</td>\n",
       "      <td>9.586908</td>\n",
       "      <td>14.0</td>\n",
       "      <td>DB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>393</th>\n",
       "      <td>Vonn Bell</td>\n",
       "      <td>0.679751</td>\n",
       "      <td>16.314014</td>\n",
       "      <td>24.0</td>\n",
       "      <td>DB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>251</th>\n",
       "      <td>Kindle Vildor</td>\n",
       "      <td>0.679112</td>\n",
       "      <td>5.432899</td>\n",
       "      <td>8.0</td>\n",
       "      <td>DB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122</th>\n",
       "      <td>Devin McCourty</td>\n",
       "      <td>0.678946</td>\n",
       "      <td>9.505244</td>\n",
       "      <td>14.0</td>\n",
       "      <td>DB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>295</th>\n",
       "      <td>Michael Jackson</td>\n",
       "      <td>0.676114</td>\n",
       "      <td>10.817818</td>\n",
       "      <td>16.0</td>\n",
       "      <td>DB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Amik Robertson</td>\n",
       "      <td>0.671554</td>\n",
       "      <td>7.387095</td>\n",
       "      <td>11.0</td>\n",
       "      <td>DB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>261</th>\n",
       "      <td>Lamarcus Joyner</td>\n",
       "      <td>0.630884</td>\n",
       "      <td>5.677960</td>\n",
       "      <td>9.0</td>\n",
       "      <td>DB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>245</th>\n",
       "      <td>Kenny Moore</td>\n",
       "      <td>0.630594</td>\n",
       "      <td>10.720101</td>\n",
       "      <td>17.0</td>\n",
       "      <td>DB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>291</th>\n",
       "      <td>Michael Carter</td>\n",
       "      <td>0.613455</td>\n",
       "      <td>7.974920</td>\n",
       "      <td>13.0</td>\n",
       "      <td>DB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>292</th>\n",
       "      <td>Michael Carter</td>\n",
       "      <td>0.613455</td>\n",
       "      <td>7.974920</td>\n",
       "      <td>13.0</td>\n",
       "      <td>DB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>345</th>\n",
       "      <td>Rayshawn Jenkins</td>\n",
       "      <td>0.577300</td>\n",
       "      <td>8.659497</td>\n",
       "      <td>15.0</td>\n",
       "      <td>DB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>Caden Sterns</td>\n",
       "      <td>0.557443</td>\n",
       "      <td>5.016986</td>\n",
       "      <td>9.0</td>\n",
       "      <td>DB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>Deommodore Lenoir</td>\n",
       "      <td>0.541897</td>\n",
       "      <td>5.418968</td>\n",
       "      <td>10.0</td>\n",
       "      <td>DB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>216</th>\n",
       "      <td>Jordan Whitehead</td>\n",
       "      <td>0.500951</td>\n",
       "      <td>8.015212</td>\n",
       "      <td>16.0</td>\n",
       "      <td>DB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>276</th>\n",
       "      <td>Marco Wilson</td>\n",
       "      <td>0.461754</td>\n",
       "      <td>6.002797</td>\n",
       "      <td>13.0</td>\n",
       "      <td>DB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>228</th>\n",
       "      <td>Juju Hughes</td>\n",
       "      <td>0.387494</td>\n",
       "      <td>3.099954</td>\n",
       "      <td>8.0</td>\n",
       "      <td>DB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>Daron Bland</td>\n",
       "      <td>0.337636</td>\n",
       "      <td>2.701087</td>\n",
       "      <td>8.0</td>\n",
       "      <td>DB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>308</th>\n",
       "      <td>Nasir Adderley</td>\n",
       "      <td>0.269961</td>\n",
       "      <td>3.509494</td>\n",
       "      <td>13.0</td>\n",
       "      <td>DB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>181</th>\n",
       "      <td>James Bradberry</td>\n",
       "      <td>0.239349</td>\n",
       "      <td>3.829587</td>\n",
       "      <td>16.0</td>\n",
       "      <td>DB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>Camryn Bynum</td>\n",
       "      <td>0.226866</td>\n",
       "      <td>3.402988</td>\n",
       "      <td>15.0</td>\n",
       "      <td>DB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>189</th>\n",
       "      <td>Jaylinn Hawkins</td>\n",
       "      <td>0.185559</td>\n",
       "      <td>2.783378</td>\n",
       "      <td>15.0</td>\n",
       "      <td>DB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>330</th>\n",
       "      <td>Quandre Diggs</td>\n",
       "      <td>0.101474</td>\n",
       "      <td>1.014743</td>\n",
       "      <td>10.0</td>\n",
       "      <td>DB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>258</th>\n",
       "      <td>Kyler Gordon</td>\n",
       "      <td>0.099610</td>\n",
       "      <td>2.689480</td>\n",
       "      <td>27.0</td>\n",
       "      <td>DB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Amani Hooker</td>\n",
       "      <td>0.030324</td>\n",
       "      <td>0.454857</td>\n",
       "      <td>15.0</td>\n",
       "      <td>DB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>373</th>\n",
       "      <td>Taylor Rapp</td>\n",
       "      <td>-0.041368</td>\n",
       "      <td>-0.413684</td>\n",
       "      <td>10.0</td>\n",
       "      <td>DB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170</th>\n",
       "      <td>Jace Whittaker</td>\n",
       "      <td>-0.157617</td>\n",
       "      <td>-1.891404</td>\n",
       "      <td>12.0</td>\n",
       "      <td>DB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>397</th>\n",
       "      <td>Xavien Howard</td>\n",
       "      <td>-0.174849</td>\n",
       "      <td>-2.797586</td>\n",
       "      <td>16.0</td>\n",
       "      <td>DB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>Darious Williams</td>\n",
       "      <td>-0.642339</td>\n",
       "      <td>-6.423385</td>\n",
       "      <td>10.0</td>\n",
       "      <td>DB</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  displayName  Average SITR  Total SITR  tackleOpportunities  \\\n",
       "309                Nate Hobbs      3.889093   77.781852                 20.0   \n",
       "27              Anthony Brown      3.883124   66.013108                 17.0   \n",
       "268              Levi Wallace      3.511717   35.117167                 10.0   \n",
       "304              Myles Bryant      3.510983   31.598847                  9.0   \n",
       "238                Kaiir Elam      3.491266   34.912662                 10.0   \n",
       "325           Patrick Surtain      3.440946   37.850403                 11.0   \n",
       "56               Caleb Farley      3.244830   32.448297                 10.0   \n",
       "375         Terrance Mitchell      3.234276   29.108480                  9.0   \n",
       "283         Marshon Lattimore      3.133794   34.471731                 11.0   \n",
       "118              Derwin James      3.127214   43.780998                 14.0   \n",
       "132              Duron Harmon      3.095674   27.861068                  9.0   \n",
       "301        Minkah Fitzpatrick      3.085678   43.199495                 14.0   \n",
       "29           Antoine Winfield      3.076562   58.454678                 19.0   \n",
       "351            Roger McCreary      3.007161   78.186195                 26.0   \n",
       "297               Mike Hilton      2.999184   59.983686                 20.0   \n",
       "237               Kader Kohou      2.989692   44.845386                 15.0   \n",
       "352              Ronald Darby      2.891377   23.131013                  8.0   \n",
       "179            Jalen Thompson      2.758804   55.176081                 20.0   \n",
       "57           Cameron Dantzler      2.724820   57.221224                 21.0   \n",
       "371             Taron Johnson      2.693577   43.097233                 16.0   \n",
       "52             C.J. Henderson      2.666398   45.328768                 17.0   \n",
       "71             Chidobe Awuzie      2.655477   45.143111                 17.0   \n",
       "169           Jabrill Peppers      2.612947   26.129475                 10.0   \n",
       "323          Patrick Peterson      2.575056   33.475727                 13.0   \n",
       "94             Darnell Savage      2.559314   25.593139                 10.0   \n",
       "141                 Eric Rowe      2.548800   38.231995                 15.0   \n",
       "339             Rashad Fenton      2.546861   43.296634                 17.0   \n",
       "277               Marcus Epps      2.525892   37.888376                 15.0   \n",
       "92                Darius Slay      2.518904   25.189043                 10.0   \n",
       "188             Jaylen Watson      2.500694   42.511800                 17.0   \n",
       "175           Jaire Alexander      2.488693   27.375620                 11.0   \n",
       "360          Shaquill Griffin      2.467858   27.146434                 11.0   \n",
       "284            Martin Emerson      2.432105   43.777895                 18.0   \n",
       "199              Jessie Bates      2.423645   21.812806                  9.0   \n",
       "107            DeShon Elliott      2.380703   49.994754                 21.0   \n",
       "260            L'Jarius Sneed      2.352531   61.165803                 26.0   \n",
       "398           Xavier McKinney      2.349140   21.142260                  9.0   \n",
       "98            Darrick Forrest      2.340266   35.103992                 15.0   \n",
       "88               Damar Hamlin      2.325578   32.558092                 14.0   \n",
       "50                Budda Baker      2.285331   52.562603                 23.0   \n",
       "226             Jourdan Lewis      2.269121   31.767699                 14.0   \n",
       "204              John Johnson      2.260945   45.218896                 20.0   \n",
       "315                Nick Scott      2.209050   33.135754                 15.0   \n",
       "349               Rock Ya-Sin      2.195933   21.959330                 10.0   \n",
       "278               Marcus Maye      2.089815   18.808331                  9.0   \n",
       "112               Denzel Ward      2.087084   29.219178                 14.0   \n",
       "364           Stephon Gilmore      2.069300   35.178092                 17.0   \n",
       "7                 Adrian Amos      2.068171   22.749881                 11.0   \n",
       "160            Harrison Smith      2.059329   45.305249                 22.0   \n",
       "395           William Jackson      2.051855   30.777827                 15.0   \n",
       "344             Rasul Douglas      2.042756   34.726850                 17.0   \n",
       "306          Myles Hartsfield      2.025386   22.279241                 11.0   \n",
       "205           Johnathan Abram      2.001862   46.042820                 23.0   \n",
       "180                Jamel Dean      1.998070   27.972982                 14.0   \n",
       "293             Michael Davis      1.981813   17.836318                  9.0   \n",
       "165            Isaiah Simmons      1.950829   21.459121                 11.0   \n",
       "135             Eddie Jackson      1.935292   29.029385                 15.0   \n",
       "365             Steven Nelson      1.925498   38.509956                 20.0   \n",
       "78                Coby Bryant      1.924182   15.393455                  8.0   \n",
       "31              Asante Samuel      1.889717   34.014911                 18.0   \n",
       "85                  D.J. Reed      1.884899   26.388580                 14.0   \n",
       "45           Brandon Stephens      1.872171   14.977369                  8.0   \n",
       "49             Bryce Callahan      1.864746   20.512201                 11.0   \n",
       "126             Donte Jackson      1.852490   20.377393                 11.0   \n",
       "89               Dane Jackson      1.818129   16.363162                  9.0   \n",
       "242            Kendall Fuller      1.818112   27.271674                 15.0   \n",
       "178              Jalen Ramsey      1.812703   30.815956                 17.0   \n",
       "281           Marlon Humphrey      1.794575   28.713196                 16.0   \n",
       "194              Jeremy Chinn      1.793478   30.489128                 17.0   \n",
       "191               Jeff Okudah      1.771464   40.743681                 23.0   \n",
       "256               Kyle Dugger      1.766667   14.133338                  8.0   \n",
       "65              Carlton Davis      1.746110   36.668316                 21.0   \n",
       "152              Grant Delpit      1.727344   32.819535                 19.0   \n",
       "6             Adoree' Jackson      1.727261   34.545215                 20.0   \n",
       "23                Andre Cisco      1.718458   17.184580                 10.0   \n",
       "388            Tyrann Mathieu      1.702920   30.652562                 18.0   \n",
       "236           K'Waun Williams      1.681621   23.542691                 14.0   \n",
       "8             Adrian Phillips      1.678014   26.848228                 16.0   \n",
       "247               Kevin Byard      1.660428   23.245995                 14.0   \n",
       "114            Derek Stingley      1.644843   29.607179                 18.0   \n",
       "241             Keisean Nixon      1.643375   13.147004                  8.0   \n",
       "155              Greg Newsome      1.607329   20.895279                 13.0   \n",
       "119              Desmond King      1.573658   23.604873                 15.0   \n",
       "137                 Eli Apple      1.570681   17.277486                 11.0   \n",
       "235               Justin Reid      1.547586   15.475855                 10.0   \n",
       "350             Rodney McLeod      1.541276   16.954035                 11.0   \n",
       "93              Darnay Holmes      1.527467   12.219738                  8.0   \n",
       "384              Trevon Diggs      1.522768   24.364293                 16.0   \n",
       "142               Eric Stokes      1.506437   21.090121                 14.0   \n",
       "224             Josh Metellus      1.501581   19.520549                 13.0   \n",
       "231              Justin Evans      1.497175   14.971747                 10.0   \n",
       "99                 David Long      1.483389   43.018267                 29.0   \n",
       "10              Ahmad Gardner      1.473317   16.206487                 11.0   \n",
       "326             Paulson Adebo      1.471207   13.240865                  9.0   \n",
       "176               Jalen Mills      1.463396   17.560749                 12.0   \n",
       "166              J.C. Jackson      1.444251   14.442513                 10.0   \n",
       "125            Donovan Wilson      1.441346   40.357675                 28.0   \n",
       "44              Brandon Jones      1.409938   23.968946                 17.0   \n",
       "138          Emmanuel Moseley      1.408837   19.723721                 14.0   \n",
       "215              Jordan Poyer      1.392230   11.137839                  8.0   \n",
       "9         Ahkello Witherspoon      1.380964   19.333499                 14.0   \n",
       "51               Byron Murphy      1.380311   13.803112                 10.0   \n",
       "200             Jevon Holland      1.354452   17.607881                 13.0   \n",
       "298               Mike Hughes      1.348831   20.232463                 15.0   \n",
       "30              Arthur Maulet      1.296658   15.559899                 12.0   \n",
       "70   Chauncey Gardner-Johnson      1.295536   29.797339                 23.0   \n",
       "21            Amani Oruwariye      1.267790   25.355802                 20.0   \n",
       "66              Casey Hayward      1.267481   19.012222                 15.0   \n",
       "369           Talanoa Hufanga      1.243675   14.924100                 12.0   \n",
       "223                Josh Jones      1.223792   29.371016                 24.0   \n",
       "222                Josh Jones      1.223792   29.371016                 24.0   \n",
       "399              Xavier Woods      1.214540   23.076252                 19.0   \n",
       "240            Kareem Jackson      1.204259   15.655361                 13.0   \n",
       "171                Jack Jones      1.185413   13.039545                 11.0   \n",
       "1                A.J. Terrell      1.153087   18.449396                 16.0   \n",
       "227            Juan Thornhill      1.143074   10.287663                  9.0   \n",
       "60             Cameron Sutton      1.139252   21.645790                 19.0   \n",
       "187               Jaycee Horn      1.098237   15.375318                 14.0   \n",
       "274              Malik Hooker      1.083263   11.915895                 11.0   \n",
       "153               Grant Haley      1.054259   10.542587                 10.0   \n",
       "376           Terrell Edmunds      1.053873   13.700351                 13.0   \n",
       "211            Jonathan Owens      1.031180   24.748331                 24.0   \n",
       "36          Benjamin St-Juste      1.025567   18.460206                 18.0   \n",
       "43               Bradley Roby      1.023593   17.401084                 17.0   \n",
       "346              Richie Grant      0.993625   19.872497                 20.0   \n",
       "280           Marcus Williams      0.993208   21.850575                 22.0   \n",
       "296              Mike Edwards      0.992743   16.876634                 17.0   \n",
       "68           Chandon Sullivan      0.969049    9.690487                 10.0   \n",
       "229               Julian Love      0.952705   11.432456                 12.0   \n",
       "77                Chuck Clark      0.942075   17.899420                 19.0   \n",
       "279             Marcus Peters      0.935741    8.421672                  9.0   \n",
       "183            Jaquan Brisker      0.932422   26.107816                 28.0   \n",
       "322             P.J. Williams      0.905647    7.245176                  8.0   \n",
       "317               Nik Needham      0.898578   12.580095                 14.0   \n",
       "210            Jonathan Jones      0.838211   10.896739                 13.0   \n",
       "389            Tyson Campbell      0.834853   12.522791                 15.0   \n",
       "213             Jordan Fuller      0.825027    6.600212                  8.0   \n",
       "370              Tariq Woolen      0.811018    8.921197                 11.0   \n",
       "177               Jalen Pitre      0.760364   17.488379                 23.0   \n",
       "115           Derion Kendrick      0.737061   10.318860                 14.0   \n",
       "33              Avonte Maddox      0.694584    9.724177                 14.0   \n",
       "38               Bobby McCain      0.691009    8.983119                 13.0   \n",
       "252           Kristian Fulton      0.684779    9.586908                 14.0   \n",
       "393                 Vonn Bell      0.679751   16.314014                 24.0   \n",
       "251             Kindle Vildor      0.679112    5.432899                  8.0   \n",
       "122            Devin McCourty      0.678946    9.505244                 14.0   \n",
       "295           Michael Jackson      0.676114   10.817818                 16.0   \n",
       "22             Amik Robertson      0.671554    7.387095                 11.0   \n",
       "261           Lamarcus Joyner      0.630884    5.677960                  9.0   \n",
       "245               Kenny Moore      0.630594   10.720101                 17.0   \n",
       "291            Michael Carter      0.613455    7.974920                 13.0   \n",
       "292            Michael Carter      0.613455    7.974920                 13.0   \n",
       "345          Rayshawn Jenkins      0.577300    8.659497                 15.0   \n",
       "54               Caden Sterns      0.557443    5.016986                  9.0   \n",
       "113         Deommodore Lenoir      0.541897    5.418968                 10.0   \n",
       "216          Jordan Whitehead      0.500951    8.015212                 16.0   \n",
       "276              Marco Wilson      0.461754    6.002797                 13.0   \n",
       "228               Juju Hughes      0.387494    3.099954                  8.0   \n",
       "95                Daron Bland      0.337636    2.701087                  8.0   \n",
       "308            Nasir Adderley      0.269961    3.509494                 13.0   \n",
       "181           James Bradberry      0.239349    3.829587                 16.0   \n",
       "61               Camryn Bynum      0.226866    3.402988                 15.0   \n",
       "189           Jaylinn Hawkins      0.185559    2.783378                 15.0   \n",
       "330             Quandre Diggs      0.101474    1.014743                 10.0   \n",
       "258              Kyler Gordon      0.099610    2.689480                 27.0   \n",
       "20               Amani Hooker      0.030324    0.454857                 15.0   \n",
       "373               Taylor Rapp     -0.041368   -0.413684                 10.0   \n",
       "170            Jace Whittaker     -0.157617   -1.891404                 12.0   \n",
       "397             Xavien Howard     -0.174849   -2.797586                 16.0   \n",
       "91           Darious Williams     -0.642339   -6.423385                 10.0   \n",
       "\n",
       "    position  \n",
       "309       DB  \n",
       "27        DB  \n",
       "268       DB  \n",
       "304       DB  \n",
       "238       DB  \n",
       "325       DB  \n",
       "56        DB  \n",
       "375       DB  \n",
       "283       DB  \n",
       "118       DB  \n",
       "132       DB  \n",
       "301       DB  \n",
       "29        DB  \n",
       "351       DB  \n",
       "297       DB  \n",
       "237       DB  \n",
       "352       DB  \n",
       "179       DB  \n",
       "57        DB  \n",
       "371       DB  \n",
       "52        DB  \n",
       "71        DB  \n",
       "169       DB  \n",
       "323       DB  \n",
       "94        DB  \n",
       "141       DB  \n",
       "339       DB  \n",
       "277       DB  \n",
       "92        DB  \n",
       "188       DB  \n",
       "175       DB  \n",
       "360       DB  \n",
       "284       DB  \n",
       "199       DB  \n",
       "107       DB  \n",
       "260       DB  \n",
       "398       DB  \n",
       "98        DB  \n",
       "88        DB  \n",
       "50        DB  \n",
       "226       DB  \n",
       "204       DB  \n",
       "315       DB  \n",
       "349       DB  \n",
       "278       DB  \n",
       "112       DB  \n",
       "364       DB  \n",
       "7         DB  \n",
       "160       DB  \n",
       "395       DB  \n",
       "344       DB  \n",
       "306       DB  \n",
       "205       DB  \n",
       "180       DB  \n",
       "293       DB  \n",
       "165       DB  \n",
       "135       DB  \n",
       "365       DB  \n",
       "78        DB  \n",
       "31        DB  \n",
       "85        DB  \n",
       "45        DB  \n",
       "49        DB  \n",
       "126       DB  \n",
       "89        DB  \n",
       "242       DB  \n",
       "178       DB  \n",
       "281       DB  \n",
       "194       DB  \n",
       "191       DB  \n",
       "256       DB  \n",
       "65        DB  \n",
       "152       DB  \n",
       "6         DB  \n",
       "23        DB  \n",
       "388       DB  \n",
       "236       DB  \n",
       "8         DB  \n",
       "247       DB  \n",
       "114       DB  \n",
       "241       DB  \n",
       "155       DB  \n",
       "119       DB  \n",
       "137       DB  \n",
       "235       DB  \n",
       "350       DB  \n",
       "93        DB  \n",
       "384       DB  \n",
       "142       DB  \n",
       "224       DB  \n",
       "231       DB  \n",
       "99        DB  \n",
       "10        DB  \n",
       "326       DB  \n",
       "176       DB  \n",
       "166       DB  \n",
       "125       DB  \n",
       "44        DB  \n",
       "138       DB  \n",
       "215       DB  \n",
       "9         DB  \n",
       "51        DB  \n",
       "200       DB  \n",
       "298       DB  \n",
       "30        DB  \n",
       "70        DB  \n",
       "21        DB  \n",
       "66        DB  \n",
       "369       DB  \n",
       "223       DB  \n",
       "222       DB  \n",
       "399       DB  \n",
       "240       DB  \n",
       "171       DB  \n",
       "1         DB  \n",
       "227       DB  \n",
       "60        DB  \n",
       "187       DB  \n",
       "274       DB  \n",
       "153       DB  \n",
       "376       DB  \n",
       "211       DB  \n",
       "36        DB  \n",
       "43        DB  \n",
       "346       DB  \n",
       "280       DB  \n",
       "296       DB  \n",
       "68        DB  \n",
       "229       DB  \n",
       "77        DB  \n",
       "279       DB  \n",
       "183       DB  \n",
       "322       DB  \n",
       "317       DB  \n",
       "210       DB  \n",
       "389       DB  \n",
       "213       DB  \n",
       "370       DB  \n",
       "177       DB  \n",
       "115       DB  \n",
       "33        DB  \n",
       "38        DB  \n",
       "252       DB  \n",
       "393       DB  \n",
       "251       DB  \n",
       "122       DB  \n",
       "295       DB  \n",
       "22        DB  \n",
       "261       DB  \n",
       "245       DB  \n",
       "291       DB  \n",
       "292       DB  \n",
       "345       DB  \n",
       "54        DB  \n",
       "113       DB  \n",
       "216       DB  \n",
       "276       DB  \n",
       "228       DB  \n",
       "95        DB  \n",
       "308       DB  \n",
       "181       DB  \n",
       "61        DB  \n",
       "189       DB  \n",
       "330       DB  \n",
       "258       DB  \n",
       "20        DB  \n",
       "373       DB  \n",
       "170       DB  \n",
       "397       DB  \n",
       "91        DB  "
      ]
     },
     "execution_count": 435,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined3[combined3[\"position\"]==\"DB\"].sort_values(by=\"Average SITR\",ascending=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
